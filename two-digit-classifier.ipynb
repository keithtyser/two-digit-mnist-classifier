{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hX1Nl8Qsboi"
   },
   "source": [
    "Keith Tyser\n",
    "\n",
    "The process of exploring the dataset begins by loading the data using the numpy library and checking the shape of the data_X and data_Y arrays to determine the number of samples and the size of the images. Then, a sample of images is visualized to get an idea of the data. The distribution of the labels is also checked to see if the dataset is balanced. The pre-processing performed on the dataset includes normalizing the pixel values by dividing them by 255.0, cropping the images to a smaller size, and resizing the images to a consistent size of 32x32. Data quality issues that were observed include samples with NaN values in the data_Y array and samples with missing or corrupted data. These samples were removed from the dataset using the np.delete() function.\n",
    "\n",
    "The model chosen is a convolutional neural network (CNN) which is appropriate for image classification tasks. The model is trained and evaluated by splitting the dataset into training and testing sets and training the model on the training set, then evaluating its performance on the testing set. The network architecture consists of several layers including an input layer, multiple convolutional layers with ReLU activation, max pooling layers, a flatten layer, dense layer, and a dropout layer. There are two output layers, each with 10 neurons and a softmax activation function, one for each digit. Hyperparameter tuning is done to find optimal kernel size, number of filters, and dropout rate. Final model with optimized hyperparameters is trained using 5-fold cross validation and receives an accuracy of ~92% on both digits.\n",
    "\n",
    "The model is evaluated using the metrics of loss and accuracy. The loss metric used is categorical cross-entropy, which is commonly used for multi-class classification problems. The accuracy metric measures the proportion of correctly classified images. The performance of the model is ~92% accuracy on both digits.\n",
    "\n",
    "To deploy the model as a service, the model could be containerized and deployed on a cloud service such as AWS or Google Cloud. Additionally, an API could be created to handle the incoming images, send them to the model for prediction, and return the predictions to the user. Another option would be to use a serverless solution like AWS Lambda to handle the image processing and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7eeagFZuLJr"
   },
   "source": [
    "# Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1391
    },
    "id": "LY7YvPobv8nM",
    "outputId": "beacaedf-bba0-4711-ab10-a7cabdb07eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X shape: (62000, 64, 64)\n",
      "data_Y shape: (62000, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVA0lEQVR4nO3df7BVZb3H8fcnEBDF8Iidyw9/BVzLkqxBzdQyTTMvV7lj41W7DTbe4eZ0zSanxMyujnpH/7F0bEImK+7cSslS0blaZDjm3AAxsPiRgYoBIscEr/gLBL73j73OZu3d+bHP3nvtfeD5vGaY86z1rL3WV/f5nud51o9nKSIws33fu9odgJm1hpPdLBFOdrNEONnNEuFkN0uEk90sEU72vYSk2ZKubfa2A4zhEkm7JL0u6f3N3n8Nx/+NpLclPdHqY+8LnOyDgKR1kt6StE3Sq5L+V9IXJZW/n4j4YkTcUMv+8ttKOk3ShiaG+7uIODAiVmf7/6CkX0r6q6QB37Qh6V8lrc3+gDwiaVxv20bE6cAXG4g9aU72weMfI2IUcARwM3AVcFd7Q6rJO8A84NKBflDSacB/AucBHcDzwE+bGZzt4WQfZCLi/yJiPvDPwAxJHwSQ9CNJN3ZvJ+nrkjZJejFrHUPSpPy2kg4AHgbGZS3n65LGSTpB0lJJr0naLOnWBuJ9JiLuAlbW8fFpwM8iYmVE7ABuAD4uaWK98VjvnOyDVEQsATYAp1bXSTob+CrwKWAScFov+3gD+AzwYtb1PjAiXgRuA26LiIOAiZRa5u59/0HSxU3+z+mLeih/sIXHT4aTfXB7kVL3ttoFwA+zFvFN4LoB7vcdYJKkMRHxekQs6q6IiCkR8ZO6Ix6YR4ALJE2RtD/wLSCAkS06flKc7IPbeGBLD+vHAetzy+t72KYvlwJ/D/xJ0pOSptUZX0Mi4tfAfwA/B9Zl/7ZR6tFYkznZBylJx1NK9p4uM20CJuSWD+tjV39zhjwi1kTERcB7gFuAe7PxfctFxHcjYnJEdFJK+qHAinbEsq9zsg8ykg7KWtq7gf+OiD/2sNk84AuS3i9pJNDXNfXNwCGS3p07xr9IOjQidgOvZqt31xmvJI0AhmXLIyQNr/GzI7JLd5J0ODCH0rmErfXEYn1zsg8eD0raRqlLfg1wK/CFnjaMiIeB24GFwFqge8y9vYdt/0TpctZz2TX8ccDZwEpJr1M6WXdhRLwFIGmlpM8NIO4jgLfYczb+LeCZ7kpJD0v6Ri+fHQH8BHgdWAL8jtwfLknfkPTwAGKxPsiTV+z9srvZVgDDI2Jngcf5PHAnsAM4qfvGmlaRtAD4KLAkIs5o5bH3BU72vZSkfwL+h9KZ67nA7oiY3t6obDBzN37v9W9AF/AssAu4rL3h2GDnlt0sEQ217JLOlvRM9iDDrGYFZWbNV3fLLmkI8GfgTEo3QTwJXBQRq/r4jLsRZgWLCPW0vpGW/QRgbUQ8lz3EcDelp5fMbBBqJNnHU3mb5oZsXQVJM7MnrJY2cCwza9DQog8QEXMo3RnlbrxZGzXSsm+k8p7sCdk6MxuEGkn2J4HJko6SNAy4EJjfnLDMrNnq7sZHxE5J/w78EhgC/CAi6pmtxMxaoKU31XjMbla8Ii69mdlexMlulggnu1kinOxmiXCymyXCyW6WCCe7WSKc7GaJcLKbJaLwp95SN2nSpIrlLVu29Fg2K5pbdrNEONnNEuEHYQq2c2flOxuuu+66cvmmm26qqPNMv9YMfhDGLHFOdrNEONnNEuExewGmTZtWLj/44IMVdatW7ZlW/9hjj62o2727rrcmm1XwmN0scU52s0T4DroCbN26tde6jo6OclnqsbdlVgi37GaJcLKbJcLJbpYIj9kLcPHFF/da19nZWS5PmDChou6FF14oLCYzt+xmieg32SX9QFKXpBW5dR2SFkhak/08uNgwzaxRtXTjfwTcAfxXbt0s4NGIuFnSrGz5quaHt3c65JBDeq3LX2778pe/XFF35ZVXFhaTWb8te0Q8DlRPqXIeMDcrzwWmNzkuM2uyek/QdUbEpqz8EtDZ24aSZgIz6zyOmTVJw2fjIyL6esAlIuYAcyCdB2FGjBhR03bnn39+xbK78Vakes/Gb5Y0FiD72dW8kMysCPUm+3xgRlaeATzQnHDMrCi1XHr7KfA74GhJGyRdCtwMnClpDfCpbNnMBrF+x+wRcVEvVWc0OZZ9xqhRo2razpNVWCv5DjqzRDjZzRLhB2EKMGbMmJq2W7RoUcGRmO3hlt0sEU52s0Q42c0S4TF7AYYPH17TdmvWrCk4ErM93LKbJcLJbpYId+MLMG7cuJq2q341lFmR3LKbJcLJbpYId+ObYNiwYRXLtU5eUesDM2bN4JbdLBFOdrNEONnNEuExexNMmjSpYnno0N7/t0bsmXNz1apVhcVkVs0tu1kinOxmiXA3vgkuu+yyiuX8K576snPnziLCMeuRW3azRDjZzRLhZDdLhMfsdcpfXuvo6KhrH2PHjq1YfuWVVxqKyawvbtnNElHL658Ok7RQ0ipJKyVdka3vkLRA0prs58HFh2tm9aqlG78TuDIifi9pFPCUpAXAJcCjEXGzpFnALOCq4kIdXPJ3wm3evLnXuurLcPnlCRMmVNStWLGimSGaVei3ZY+ITRHx+6y8DVgNjAfOA+Zmm80FphcVpJk1bkAn6CQdCXwYWAx0RsSmrOoloLOXz8wEZtYfopk1Q80n6CQdCPwc+EpEvJavi1K/NXr6XETMiYipETG1oUjNrCE1teyS9qOU6D+OiF9kqzdLGhsRmySNBbqKCnIwyo/L33jjjbr2cc4551QsP/LIIw3FZNaXWs7GC7gLWB0Rt+aq5gMzsvIM4IHmh2dmzVJLy34y8Hngj5KWZ+u+AdwMzJN0KfACcEExIZpZM/Sb7BHxBNDbY1xnNDecvUe+Gz9lypSKulqfejvzzDObGpNZX3wHnVkinOxmifCDMHXKd+MPPfTQuvbR19x1ntjCms0tu1kinOxmiXCymyVC+bFn4QeTWnewFqqeJ/7ll18ul0ePHl1Rt2vXrnK5esy+bt265gdnyYmIHq/9umU3S4ST3SwR7sab7WPcjTdLnJPdLBFOdrNEONnNEuFkN0uEk90sEU52s0Q42c0S4WQ3S4Qnr2ix/IMxS5YsqaibPHnygPdXfQfk+vXry+VTTz21XP7LX/4y4H3bvsUtu1kinOxmiXCymyXCT70V4KKLLiqXZ8+eXVF30EEHtTqcHi1fvrxcPvHEEyvqduzY0epwrIn81JtZ4mp519sISUskPS1ppaTrs/VHSVosaa2keyQNKz5cM6tXv9347MWOB0TE69nbXJ8ArgC+CvwiIu6WNBt4OiK+18++9slufPVccmvWrKlrP3PmzCmX77///nJ55MiRFdu9+eab5fKyZcsq6rZv314ur169ulzu7OysOY477rijXL788str/pwNDnV346Pk9Wxxv+xfAKcD92br5wLTmxCnmRWkpjG7pCHZG1y7gAXAs8CrEdH92pINwPhePjtT0lJJS5sRsJnVp6Zkj4hdEXEcMAE4AXhfrQeIiDkRMTUiptYZo5k1wYAvvUn6FvAWcBXwdxGxU9JJwHUR8el+PrtPjtlfe+21iuVRo0bV9LnzzjuvYvnBBx8sl/PfS/UroOu5XFo9t/3UqXv+9j722GMVdflLb2PGjOlxvQ1edY/ZJR0qaXRW3h84E1gNLAQ+m202A3igOaGaWRFqeRBmLDBX0hBKfxzmRcRDklYBd0u6EVgG3FVgnGbWIN9B1wRr166tWJ44cWKv2+a7/NWvhmrld5F3yy23VCx/7WtfK5cXLVpULn/sYx9rWUxWP99BZ5Y4J7tZItyNb4KOjo6K5VdeeaXXbd95551yediw9t1hnD87v3Dhwoq6U045pVzO/35ce+21FdvddNNNBUVnjXA33ixxTnazRDjZzRLhMXsB8uPy6jvX8qrrdu3aVVhM1d71rj1/56+55pqKum9+85vlcv68wrPPPlux3UknnVQuv/zyy80O0erkMbtZ4pzsZonwvPEFuP7668vlG264odftjj322Irl/LxwzTZkyJCK5WnTppXL559/fkXd7t27y+X8MC/f9QcYPnx4M0O0grllN0uEk90sEU52s0T40lsB8per3n777Yq6/EQU69atq6ibMmVKuXzYYYf1WAY44ogjyuXqy3WzZs0qlw8//PByuXq8nR/D58foUHnpcL/99iuXqy+vfeADHyiXt2zZgg0OvvRmljgnu1ki3I0vQL6LvG3btoq6/fffv9fP9TXvXLPlu//Vr3PODy/yT8BVxzR+/J4Jhbu6upocodXL3XizxDnZzRLhO+gKkO/uVp+N76sbX0/XvfpMen7YkH8N1RNPPFGxXb7b/fDDD1fUXXLJJeXyJz7xiXK5+oz+ySefXC7fd999A4ja2sEtu1kinOxmiXCymyXCY/YC5MflI0aMqKjLX16rvuy5fv36cvnGG28sl+fNm1exXX5cXuul0+qn3vLL1XXPP/98udzXeYT866s8Zh/83LKbJaLmZM9e27xM0kPZ8lGSFktaK+keSe2bF9nM+jWQbvwVlF7oeFC2fAvw7Yi4W9Js4FLge02Ob6+U72ZfeOGFFXXTp08vl++4446KumXLlpXLzb6zsfqBmfxydVd98eLFPcZRvd3RRx/dzBCtYDW17JImAP8AfD9bFnA6cG+2yVxges+fNrPBoNZu/HeArwPdd3AcArwaETuz5Q3A+J4+KGmmpKWSljYUqZk1pJb3s08DuiLiqXoOEBFzImJqREyt5/Nm1hy1jNlPBs6VdA4wgtKY/TZgtKShWes+AdhYXJh7r/nz5/e5PBjlLx3mb8etvl02/9Rb9Xi+Xa+ftt7127JHxNURMSEijgQuBH4TEZ8DFgKfzTabATxQWJRm1rBGrrNfBXxV0lpKY/i7mhOSmRVhQHfQRcRjwGNZ+TnghOaHZK1W3T0/8MADy+W+XmU1duzYcnncuHEVdRs3elQ32PgOOrNEONnNEuE56OxvuvH5Lvntt99eLp977rkV2+UfoNm+fXtF3ciRI8vl6gk2rFieg84scU52s0Q42c0S4TG7/c3kFaNGjSqXjznmmHJ59uzZFdtVv3I677nnniuXJ06c2GiINgAes5slzslulgh3461P+Qdc8m+nBfjtb39bLh9//PEVdTt27CiXhw8fXlB01hN3480S52Q3S4ST3SwRnjfe+pQ/p1N9S+ydd95ZLleP2atvwbX28zdilggnu1ki3I23mlXPM/fiiy+Wy48//nhF3VlnndWSmKx2btnNEuFkN0uE76CzuuW79Z46evDwHXRmiXOymyXCyW6WCF96s7p5nL53cctuloiaWnZJ64BtwC5gZ0RMldQB3AMcCawDLoiIrcWEaWaNGkjL/smIOC736uVZwKMRMRl4NFs2s0GqkW78ecDcrDwXmN54OGZWlFqTPYBfSXpK0sxsXWdEbMrKLwGdPX1Q0kxJSyUtbTBWM2tATXfQSRofERslvQdYAFwOzI+I0blttkbEwf3sx6dvzQrW0B10EbEx+9kF3EfpVc2bJY0FyH52NSdUMytCv8ku6QBJo7rLwFnACmA+MCPbbAbwQFFBmlnj+u3GS3ovpdYcSpfqfhIRN0k6BJgHHA68QOnS25Z+9uVuvFnBeuvG+6k3s32Mn3ozS5yT3SwRTnazRDjZzRLhZDdLhJPdLBFOdrNEONnNEuFkN0uEk90sEU52s0Q42c0S4WQ3S4ST3SwRTnazRDjZzRLhZDdLhJPdLBFOdrNEONnNEuFkN0uEk90sEU52s0Q42c0S4WQ3S0RNyS5ptKR7Jf1J0mpJJ0nqkLRA0prsZ59vcDWz9qq1Zb8NeCQi3gd8CFgNzAIejYjJwKPZspkNUrW82PHdwHLgvZHbWNIzwGkRsSl7ZfNjEXF0P/vyu97MCtbIu96OAl4GfihpmaTvZ69u7oyITdk2LwGdPX1Y0kxJSyUtrSdwM2uOWlr2qcAi4OSIWCzpNuA14PKIGJ3bbmtE9Dlud8tuVrxGWvYNwIaIWJwt3wt8BNicdd/JfnY1I1AzK0a/yR4RLwHrJXWPx88AVgHzgRnZuhnAA4VEaGZN0W83HkDSccD3gWHAc8AXKP2hmAccDrwAXBARW/rZj7vxZgXrrRtfU7I3i5PdrHiNjNnNbB/gZDdLhJPdLBFOdrNEONnNEuFkN0vE0BYf76+UrsmPycrtNBhiAMdRzXFUGmgcR/RW0dLr7OWDSksjYmrLDzzIYnAcjqOVcbgbb5YIJ7tZItqV7HPadNy8wRADOI5qjqNS0+Joy5jdzFrP3XizRDjZzRLR0mSXdLakZyStldSy2Wgl/UBSl6QVuXUtnwpb0mGSFkpaJWmlpCvaEYukEZKWSHo6i+P6bP1RkhZn3889koYVGUcuniHZ/IYPtSsOSesk/VHS8u75Etv0O1LYtO0tS3ZJQ4DvAp8BjgEuknRMiw7/I+DsqnXtmAp7J3BlRBwDfBT4Uvb/oNWxbAdOj4gPAccBZ0v6KHAL8O2ImARsBS4tOI5uV1Canrxbu+L4ZEQcl7uu3Y7fkeKmbY+IlvwDTgJ+mVu+Gri6hcc/EliRW34GGJuVxwLPtCqWXAwPAGe2MxZgJPB74ERKd2oN7en7KvD4E7Jf4NOBhwC1KY51wJiqdS39XoB3A8+TnThvdhyt7MaPB9bnljdk69qlpqmwiyLpSODDwOJ2xJJ1nZdTmih0AfAs8GpE7Mw2adX38x3g68DubPmQNsURwK8kPSVpZrau1d9LQ9O298cn6IAo/cls2TVISQcCPwe+EhGvtSOWiNgVEcdRallPAN5X9DGrSZoGdEXEU60+dg9OiYiPUBpmfknSx/OVLfpehlKaufl7EfFh4A2quuyNxNHKZN8IHJZbnpCta5e2TIUtaT9Kif7jiPhFO2MBiIhXgYWUusujJXU/HNWK7+dk4FxJ64C7KXXlb2tDHETExuxnF3AfpT+Arf5eCp22vZXJ/iQwOTvTOgy4kNJ01O3S8qmwJQm4C1gdEbe2KxZJh0oanZX3p3TeYDWlpP9sq+KIiKsjYkJEHEnp9+E3EfG5Vsch6QBJo7rLwFnAClr8vUTR07YXfeKj6kTDOcCfKY0Pr2nhcX8KbALeofTX81JKY8NHgTXAr4GOFsRxCqUu2B8ovT9vefb/pKWxAFOAZVkcK4BvZevfCywB1gI/A4a38Ds6DXioHXFkx3s6+7ey+3ezTb8jxwFLs+/mfuDgZsXh22XNEuETdGaJcLKbJcLJbpYIJ7tZIpzsZolwspslwsluloj/B3yZUBB3cX+QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: {0.0: 12114, 1.0: 12042, 2.0: 12167, 3.0: 11971, 4.0: 12108, 5.0: 11788, 6.0: 11933, 7.0: 11869, 8.0: 11915, 9.0: 12093, nan: 4000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data_X = np.load('/content/drive/MyDrive/data (1)/data_X.npy')\n",
    "data_Y = np.load('/content/drive/MyDrive/data (1)/data_Y.npy')\n",
    "\n",
    "# Print the shape of the data_X and data_Y arrays to check the number of samples and the size of the images\n",
    "print(\"data_X shape:\", data_X.shape)\n",
    "print(\"data_Y shape:\", data_Y.shape)\n",
    "\n",
    "# Visualize a sample of the images\n",
    "sample_indices = np.random.randint(0, data_X.shape[0], size=5)\n",
    "for i in sample_indices:\n",
    "    plt.imshow(data_X[i], cmap='gray')\n",
    "    plt.title(\"Digits: \" + str(data_Y[i]))\n",
    "    plt.show()\n",
    "    \n",
    "# Check the distribution of the labels\n",
    "unique, counts = np.unique(data_Y, return_counts=True)\n",
    "print(\"Label distribution:\", dict(zip(unique, counts)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrS1TgS3uWyw"
   },
   "source": [
    "# Remove NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "May3qEa_ylkk",
    "outputId": "4bf53200-620f-4f01-dd61-3a070cee64e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X shape: (59999, 64, 64)\n",
      "data_Y shape: (59999, 2)\n"
     ]
    }
   ],
   "source": [
    "# Find the indices of the samples with NaN values in the data_Y array\n",
    "nan_indices = np.argwhere(np.isnan(data_Y))\n",
    "\n",
    "# Remove the samples with NaN values from the data_X and data_Y arrays\n",
    "data_X = np.delete(data_X, nan_indices, axis=0)\n",
    "data_Y = np.delete(data_Y, nan_indices, axis=0)\n",
    "\n",
    "# Print the new shape of the data_X and data_Y arrays to check the number of samples\n",
    "print(\"data_X shape:\", data_X.shape)\n",
    "print(\"data_Y shape:\", data_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgBpIn8AubeE"
   },
   "source": [
    "# Normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3V6yVRxey7L3"
   },
   "outputs": [],
   "source": [
    "# Normalize the pixel values\n",
    "data_X = data_X / 255.0\n",
    "\n",
    "# Crop the images\n",
    "data_X = data_X[:, :50, :50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "bKE_FN-ty8Nd",
    "outputId": "19bdc71f-829e-4cec-8449-9b522b44dbea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X shape: (59999, 32, 32)\n",
      "data_Y shape: (59999, 2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Resize the images to a consistent size\n",
    "new_size = (32, 32)\n",
    "data_X = np.array([cv2.resize(img, new_size) for img in data_X])\n",
    "\n",
    "# Check for any missing or corrupted data\n",
    "missing_data_indices = []\n",
    "for i, img in enumerate(data_X):\n",
    "    if img.shape != new_size:\n",
    "        missing_data_indices.append(i)\n",
    "\n",
    "# Remove the samples with missing or corrupted data\n",
    "data_X = np.delete(data_X, missing_data_indices, axis=0)\n",
    "data_Y = np.delete(data_Y, missing_data_indices, axis=0)\n",
    "\n",
    "# Print the new shape of the data_X and data_Y arrays to check the number of samples\n",
    "print(\"data_X shape:\", data_X.shape)\n",
    "print(\"data_Y shape:\", data_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCOnUAFvfEUU"
   },
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "wj1459Bxze-k",
    "outputId": "015e63d4-9faa-4cba-dbf8-0ce2d8366ae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 4s 4ms/step - loss: 3.6979 - digit1_loss: 1.7852 - digit2_loss: 1.9127 - digit1_accuracy: 0.3523 - digit2_accuracy: 0.2930\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 2.8165 - digit1_loss: 1.3245 - digit2_loss: 1.4920 - digit1_accuracy: 0.5325 - digit2_accuracy: 0.4663\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 2.4586 - digit1_loss: 1.1474 - digit2_loss: 1.3112 - digit1_accuracy: 0.5987 - digit2_accuracy: 0.5344\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 2.2395 - digit1_loss: 1.0460 - digit2_loss: 1.1935 - digit1_accuracy: 0.6344 - digit2_accuracy: 0.5788\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 2.0769 - digit1_loss: 0.9700 - digit2_loss: 1.1070 - digit1_accuracy: 0.6635 - digit2_accuracy: 0.6132\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.9467 - digit1_loss: 0.9123 - digit2_loss: 1.0344 - digit1_accuracy: 0.6841 - digit2_accuracy: 0.6391\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.8378 - digit1_loss: 0.8595 - digit2_loss: 0.9783 - digit1_accuracy: 0.7028 - digit2_accuracy: 0.6576\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.7540 - digit1_loss: 0.8211 - digit2_loss: 0.9329 - digit1_accuracy: 0.7143 - digit2_accuracy: 0.6748\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.6769 - digit1_loss: 0.7859 - digit2_loss: 0.8910 - digit1_accuracy: 0.7260 - digit2_accuracy: 0.6909\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.6233 - digit1_loss: 0.7639 - digit2_loss: 0.8594 - digit1_accuracy: 0.7348 - digit2_accuracy: 0.7015\n",
      "loss 1.4697942733764648\n",
      "digit1_loss 0.6914819478988647\n",
      "digit2_loss 0.7783114314079285\n",
      "digit1_accuracy 0.7595000267028809\n",
      "digit2_accuracy 0.7324166893959045\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(data_X, data_Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape train_X and test_X and preprocess train_Y and test_Y\n",
    "train_X = train_X.reshape(train_X.shape[0], 32, 32, 1)\n",
    "test_X = test_X.reshape(test_X.shape[0], 32, 32, 1)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_Y1, train_Y2 = train_Y[:,0], train_Y[:,1]\n",
    "test_Y1, test_Y2 = test_Y[:,0], test_Y[:,1]\n",
    "\n",
    "train_Y1 = to_categorical(train_Y1, num_classes=10)\n",
    "train_Y2 = to_categorical(train_Y2, num_classes=10)\n",
    "\n",
    "test_Y1 = to_categorical(test_Y1, num_classes=10)\n",
    "test_Y2 = to_categorical(test_Y2, num_classes=10)\n",
    "\n",
    "# Create the model\n",
    "inputs = Input(shape=(32, 32, 1))\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add an output layer for each digit\n",
    "output1 = Dense(10, activation='softmax', name='digit1')(x)\n",
    "output2 = Dense(10, activation='softmax', name='digit2')(x)\n",
    "\n",
    "model = Model(inputs, [output1, output2])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_X, [train_Y1, train_Y2], batch_size=64, epochs=10)\n",
    "\n",
    "metrics_names = model.metrics_names\n",
    "test_values = model.evaluate(test_X, [test_Y1, test_Y2], verbose=0)\n",
    "\n",
    "for i in range(len(metrics_names)):\n",
    "    print(metrics_names[i], test_values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FEaKLJ2ph1D"
   },
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "UpbFt1dXhJjL",
    "outputId": "3b3bf3b3-cb16-49f5-e23b-4e83a745c5a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting optuna\n",
      "  Downloading optuna-3.0.5-py3-none-any.whl (348 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.5/348.5 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
      "Collecting importlib-metadata<5.0.0\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.9.2-py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.46)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.7.3)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-4.1.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<5.0.0->optuna) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna) (3.5.0)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.1/147.1 KB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=ffe76c7445ea6b5c8eecd7a158718041208a2fdf77061e16e8a9b5713c642732\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyperclip, pbr, Mako, importlib-metadata, colorlog, cmd2, cmaes, autopage, stevedore, alembic, cliff, optuna\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.0.0\n",
      "    Uninstalling importlib-metadata-6.0.0:\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\n",
      "Successfully installed Mako-1.2.4 alembic-1.9.2 autopage-0.5.1 cliff-4.1.0 cmaes-0.9.1 cmd2-2.4.2 colorlog-6.7.0 importlib-metadata-4.13.0 optuna-3.0.5 pbr-5.11.1 pyperclip-1.8.2 stevedore-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "hGDrjwH1hIeE",
    "outputId": "6fb86f73-8f1f-494e-c345-3009111a3111"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:01:01,835]\u001b[0m A new study created in memory with name: no-name-27ba9c2a-a11d-4bd1-8458-c7c5c4e7242a\u001b[0m\n",
      "<ipython-input-14-3974e6b679e6>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0, 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 13s 5ms/step - loss: 2.9984 - digit1_loss: 1.4070 - digit2_loss: 1.5914 - digit1_accuracy: 0.4994 - digit2_accuracy: 0.4235 - val_loss: 1.8156 - val_digit1_loss: 0.8136 - val_digit2_loss: 1.0020 - val_digit1_accuracy: 0.7204 - val_digit2_accuracy: 0.6530\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6576 - digit1_loss: 0.7462 - digit2_loss: 0.9114 - digit1_accuracy: 0.7447 - digit2_accuracy: 0.6853 - val_loss: 1.2200 - val_digit1_loss: 0.5433 - val_digit2_loss: 0.6767 - val_digit1_accuracy: 0.8146 - val_digit2_accuracy: 0.7785\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2171 - digit1_loss: 0.5568 - digit2_loss: 0.6603 - digit1_accuracy: 0.8127 - digit2_accuracy: 0.7786 - val_loss: 1.0030 - val_digit1_loss: 0.4542 - val_digit2_loss: 0.5488 - val_digit1_accuracy: 0.8474 - val_digit2_accuracy: 0.8169\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9737 - digit1_loss: 0.4450 - digit2_loss: 0.5288 - digit1_accuracy: 0.8515 - digit2_accuracy: 0.8216 - val_loss: 0.8600 - val_digit1_loss: 0.3951 - val_digit2_loss: 0.4649 - val_digit1_accuracy: 0.8612 - val_digit2_accuracy: 0.8445\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8120 - digit1_loss: 0.3738 - digit2_loss: 0.4382 - digit1_accuracy: 0.8727 - digit2_accuracy: 0.8537 - val_loss: 0.7838 - val_digit1_loss: 0.3705 - val_digit2_loss: 0.4133 - val_digit1_accuracy: 0.8749 - val_digit2_accuracy: 0.8596\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6985 - digit1_loss: 0.3274 - digit2_loss: 0.3711 - digit1_accuracy: 0.8890 - digit2_accuracy: 0.8760 - val_loss: 0.8061 - val_digit1_loss: 0.3733 - val_digit2_loss: 0.4328 - val_digit1_accuracy: 0.8827 - val_digit2_accuracy: 0.8580\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6096 - digit1_loss: 0.2868 - digit2_loss: 0.3227 - digit1_accuracy: 0.9024 - digit2_accuracy: 0.8921 - val_loss: 0.7043 - val_digit1_loss: 0.3254 - val_digit2_loss: 0.3789 - val_digit1_accuracy: 0.8936 - val_digit2_accuracy: 0.8721\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5276 - digit1_loss: 0.2469 - digit2_loss: 0.2807 - digit1_accuracy: 0.9163 - digit2_accuracy: 0.9041 - val_loss: 0.7214 - val_digit1_loss: 0.3358 - val_digit2_loss: 0.3856 - val_digit1_accuracy: 0.8908 - val_digit2_accuracy: 0.8742\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4649 - digit1_loss: 0.2179 - digit2_loss: 0.2470 - digit1_accuracy: 0.9252 - digit2_accuracy: 0.9165 - val_loss: 0.6871 - val_digit1_loss: 0.3278 - val_digit2_loss: 0.3593 - val_digit1_accuracy: 0.8904 - val_digit2_accuracy: 0.8829\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4099 - digit1_loss: 0.1944 - digit2_loss: 0.2155 - digit1_accuracy: 0.9326 - digit2_accuracy: 0.9257 - val_loss: 0.6686 - val_digit1_loss: 0.3163 - val_digit2_loss: 0.3522 - val_digit1_accuracy: 0.8992 - val_digit2_accuracy: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:01:50,983]\u001b[0m Trial 0 finished with value: 0.6685672998428345 and parameters: {'kernel_size': 5, 'num_filters': 77, 'dropout_rate': 0.23877066651573914}. Best is trial 0 with value: 0.6685672998428345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.2926 - digit1_loss: 1.5665 - digit2_loss: 1.7261 - digit1_accuracy: 0.4396 - digit2_accuracy: 0.3710 - val_loss: 2.0131 - val_digit1_loss: 0.9029 - val_digit2_loss: 1.1102 - val_digit1_accuracy: 0.6970 - val_digit2_accuracy: 0.6329\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9448 - digit1_loss: 0.9017 - digit2_loss: 1.0431 - digit1_accuracy: 0.6911 - digit2_accuracy: 0.6396 - val_loss: 1.3307 - val_digit1_loss: 0.6150 - val_digit2_loss: 0.7157 - val_digit1_accuracy: 0.8009 - val_digit2_accuracy: 0.7707\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4538 - digit1_loss: 0.6814 - digit2_loss: 0.7724 - digit1_accuracy: 0.7712 - digit2_accuracy: 0.7386 - val_loss: 1.0804 - val_digit1_loss: 0.4936 - val_digit2_loss: 0.5868 - val_digit1_accuracy: 0.8377 - val_digit2_accuracy: 0.8095\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1848 - digit1_loss: 0.5619 - digit2_loss: 0.6229 - digit1_accuracy: 0.8114 - digit2_accuracy: 0.7899 - val_loss: 0.8705 - val_digit1_loss: 0.4082 - val_digit2_loss: 0.4623 - val_digit1_accuracy: 0.8663 - val_digit2_accuracy: 0.8443\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9976 - digit1_loss: 0.4782 - digit2_loss: 0.5194 - digit1_accuracy: 0.8415 - digit2_accuracy: 0.8255 - val_loss: 0.7589 - val_digit1_loss: 0.3637 - val_digit2_loss: 0.3952 - val_digit1_accuracy: 0.8807 - val_digit2_accuracy: 0.8695\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8618 - digit1_loss: 0.4143 - digit2_loss: 0.4475 - digit1_accuracy: 0.8616 - digit2_accuracy: 0.8517 - val_loss: 0.7401 - val_digit1_loss: 0.3476 - val_digit2_loss: 0.3925 - val_digit1_accuracy: 0.8863 - val_digit2_accuracy: 0.8718\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7500 - digit1_loss: 0.3595 - digit2_loss: 0.3905 - digit1_accuracy: 0.8804 - digit2_accuracy: 0.8693 - val_loss: 0.6744 - val_digit1_loss: 0.3224 - val_digit2_loss: 0.3521 - val_digit1_accuracy: 0.8930 - val_digit2_accuracy: 0.8817\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6669 - digit1_loss: 0.3191 - digit2_loss: 0.3478 - digit1_accuracy: 0.8947 - digit2_accuracy: 0.8835 - val_loss: 0.6407 - val_digit1_loss: 0.3101 - val_digit2_loss: 0.3306 - val_digit1_accuracy: 0.8991 - val_digit2_accuracy: 0.8926\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5936 - digit1_loss: 0.2847 - digit2_loss: 0.3089 - digit1_accuracy: 0.9044 - digit2_accuracy: 0.8958 - val_loss: 0.6189 - val_digit1_loss: 0.2959 - val_digit2_loss: 0.3231 - val_digit1_accuracy: 0.9026 - val_digit2_accuracy: 0.8928\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5421 - digit1_loss: 0.2615 - digit2_loss: 0.2805 - digit1_accuracy: 0.9114 - digit2_accuracy: 0.9070 - val_loss: 0.6206 - val_digit1_loss: 0.3016 - val_digit2_loss: 0.3190 - val_digit1_accuracy: 0.9038 - val_digit2_accuracy: 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:02:28,840]\u001b[0m Trial 1 finished with value: 0.620613694190979 and parameters: {'kernel_size': 5, 'num_filters': 72, 'dropout_rate': 0.4859591705389539}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.7504 - digit1_loss: 1.7997 - digit2_loss: 1.9507 - digit1_accuracy: 0.3447 - digit2_accuracy: 0.2682 - val_loss: 2.9526 - val_digit1_loss: 1.3606 - val_digit2_loss: 1.5920 - val_digit1_accuracy: 0.5257 - val_digit2_accuracy: 0.4302\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.8381 - digit1_loss: 1.3215 - digit2_loss: 1.5166 - digit1_accuracy: 0.5308 - digit2_accuracy: 0.4437 - val_loss: 2.3280 - val_digit1_loss: 1.0631 - val_digit2_loss: 1.2649 - val_digit1_accuracy: 0.6370 - val_digit2_accuracy: 0.5578\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.4396 - digit1_loss: 1.1279 - digit2_loss: 1.3117 - digit1_accuracy: 0.5994 - digit2_accuracy: 0.5251 - val_loss: 2.0557 - val_digit1_loss: 0.9446 - val_digit2_loss: 1.1111 - val_digit1_accuracy: 0.6712 - val_digit2_accuracy: 0.6130\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.2073 - digit1_loss: 1.0225 - digit2_loss: 1.1848 - digit1_accuracy: 0.6359 - digit2_accuracy: 0.5722 - val_loss: 1.9259 - val_digit1_loss: 0.8853 - val_digit2_loss: 1.0406 - val_digit1_accuracy: 0.7006 - val_digit2_accuracy: 0.6432\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.0400 - digit1_loss: 0.9437 - digit2_loss: 1.0962 - digit1_accuracy: 0.6653 - digit2_accuracy: 0.6080 - val_loss: 1.7635 - val_digit1_loss: 0.8035 - val_digit2_loss: 0.9601 - val_digit1_accuracy: 0.7225 - val_digit2_accuracy: 0.6706\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.9004 - digit1_loss: 0.8788 - digit2_loss: 1.0216 - digit1_accuracy: 0.6894 - digit2_accuracy: 0.6336 - val_loss: 1.6780 - val_digit1_loss: 0.7643 - val_digit2_loss: 0.9137 - val_digit1_accuracy: 0.7340 - val_digit2_accuracy: 0.6846\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.7913 - digit1_loss: 0.8337 - digit2_loss: 0.9576 - digit1_accuracy: 0.7036 - digit2_accuracy: 0.6589 - val_loss: 1.5816 - val_digit1_loss: 0.7279 - val_digit2_loss: 0.8537 - val_digit1_accuracy: 0.7468 - val_digit2_accuracy: 0.7038\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.6857 - digit1_loss: 0.7840 - digit2_loss: 0.9017 - digit1_accuracy: 0.7218 - digit2_accuracy: 0.6786 - val_loss: 1.5279 - val_digit1_loss: 0.7033 - val_digit2_loss: 0.8246 - val_digit1_accuracy: 0.7558 - val_digit2_accuracy: 0.7107\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.6164 - digit1_loss: 0.7522 - digit2_loss: 0.8642 - digit1_accuracy: 0.7349 - digit2_accuracy: 0.6910 - val_loss: 1.4799 - val_digit1_loss: 0.6777 - val_digit2_loss: 0.8022 - val_digit1_accuracy: 0.7629 - val_digit2_accuracy: 0.7211\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.5379 - digit1_loss: 0.7171 - digit2_loss: 0.8208 - digit1_accuracy: 0.7440 - digit2_accuracy: 0.7058 - val_loss: 1.4879 - val_digit1_loss: 0.6934 - val_digit2_loss: 0.7946 - val_digit1_accuracy: 0.7563 - val_digit2_accuracy: 0.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:03:05,798]\u001b[0m Trial 2 finished with value: 1.4879261255264282 and parameters: {'kernel_size': 2, 'num_filters': 57, 'dropout_rate': 0.48599001187820906}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.3683 - digit1_loss: 1.6001 - digit2_loss: 1.7682 - digit1_accuracy: 0.4295 - digit2_accuracy: 0.3551 - val_loss: 2.5932 - val_digit1_loss: 1.1980 - val_digit2_loss: 1.3952 - val_digit1_accuracy: 0.5829 - val_digit2_accuracy: 0.5048\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2751 - digit1_loss: 1.0245 - digit2_loss: 1.2506 - digit1_accuracy: 0.6410 - digit2_accuracy: 0.5558 - val_loss: 1.9693 - val_digit1_loss: 0.8718 - val_digit2_loss: 1.0975 - val_digit1_accuracy: 0.6958 - val_digit2_accuracy: 0.6183\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.8584 - digit1_loss: 0.8334 - digit2_loss: 1.0249 - digit1_accuracy: 0.7083 - digit2_accuracy: 0.6422 - val_loss: 1.7563 - val_digit1_loss: 0.7729 - val_digit2_loss: 0.9834 - val_digit1_accuracy: 0.7322 - val_digit2_accuracy: 0.6568\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6044 - digit1_loss: 0.7199 - digit2_loss: 0.8845 - digit1_accuracy: 0.7489 - digit2_accuracy: 0.6917 - val_loss: 1.5851 - val_digit1_loss: 0.7108 - val_digit2_loss: 0.8743 - val_digit1_accuracy: 0.7539 - val_digit2_accuracy: 0.6988\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4278 - digit1_loss: 0.6457 - digit2_loss: 0.7821 - digit1_accuracy: 0.7746 - digit2_accuracy: 0.7276 - val_loss: 1.4583 - val_digit1_loss: 0.6359 - val_digit2_loss: 0.8223 - val_digit1_accuracy: 0.7767 - val_digit2_accuracy: 0.7169\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2967 - digit1_loss: 0.5902 - digit2_loss: 0.7064 - digit1_accuracy: 0.7953 - digit2_accuracy: 0.7548 - val_loss: 1.3368 - val_digit1_loss: 0.6093 - val_digit2_loss: 0.7276 - val_digit1_accuracy: 0.7853 - val_digit2_accuracy: 0.7502\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1989 - digit1_loss: 0.5480 - digit2_loss: 0.6509 - digit1_accuracy: 0.8105 - digit2_accuracy: 0.7748 - val_loss: 1.2855 - val_digit1_loss: 0.5880 - val_digit2_loss: 0.6975 - val_digit1_accuracy: 0.7925 - val_digit2_accuracy: 0.7592\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1098 - digit1_loss: 0.5092 - digit2_loss: 0.6006 - digit1_accuracy: 0.8221 - digit2_accuracy: 0.7927 - val_loss: 1.2183 - val_digit1_loss: 0.5533 - val_digit2_loss: 0.6650 - val_digit1_accuracy: 0.8097 - val_digit2_accuracy: 0.7735\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0365 - digit1_loss: 0.4746 - digit2_loss: 0.5619 - digit1_accuracy: 0.8361 - digit2_accuracy: 0.8063 - val_loss: 1.1823 - val_digit1_loss: 0.5429 - val_digit2_loss: 0.6394 - val_digit1_accuracy: 0.8094 - val_digit2_accuracy: 0.7803\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9757 - digit1_loss: 0.4493 - digit2_loss: 0.5264 - digit1_accuracy: 0.8426 - digit2_accuracy: 0.8175 - val_loss: 1.1659 - val_digit1_loss: 0.5450 - val_digit2_loss: 0.6209 - val_digit1_accuracy: 0.8130 - val_digit2_accuracy: 0.7836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:03:43,344]\u001b[0m Trial 3 finished with value: 1.1659303903579712 and parameters: {'kernel_size': 5, 'num_filters': 16, 'dropout_rate': 0.061920073546482934}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.8614 - digit1_loss: 1.8759 - digit2_loss: 1.9855 - digit1_accuracy: 0.3207 - digit2_accuracy: 0.2620 - val_loss: 3.1934 - val_digit1_loss: 1.4992 - val_digit2_loss: 1.6942 - val_digit1_accuracy: 0.4775 - val_digit2_accuracy: 0.4029\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.0668 - digit1_loss: 1.4412 - digit2_loss: 1.6255 - digit1_accuracy: 0.4983 - digit2_accuracy: 0.4227 - val_loss: 2.6854 - val_digit1_loss: 1.2419 - val_digit2_loss: 1.4435 - val_digit1_accuracy: 0.5673 - val_digit2_accuracy: 0.4942\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.7501 - digit1_loss: 1.2821 - digit2_loss: 1.4680 - digit1_accuracy: 0.5554 - digit2_accuracy: 0.4821 - val_loss: 2.4864 - val_digit1_loss: 1.1457 - val_digit2_loss: 1.3407 - val_digit1_accuracy: 0.6003 - val_digit2_accuracy: 0.5354\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.5695 - digit1_loss: 1.1998 - digit2_loss: 1.3696 - digit1_accuracy: 0.5864 - digit2_accuracy: 0.5202 - val_loss: 2.3697 - val_digit1_loss: 1.0886 - val_digit2_loss: 1.2810 - val_digit1_accuracy: 0.6274 - val_digit2_accuracy: 0.5526\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.4629 - digit1_loss: 1.1513 - digit2_loss: 1.3116 - digit1_accuracy: 0.6038 - digit2_accuracy: 0.5406 - val_loss: 2.2550 - val_digit1_loss: 1.0432 - val_digit2_loss: 1.2118 - val_digit1_accuracy: 0.6380 - val_digit2_accuracy: 0.5875\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.3663 - digit1_loss: 1.1032 - digit2_loss: 1.2631 - digit1_accuracy: 0.6194 - digit2_accuracy: 0.5569 - val_loss: 2.2151 - val_digit1_loss: 1.0321 - val_digit2_loss: 1.1829 - val_digit1_accuracy: 0.6432 - val_digit2_accuracy: 0.5918\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.2848 - digit1_loss: 1.0678 - digit2_loss: 1.2170 - digit1_accuracy: 0.6315 - digit2_accuracy: 0.5751 - val_loss: 2.1559 - val_digit1_loss: 1.0030 - val_digit2_loss: 1.1529 - val_digit1_accuracy: 0.6533 - val_digit2_accuracy: 0.6038\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.2240 - digit1_loss: 1.0427 - digit2_loss: 1.1813 - digit1_accuracy: 0.6384 - digit2_accuracy: 0.5882 - val_loss: 2.0880 - val_digit1_loss: 0.9751 - val_digit2_loss: 1.1129 - val_digit1_accuracy: 0.6647 - val_digit2_accuracy: 0.6175\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.1723 - digit1_loss: 1.0180 - digit2_loss: 1.1543 - digit1_accuracy: 0.6471 - digit2_accuracy: 0.5986 - val_loss: 2.0755 - val_digit1_loss: 0.9610 - val_digit2_loss: 1.1145 - val_digit1_accuracy: 0.6681 - val_digit2_accuracy: 0.6106\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.1315 - digit1_loss: 1.0008 - digit2_loss: 1.1306 - digit1_accuracy: 0.6554 - digit2_accuracy: 0.6057 - val_loss: 2.0236 - val_digit1_loss: 0.9437 - val_digit2_loss: 1.0799 - val_digit1_accuracy: 0.6732 - val_digit2_accuracy: 0.6288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:04:20,435]\u001b[0m Trial 4 finished with value: 2.023577928543091 and parameters: {'kernel_size': 4, 'num_filters': 13, 'dropout_rate': 0.49316059853800776}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.1514 - digit1_loss: 1.5146 - digit2_loss: 1.6368 - digit1_accuracy: 0.4634 - digit2_accuracy: 0.4099 - val_loss: 2.3108 - val_digit1_loss: 1.0834 - val_digit2_loss: 1.2274 - val_digit1_accuracy: 0.6267 - val_digit2_accuracy: 0.5819\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.1348 - digit1_loss: 1.0117 - digit2_loss: 1.1230 - digit1_accuracy: 0.6486 - digit2_accuracy: 0.6157 - val_loss: 1.8779 - val_digit1_loss: 0.8864 - val_digit2_loss: 0.9915 - val_digit1_accuracy: 0.6980 - val_digit2_accuracy: 0.6695\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7716 - digit1_loss: 0.8429 - digit2_loss: 0.9286 - digit1_accuracy: 0.7087 - digit2_accuracy: 0.6830 - val_loss: 1.6950 - val_digit1_loss: 0.8024 - val_digit2_loss: 0.8926 - val_digit1_accuracy: 0.7217 - val_digit2_accuracy: 0.7000\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5424 - digit1_loss: 0.7352 - digit2_loss: 0.8071 - digit1_accuracy: 0.7456 - digit2_accuracy: 0.7224 - val_loss: 1.5850 - val_digit1_loss: 0.7529 - val_digit2_loss: 0.8321 - val_digit1_accuracy: 0.7371 - val_digit2_accuracy: 0.7176\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3750 - digit1_loss: 0.6548 - digit2_loss: 0.7202 - digit1_accuracy: 0.7722 - digit2_accuracy: 0.7530 - val_loss: 1.5628 - val_digit1_loss: 0.7451 - val_digit2_loss: 0.8177 - val_digit1_accuracy: 0.7387 - val_digit2_accuracy: 0.7247\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2374 - digit1_loss: 0.5909 - digit2_loss: 0.6465 - digit1_accuracy: 0.7931 - digit2_accuracy: 0.7765 - val_loss: 1.5476 - val_digit1_loss: 0.7432 - val_digit2_loss: 0.8044 - val_digit1_accuracy: 0.7408 - val_digit2_accuracy: 0.7342\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1142 - digit1_loss: 0.5297 - digit2_loss: 0.5845 - digit1_accuracy: 0.8142 - digit2_accuracy: 0.7985 - val_loss: 1.4756 - val_digit1_loss: 0.7159 - val_digit2_loss: 0.7597 - val_digit1_accuracy: 0.7477 - val_digit2_accuracy: 0.7467\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0055 - digit1_loss: 0.4785 - digit2_loss: 0.5270 - digit1_accuracy: 0.8310 - digit2_accuracy: 0.8177 - val_loss: 1.5477 - val_digit1_loss: 0.7463 - val_digit2_loss: 0.8014 - val_digit1_accuracy: 0.7568 - val_digit2_accuracy: 0.7411\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9202 - digit1_loss: 0.4388 - digit2_loss: 0.4814 - digit1_accuracy: 0.8468 - digit2_accuracy: 0.8322 - val_loss: 1.4932 - val_digit1_loss: 0.7248 - val_digit2_loss: 0.7684 - val_digit1_accuracy: 0.7582 - val_digit2_accuracy: 0.7530\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8313 - digit1_loss: 0.3968 - digit2_loss: 0.4345 - digit1_accuracy: 0.8605 - digit2_accuracy: 0.8483 - val_loss: 1.5751 - val_digit1_loss: 0.7690 - val_digit2_loss: 0.8061 - val_digit1_accuracy: 0.7551 - val_digit2_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:05:00,645]\u001b[0m Trial 5 finished with value: 1.5751451253890991 and parameters: {'kernel_size': 4, 'num_filters': 103, 'dropout_rate': 0.10229007658591016}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.7412 - digit1_loss: 1.7910 - digit2_loss: 1.9502 - digit1_accuracy: 0.3563 - digit2_accuracy: 0.2686 - val_loss: 3.1117 - val_digit1_loss: 1.4413 - val_digit2_loss: 1.6705 - val_digit1_accuracy: 0.4948 - val_digit2_accuracy: 0.4017\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.8636 - digit1_loss: 1.3339 - digit2_loss: 1.5297 - digit1_accuracy: 0.5275 - digit2_accuracy: 0.4434 - val_loss: 2.4356 - val_digit1_loss: 1.1207 - val_digit2_loss: 1.3149 - val_digit1_accuracy: 0.6008 - val_digit2_accuracy: 0.5378\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.4530 - digit1_loss: 1.1397 - digit2_loss: 1.3132 - digit1_accuracy: 0.5985 - digit2_accuracy: 0.5267 - val_loss: 2.1840 - val_digit1_loss: 1.0106 - val_digit2_loss: 1.1734 - val_digit1_accuracy: 0.6438 - val_digit2_accuracy: 0.5859\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.2248 - digit1_loss: 1.0281 - digit2_loss: 1.1967 - digit1_accuracy: 0.6353 - digit2_accuracy: 0.5703 - val_loss: 2.0111 - val_digit1_loss: 0.9162 - val_digit2_loss: 1.0949 - val_digit1_accuracy: 0.6805 - val_digit2_accuracy: 0.6193\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.0563 - digit1_loss: 0.9501 - digit2_loss: 1.1062 - digit1_accuracy: 0.6642 - digit2_accuracy: 0.6037 - val_loss: 1.8853 - val_digit1_loss: 0.8726 - val_digit2_loss: 1.0127 - val_digit1_accuracy: 0.6950 - val_digit2_accuracy: 0.6462\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.9157 - digit1_loss: 0.8826 - digit2_loss: 1.0331 - digit1_accuracy: 0.6880 - digit2_accuracy: 0.6283 - val_loss: 1.7827 - val_digit1_loss: 0.8159 - val_digit2_loss: 0.9669 - val_digit1_accuracy: 0.7197 - val_digit2_accuracy: 0.6592\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.8022 - digit1_loss: 0.8302 - digit2_loss: 0.9720 - digit1_accuracy: 0.7030 - digit2_accuracy: 0.6529 - val_loss: 1.7162 - val_digit1_loss: 0.7925 - val_digit2_loss: 0.9237 - val_digit1_accuracy: 0.7286 - val_digit2_accuracy: 0.6796\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.7169 - digit1_loss: 0.7938 - digit2_loss: 0.9231 - digit1_accuracy: 0.7189 - digit2_accuracy: 0.6695 - val_loss: 1.6805 - val_digit1_loss: 0.7872 - val_digit2_loss: 0.8933 - val_digit1_accuracy: 0.7314 - val_digit2_accuracy: 0.6904\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.6307 - digit1_loss: 0.7531 - digit2_loss: 0.8776 - digit1_accuracy: 0.7334 - digit2_accuracy: 0.6857 - val_loss: 1.6476 - val_digit1_loss: 0.7508 - val_digit2_loss: 0.8968 - val_digit1_accuracy: 0.7398 - val_digit2_accuracy: 0.6830\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.5593 - digit1_loss: 0.7201 - digit2_loss: 0.8392 - digit1_accuracy: 0.7456 - digit2_accuracy: 0.7015 - val_loss: 1.6114 - val_digit1_loss: 0.7435 - val_digit2_loss: 0.8679 - val_digit1_accuracy: 0.7434 - val_digit2_accuracy: 0.6901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:05:36,978]\u001b[0m Trial 6 finished with value: 1.611404299736023 and parameters: {'kernel_size': 2, 'num_filters': 26, 'dropout_rate': 0.3478178592746605}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.7078 - digit1_loss: 1.7734 - digit2_loss: 1.9344 - digit1_accuracy: 0.3555 - digit2_accuracy: 0.2764 - val_loss: 2.8159 - val_digit1_loss: 1.2863 - val_digit2_loss: 1.5296 - val_digit1_accuracy: 0.5507 - val_digit2_accuracy: 0.4551\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.7591 - digit1_loss: 1.2834 - digit2_loss: 1.4757 - digit1_accuracy: 0.5432 - digit2_accuracy: 0.4659 - val_loss: 2.2404 - val_digit1_loss: 1.0235 - val_digit2_loss: 1.2170 - val_digit1_accuracy: 0.6482 - val_digit2_accuracy: 0.5753\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.3721 - digit1_loss: 1.0980 - digit2_loss: 1.2741 - digit1_accuracy: 0.6113 - digit2_accuracy: 0.5385 - val_loss: 2.0045 - val_digit1_loss: 0.9276 - val_digit2_loss: 1.0769 - val_digit1_accuracy: 0.6820 - val_digit2_accuracy: 0.6254\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.1501 - digit1_loss: 0.9959 - digit2_loss: 1.1542 - digit1_accuracy: 0.6437 - digit2_accuracy: 0.5837 - val_loss: 1.7846 - val_digit1_loss: 0.8127 - val_digit2_loss: 0.9719 - val_digit1_accuracy: 0.7195 - val_digit2_accuracy: 0.6683\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9767 - digit1_loss: 0.9178 - digit2_loss: 1.0589 - digit1_accuracy: 0.6738 - digit2_accuracy: 0.6202 - val_loss: 1.6820 - val_digit1_loss: 0.7716 - val_digit2_loss: 0.9104 - val_digit1_accuracy: 0.7379 - val_digit2_accuracy: 0.6888\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8349 - digit1_loss: 0.8552 - digit2_loss: 0.9798 - digit1_accuracy: 0.6987 - digit2_accuracy: 0.6499 - val_loss: 1.6002 - val_digit1_loss: 0.7291 - val_digit2_loss: 0.8711 - val_digit1_accuracy: 0.7513 - val_digit2_accuracy: 0.6939\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7053 - digit1_loss: 0.7951 - digit2_loss: 0.9103 - digit1_accuracy: 0.7192 - digit2_accuracy: 0.6749 - val_loss: 1.5414 - val_digit1_loss: 0.7119 - val_digit2_loss: 0.8295 - val_digit1_accuracy: 0.7542 - val_digit2_accuracy: 0.7107\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6075 - digit1_loss: 0.7511 - digit2_loss: 0.8564 - digit1_accuracy: 0.7327 - digit2_accuracy: 0.6949 - val_loss: 1.4805 - val_digit1_loss: 0.6895 - val_digit2_loss: 0.7910 - val_digit1_accuracy: 0.7609 - val_digit2_accuracy: 0.7225\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5288 - digit1_loss: 0.7171 - digit2_loss: 0.8117 - digit1_accuracy: 0.7457 - digit2_accuracy: 0.7101 - val_loss: 1.4430 - val_digit1_loss: 0.6639 - val_digit2_loss: 0.7791 - val_digit1_accuracy: 0.7717 - val_digit2_accuracy: 0.7312\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4443 - digit1_loss: 0.6758 - digit2_loss: 0.7685 - digit1_accuracy: 0.7569 - digit2_accuracy: 0.7262 - val_loss: 1.3684 - val_digit1_loss: 0.6335 - val_digit2_loss: 0.7349 - val_digit1_accuracy: 0.7833 - val_digit2_accuracy: 0.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:06:15,084]\u001b[0m Trial 7 finished with value: 1.368417501449585 and parameters: {'kernel_size': 2, 'num_filters': 65, 'dropout_rate': 0.48083744459077193}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.6935 - digit1_loss: 1.7792 - digit2_loss: 1.9143 - digit1_accuracy: 0.3518 - digit2_accuracy: 0.2867 - val_loss: 2.9248 - val_digit1_loss: 1.3642 - val_digit2_loss: 1.5605 - val_digit1_accuracy: 0.5191 - val_digit2_accuracy: 0.4413\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.8232 - digit1_loss: 1.3271 - digit2_loss: 1.4961 - digit1_accuracy: 0.5238 - digit2_accuracy: 0.4514 - val_loss: 2.3489 - val_digit1_loss: 1.0879 - val_digit2_loss: 1.2610 - val_digit1_accuracy: 0.6221 - val_digit2_accuracy: 0.5642\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.4387 - digit1_loss: 1.1379 - digit2_loss: 1.3009 - digit1_accuracy: 0.5953 - digit2_accuracy: 0.5236 - val_loss: 2.0879 - val_digit1_loss: 0.9590 - val_digit2_loss: 1.1289 - val_digit1_accuracy: 0.6651 - val_digit2_accuracy: 0.6028\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2075 - digit1_loss: 1.0311 - digit2_loss: 1.1764 - digit1_accuracy: 0.6340 - digit2_accuracy: 0.5706 - val_loss: 1.9327 - val_digit1_loss: 0.8884 - val_digit2_loss: 1.0443 - val_digit1_accuracy: 0.6907 - val_digit2_accuracy: 0.6331\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.0328 - digit1_loss: 0.9501 - digit2_loss: 1.0827 - digit1_accuracy: 0.6624 - digit2_accuracy: 0.6072 - val_loss: 1.7837 - val_digit1_loss: 0.8280 - val_digit2_loss: 0.9557 - val_digit1_accuracy: 0.7133 - val_digit2_accuracy: 0.6691\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8922 - digit1_loss: 0.8845 - digit2_loss: 1.0077 - digit1_accuracy: 0.6845 - digit2_accuracy: 0.6389 - val_loss: 1.6864 - val_digit1_loss: 0.7898 - val_digit2_loss: 0.8966 - val_digit1_accuracy: 0.7280 - val_digit2_accuracy: 0.6960\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7693 - digit1_loss: 0.8332 - digit2_loss: 0.9361 - digit1_accuracy: 0.7037 - digit2_accuracy: 0.6622 - val_loss: 1.5938 - val_digit1_loss: 0.7452 - val_digit2_loss: 0.8485 - val_digit1_accuracy: 0.7456 - val_digit2_accuracy: 0.7095\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6644 - digit1_loss: 0.7822 - digit2_loss: 0.8822 - digit1_accuracy: 0.7199 - digit2_accuracy: 0.6833 - val_loss: 1.5386 - val_digit1_loss: 0.7189 - val_digit2_loss: 0.8197 - val_digit1_accuracy: 0.7518 - val_digit2_accuracy: 0.7183\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5743 - digit1_loss: 0.7425 - digit2_loss: 0.8318 - digit1_accuracy: 0.7354 - digit2_accuracy: 0.7020 - val_loss: 1.4925 - val_digit1_loss: 0.7066 - val_digit2_loss: 0.7859 - val_digit1_accuracy: 0.7531 - val_digit2_accuracy: 0.7272\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4912 - digit1_loss: 0.7015 - digit2_loss: 0.7897 - digit1_accuracy: 0.7487 - digit2_accuracy: 0.7171 - val_loss: 1.4707 - val_digit1_loss: 0.6869 - val_digit2_loss: 0.7839 - val_digit1_accuracy: 0.7628 - val_digit2_accuracy: 0.7283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:06:53,128]\u001b[0m Trial 8 finished with value: 1.4707485437393188 and parameters: {'kernel_size': 2, 'num_filters': 64, 'dropout_rate': 0.36086401824876335}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.3254 - digit1_loss: 1.5713 - digit2_loss: 1.7541 - digit1_accuracy: 0.4350 - digit2_accuracy: 0.3556 - val_loss: 2.3293 - val_digit1_loss: 1.0545 - val_digit2_loss: 1.2749 - val_digit1_accuracy: 0.6247 - val_digit2_accuracy: 0.5494\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.1318 - digit1_loss: 0.9553 - digit2_loss: 1.1766 - digit1_accuracy: 0.6682 - digit2_accuracy: 0.5825 - val_loss: 1.7758 - val_digit1_loss: 0.7863 - val_digit2_loss: 0.9895 - val_digit1_accuracy: 0.7237 - val_digit2_accuracy: 0.6626\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7143 - digit1_loss: 0.7720 - digit2_loss: 0.9423 - digit1_accuracy: 0.7340 - digit2_accuracy: 0.6728 - val_loss: 1.4637 - val_digit1_loss: 0.6480 - val_digit2_loss: 0.8157 - val_digit1_accuracy: 0.7742 - val_digit2_accuracy: 0.7243\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4789 - digit1_loss: 0.6679 - digit2_loss: 0.8110 - digit1_accuracy: 0.7699 - digit2_accuracy: 0.7173 - val_loss: 1.3407 - val_digit1_loss: 0.6159 - val_digit2_loss: 0.7248 - val_digit1_accuracy: 0.7832 - val_digit2_accuracy: 0.7532\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3157 - digit1_loss: 0.5941 - digit2_loss: 0.7216 - digit1_accuracy: 0.7968 - digit2_accuracy: 0.7507 - val_loss: 1.2615 - val_digit1_loss: 0.5665 - val_digit2_loss: 0.6951 - val_digit1_accuracy: 0.8040 - val_digit2_accuracy: 0.7616\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1885 - digit1_loss: 0.5355 - digit2_loss: 0.6530 - digit1_accuracy: 0.8160 - digit2_accuracy: 0.7732 - val_loss: 1.1388 - val_digit1_loss: 0.5221 - val_digit2_loss: 0.6167 - val_digit1_accuracy: 0.8203 - val_digit2_accuracy: 0.7892\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.0765 - digit1_loss: 0.4888 - digit2_loss: 0.5877 - digit1_accuracy: 0.8315 - digit2_accuracy: 0.7987 - val_loss: 1.0957 - val_digit1_loss: 0.5097 - val_digit2_loss: 0.5860 - val_digit1_accuracy: 0.8275 - val_digit2_accuracy: 0.7995\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9975 - digit1_loss: 0.4544 - digit2_loss: 0.5430 - digit1_accuracy: 0.8443 - digit2_accuracy: 0.8132 - val_loss: 1.0157 - val_digit1_loss: 0.4723 - val_digit2_loss: 0.5435 - val_digit1_accuracy: 0.8372 - val_digit2_accuracy: 0.8113\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9287 - digit1_loss: 0.4204 - digit2_loss: 0.5083 - digit1_accuracy: 0.8566 - digit2_accuracy: 0.8248 - val_loss: 0.9843 - val_digit1_loss: 0.4551 - val_digit2_loss: 0.5292 - val_digit1_accuracy: 0.8459 - val_digit2_accuracy: 0.8192\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8700 - digit1_loss: 0.3940 - digit2_loss: 0.4760 - digit1_accuracy: 0.8661 - digit2_accuracy: 0.8368 - val_loss: 0.9547 - val_digit1_loss: 0.4389 - val_digit2_loss: 0.5158 - val_digit1_accuracy: 0.8493 - val_digit2_accuracy: 0.8199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:07:30,706]\u001b[0m Trial 9 finished with value: 0.95468670129776 and parameters: {'kernel_size': 5, 'num_filters': 23, 'dropout_rate': 0.23384498103422685}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.3126 - digit1_loss: 1.5860 - digit2_loss: 1.7266 - digit1_accuracy: 0.4329 - digit2_accuracy: 0.3678 - val_loss: 2.2648 - val_digit1_loss: 1.0511 - val_digit2_loss: 1.2137 - val_digit1_accuracy: 0.6377 - val_digit2_accuracy: 0.5842\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2319 - digit1_loss: 1.0497 - digit2_loss: 1.1822 - digit1_accuracy: 0.6363 - digit2_accuracy: 0.5838 - val_loss: 1.8513 - val_digit1_loss: 0.8759 - val_digit2_loss: 0.9754 - val_digit1_accuracy: 0.7005 - val_digit2_accuracy: 0.6730\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8461 - digit1_loss: 0.8704 - digit2_loss: 0.9757 - digit1_accuracy: 0.7000 - digit2_accuracy: 0.6620 - val_loss: 1.5548 - val_digit1_loss: 0.7410 - val_digit2_loss: 0.8139 - val_digit1_accuracy: 0.7466 - val_digit2_accuracy: 0.7258\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6120 - digit1_loss: 0.7633 - digit2_loss: 0.8487 - digit1_accuracy: 0.7382 - digit2_accuracy: 0.7097 - val_loss: 1.3902 - val_digit1_loss: 0.6473 - val_digit2_loss: 0.7429 - val_digit1_accuracy: 0.7801 - val_digit2_accuracy: 0.7493\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4416 - digit1_loss: 0.6874 - digit2_loss: 0.7542 - digit1_accuracy: 0.7646 - digit2_accuracy: 0.7417 - val_loss: 1.2872 - val_digit1_loss: 0.6130 - val_digit2_loss: 0.6742 - val_digit1_accuracy: 0.7859 - val_digit2_accuracy: 0.7714\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2989 - digit1_loss: 0.6177 - digit2_loss: 0.6812 - digit1_accuracy: 0.7856 - digit2_accuracy: 0.7666 - val_loss: 1.3021 - val_digit1_loss: 0.6186 - val_digit2_loss: 0.6834 - val_digit1_accuracy: 0.7862 - val_digit2_accuracy: 0.7681\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1943 - digit1_loss: 0.5645 - digit2_loss: 0.6298 - digit1_accuracy: 0.8055 - digit2_accuracy: 0.7841 - val_loss: 1.2341 - val_digit1_loss: 0.5779 - val_digit2_loss: 0.6562 - val_digit1_accuracy: 0.7977 - val_digit2_accuracy: 0.7763\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1101 - digit1_loss: 0.5272 - digit2_loss: 0.5829 - digit1_accuracy: 0.8162 - digit2_accuracy: 0.8002 - val_loss: 1.2374 - val_digit1_loss: 0.5727 - val_digit2_loss: 0.6647 - val_digit1_accuracy: 0.8018 - val_digit2_accuracy: 0.7790\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0258 - digit1_loss: 0.4820 - digit2_loss: 0.5438 - digit1_accuracy: 0.8327 - digit2_accuracy: 0.8116 - val_loss: 1.1804 - val_digit1_loss: 0.5535 - val_digit2_loss: 0.6270 - val_digit1_accuracy: 0.8091 - val_digit2_accuracy: 0.7887\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9621 - digit1_loss: 0.4554 - digit2_loss: 0.5067 - digit1_accuracy: 0.8419 - digit2_accuracy: 0.8238 - val_loss: 1.1603 - val_digit1_loss: 0.5572 - val_digit2_loss: 0.6031 - val_digit1_accuracy: 0.8150 - val_digit2_accuracy: 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:08:09,563]\u001b[0m Trial 10 finished with value: 1.1603058576583862 and parameters: {'kernel_size': 3, 'num_filters': 128, 'dropout_rate': 0.3556964224280015}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 2.8149 - digit1_loss: 1.3354 - digit2_loss: 1.4795 - digit1_accuracy: 0.5268 - digit2_accuracy: 0.4689 - val_loss: 1.6082 - val_digit1_loss: 0.7453 - val_digit2_loss: 0.8629 - val_digit1_accuracy: 0.7477 - val_digit2_accuracy: 0.7104\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4189 - digit1_loss: 0.6615 - digit2_loss: 0.7574 - digit1_accuracy: 0.7749 - digit2_accuracy: 0.7421 - val_loss: 1.2477 - val_digit1_loss: 0.5676 - val_digit2_loss: 0.6800 - val_digit1_accuracy: 0.8043 - val_digit2_accuracy: 0.7750\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0165 - digit1_loss: 0.4776 - digit2_loss: 0.5389 - digit1_accuracy: 0.8404 - digit2_accuracy: 0.8183 - val_loss: 0.8445 - val_digit1_loss: 0.3984 - val_digit2_loss: 0.4462 - val_digit1_accuracy: 0.8671 - val_digit2_accuracy: 0.8509\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7836 - digit1_loss: 0.3702 - digit2_loss: 0.4134 - digit1_accuracy: 0.8751 - digit2_accuracy: 0.8614 - val_loss: 0.7562 - val_digit1_loss: 0.3638 - val_digit2_loss: 0.3923 - val_digit1_accuracy: 0.8781 - val_digit2_accuracy: 0.8679\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6375 - digit1_loss: 0.3019 - digit2_loss: 0.3356 - digit1_accuracy: 0.8979 - digit2_accuracy: 0.8888 - val_loss: 0.6921 - val_digit1_loss: 0.3274 - val_digit2_loss: 0.3647 - val_digit1_accuracy: 0.8894 - val_digit2_accuracy: 0.8749\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5274 - digit1_loss: 0.2506 - digit2_loss: 0.2768 - digit1_accuracy: 0.9144 - digit2_accuracy: 0.9069 - val_loss: 0.6435 - val_digit1_loss: 0.3089 - val_digit2_loss: 0.3346 - val_digit1_accuracy: 0.8962 - val_digit2_accuracy: 0.8872\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4406 - digit1_loss: 0.2109 - digit2_loss: 0.2297 - digit1_accuracy: 0.9279 - digit2_accuracy: 0.9222 - val_loss: 0.6279 - val_digit1_loss: 0.3010 - val_digit2_loss: 0.3270 - val_digit1_accuracy: 0.9009 - val_digit2_accuracy: 0.8909\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3746 - digit1_loss: 0.1776 - digit2_loss: 0.1970 - digit1_accuracy: 0.9384 - digit2_accuracy: 0.9331 - val_loss: 0.6482 - val_digit1_loss: 0.3096 - val_digit2_loss: 0.3386 - val_digit1_accuracy: 0.9016 - val_digit2_accuracy: 0.8905\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3238 - digit1_loss: 0.1538 - digit2_loss: 0.1700 - digit1_accuracy: 0.9476 - digit2_accuracy: 0.9414 - val_loss: 0.6591 - val_digit1_loss: 0.3157 - val_digit2_loss: 0.3434 - val_digit1_accuracy: 0.9021 - val_digit2_accuracy: 0.8912\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.2810 - digit1_loss: 0.1347 - digit2_loss: 0.1463 - digit1_accuracy: 0.9534 - digit2_accuracy: 0.9505 - val_loss: 0.7192 - val_digit1_loss: 0.3318 - val_digit2_loss: 0.3873 - val_digit1_accuracy: 0.9019 - val_digit2_accuracy: 0.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:08:48,779]\u001b[0m Trial 11 finished with value: 0.7191789746284485 and parameters: {'kernel_size': 5, 'num_filters': 90, 'dropout_rate': 0.19151713784768146}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.3116 - digit1_loss: 1.5952 - digit2_loss: 1.7164 - digit1_accuracy: 0.4305 - digit2_accuracy: 0.3844 - val_loss: 2.4488 - val_digit1_loss: 1.1466 - val_digit2_loss: 1.3022 - val_digit1_accuracy: 0.6113 - val_digit2_accuracy: 0.5541\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2878 - digit1_loss: 1.0854 - digit2_loss: 1.2023 - digit1_accuracy: 0.6232 - digit2_accuracy: 0.5833 - val_loss: 2.0036 - val_digit1_loss: 0.9588 - val_digit2_loss: 1.0448 - val_digit1_accuracy: 0.6672 - val_digit2_accuracy: 0.6485\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9170 - digit1_loss: 0.9154 - digit2_loss: 1.0016 - digit1_accuracy: 0.6818 - digit2_accuracy: 0.6565 - val_loss: 1.7704 - val_digit1_loss: 0.8365 - val_digit2_loss: 0.9339 - val_digit1_accuracy: 0.7057 - val_digit2_accuracy: 0.6849\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6815 - digit1_loss: 0.8047 - digit2_loss: 0.8768 - digit1_accuracy: 0.7216 - digit2_accuracy: 0.7003 - val_loss: 1.6433 - val_digit1_loss: 0.7714 - val_digit2_loss: 0.8719 - val_digit1_accuracy: 0.7296 - val_digit2_accuracy: 0.6992\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5145 - digit1_loss: 0.7267 - digit2_loss: 0.7879 - digit1_accuracy: 0.7500 - digit2_accuracy: 0.7303 - val_loss: 1.6386 - val_digit1_loss: 0.8165 - val_digit2_loss: 0.8221 - val_digit1_accuracy: 0.7123 - val_digit2_accuracy: 0.7187\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3874 - digit1_loss: 0.6686 - digit2_loss: 0.7188 - digit1_accuracy: 0.7692 - digit2_accuracy: 0.7515 - val_loss: 1.4743 - val_digit1_loss: 0.7038 - val_digit2_loss: 0.7705 - val_digit1_accuracy: 0.7552 - val_digit2_accuracy: 0.7401\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2717 - digit1_loss: 0.6115 - digit2_loss: 0.6601 - digit1_accuracy: 0.7884 - digit2_accuracy: 0.7726 - val_loss: 1.5026 - val_digit1_loss: 0.7239 - val_digit2_loss: 0.7787 - val_digit1_accuracy: 0.7533 - val_digit2_accuracy: 0.7296\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1778 - digit1_loss: 0.5656 - digit2_loss: 0.6122 - digit1_accuracy: 0.8056 - digit2_accuracy: 0.7888 - val_loss: 1.4397 - val_digit1_loss: 0.6990 - val_digit2_loss: 0.7407 - val_digit1_accuracy: 0.7559 - val_digit2_accuracy: 0.7498\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0935 - digit1_loss: 0.5294 - digit2_loss: 0.5641 - digit1_accuracy: 0.8147 - digit2_accuracy: 0.8034 - val_loss: 1.4438 - val_digit1_loss: 0.6935 - val_digit2_loss: 0.7503 - val_digit1_accuracy: 0.7627 - val_digit2_accuracy: 0.7503\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0195 - digit1_loss: 0.4893 - digit2_loss: 0.5302 - digit1_accuracy: 0.8282 - digit2_accuracy: 0.8144 - val_loss: 1.4748 - val_digit1_loss: 0.7102 - val_digit2_loss: 0.7646 - val_digit1_accuracy: 0.7669 - val_digit2_accuracy: 0.7447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:09:28,729]\u001b[0m Trial 12 finished with value: 1.4748495817184448 and parameters: {'kernel_size': 4, 'num_filters': 91, 'dropout_rate': 0.16507358499512192}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.3215 - digit1_loss: 1.5748 - digit2_loss: 1.7466 - digit1_accuracy: 0.4354 - digit2_accuracy: 0.3576 - val_loss: 2.1967 - val_digit1_loss: 0.9765 - val_digit2_loss: 1.2202 - val_digit1_accuracy: 0.6685 - val_digit2_accuracy: 0.5789\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.0447 - digit1_loss: 0.9261 - digit2_loss: 1.1186 - digit1_accuracy: 0.6806 - digit2_accuracy: 0.6074 - val_loss: 1.5712 - val_digit1_loss: 0.6867 - val_digit2_loss: 0.8844 - val_digit1_accuracy: 0.7638 - val_digit2_accuracy: 0.7025\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5575 - digit1_loss: 0.7122 - digit2_loss: 0.8453 - digit1_accuracy: 0.7532 - digit2_accuracy: 0.7083 - val_loss: 1.2486 - val_digit1_loss: 0.5770 - val_digit2_loss: 0.6716 - val_digit1_accuracy: 0.8048 - val_digit2_accuracy: 0.7774\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2928 - digit1_loss: 0.5970 - digit2_loss: 0.6958 - digit1_accuracy: 0.7948 - digit2_accuracy: 0.7644 - val_loss: 1.0742 - val_digit1_loss: 0.4888 - val_digit2_loss: 0.5854 - val_digit1_accuracy: 0.8366 - val_digit2_accuracy: 0.8047\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.1100 - digit1_loss: 0.5159 - digit2_loss: 0.5941 - digit1_accuracy: 0.8240 - digit2_accuracy: 0.7976 - val_loss: 0.9464 - val_digit1_loss: 0.4409 - val_digit2_loss: 0.5055 - val_digit1_accuracy: 0.8503 - val_digit2_accuracy: 0.8315\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9826 - digit1_loss: 0.4574 - digit2_loss: 0.5253 - digit1_accuracy: 0.8439 - digit2_accuracy: 0.8214 - val_loss: 0.8997 - val_digit1_loss: 0.4213 - val_digit2_loss: 0.4784 - val_digit1_accuracy: 0.8545 - val_digit2_accuracy: 0.8367\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8691 - digit1_loss: 0.4055 - digit2_loss: 0.4636 - digit1_accuracy: 0.8612 - digit2_accuracy: 0.8424 - val_loss: 0.8430 - val_digit1_loss: 0.3956 - val_digit2_loss: 0.4474 - val_digit1_accuracy: 0.8621 - val_digit2_accuracy: 0.8475\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7947 - digit1_loss: 0.3704 - digit2_loss: 0.4243 - digit1_accuracy: 0.8714 - digit2_accuracy: 0.8550 - val_loss: 0.8121 - val_digit1_loss: 0.3800 - val_digit2_loss: 0.4321 - val_digit1_accuracy: 0.8701 - val_digit2_accuracy: 0.8534\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7142 - digit1_loss: 0.3314 - digit2_loss: 0.3827 - digit1_accuracy: 0.8854 - digit2_accuracy: 0.8694 - val_loss: 0.8098 - val_digit1_loss: 0.3736 - val_digit2_loss: 0.4361 - val_digit1_accuracy: 0.8741 - val_digit2_accuracy: 0.8526\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6478 - digit1_loss: 0.3031 - digit2_loss: 0.3446 - digit1_accuracy: 0.8947 - digit2_accuracy: 0.8824 - val_loss: 0.9045 - val_digit1_loss: 0.4397 - val_digit2_loss: 0.4648 - val_digit1_accuracy: 0.8587 - val_digit2_accuracy: 0.8489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:10:06,350]\u001b[0m Trial 13 finished with value: 0.904519259929657 and parameters: {'kernel_size': 5, 'num_filters': 45, 'dropout_rate': 0.3106540379679537}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.2926 - digit1_loss: 1.5748 - digit2_loss: 1.7178 - digit1_accuracy: 0.4331 - digit2_accuracy: 0.3728 - val_loss: 2.3941 - val_digit1_loss: 1.1063 - val_digit2_loss: 1.2878 - val_digit1_accuracy: 0.6155 - val_digit2_accuracy: 0.5474\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2660 - digit1_loss: 1.0634 - digit2_loss: 1.2026 - digit1_accuracy: 0.6290 - digit2_accuracy: 0.5749 - val_loss: 1.8787 - val_digit1_loss: 0.8738 - val_digit2_loss: 1.0049 - val_digit1_accuracy: 0.6995 - val_digit2_accuracy: 0.6531\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8727 - digit1_loss: 0.8782 - digit2_loss: 0.9945 - digit1_accuracy: 0.6928 - digit2_accuracy: 0.6513 - val_loss: 1.6108 - val_digit1_loss: 0.7598 - val_digit2_loss: 0.8510 - val_digit1_accuracy: 0.7357 - val_digit2_accuracy: 0.7090\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6420 - digit1_loss: 0.7721 - digit2_loss: 0.8699 - digit1_accuracy: 0.7323 - digit2_accuracy: 0.6983 - val_loss: 1.4773 - val_digit1_loss: 0.6914 - val_digit2_loss: 0.7859 - val_digit1_accuracy: 0.7562 - val_digit2_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4622 - digit1_loss: 0.6850 - digit2_loss: 0.7773 - digit1_accuracy: 0.7637 - digit2_accuracy: 0.7316 - val_loss: 1.3928 - val_digit1_loss: 0.6527 - val_digit2_loss: 0.7402 - val_digit1_accuracy: 0.7717 - val_digit2_accuracy: 0.7468\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3335 - digit1_loss: 0.6270 - digit2_loss: 0.7066 - digit1_accuracy: 0.7812 - digit2_accuracy: 0.7543 - val_loss: 1.3358 - val_digit1_loss: 0.6332 - val_digit2_loss: 0.7026 - val_digit1_accuracy: 0.7783 - val_digit2_accuracy: 0.7594\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2206 - digit1_loss: 0.5744 - digit2_loss: 0.6462 - digit1_accuracy: 0.8001 - digit2_accuracy: 0.7764 - val_loss: 1.2719 - val_digit1_loss: 0.5976 - val_digit2_loss: 0.6743 - val_digit1_accuracy: 0.7937 - val_digit2_accuracy: 0.7732\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1202 - digit1_loss: 0.5254 - digit2_loss: 0.5948 - digit1_accuracy: 0.8175 - digit2_accuracy: 0.7931 - val_loss: 1.2848 - val_digit1_loss: 0.6034 - val_digit2_loss: 0.6814 - val_digit1_accuracy: 0.7906 - val_digit2_accuracy: 0.7661\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0429 - digit1_loss: 0.4870 - digit2_loss: 0.5560 - digit1_accuracy: 0.8279 - digit2_accuracy: 0.8058 - val_loss: 1.1998 - val_digit1_loss: 0.5676 - val_digit2_loss: 0.6322 - val_digit1_accuracy: 0.7998 - val_digit2_accuracy: 0.7846\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9677 - digit1_loss: 0.4542 - digit2_loss: 0.5135 - digit1_accuracy: 0.8395 - digit2_accuracy: 0.8205 - val_loss: 1.2297 - val_digit1_loss: 0.5794 - val_digit2_loss: 0.6503 - val_digit1_accuracy: 0.8025 - val_digit2_accuracy: 0.7795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:10:44,944]\u001b[0m Trial 14 finished with value: 1.2296996116638184 and parameters: {'kernel_size': 3, 'num_filters': 79, 'dropout_rate': 0.28153227026852096}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.5943 - digit1_loss: 1.7249 - digit2_loss: 1.8695 - digit1_accuracy: 0.3835 - digit2_accuracy: 0.3131 - val_loss: 2.8092 - val_digit1_loss: 1.3024 - val_digit2_loss: 1.5068 - val_digit1_accuracy: 0.5447 - val_digit2_accuracy: 0.4711\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.6859 - digit1_loss: 1.2614 - digit2_loss: 1.4245 - digit1_accuracy: 0.5645 - digit2_accuracy: 0.4992 - val_loss: 2.3069 - val_digit1_loss: 1.0788 - val_digit2_loss: 1.2281 - val_digit1_accuracy: 0.6329 - val_digit2_accuracy: 0.5829\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.3180 - digit1_loss: 1.0883 - digit2_loss: 1.2296 - digit1_accuracy: 0.6258 - digit2_accuracy: 0.5758 - val_loss: 2.0517 - val_digit1_loss: 0.9507 - val_digit2_loss: 1.1010 - val_digit1_accuracy: 0.6805 - val_digit2_accuracy: 0.6301\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.1014 - digit1_loss: 0.9897 - digit2_loss: 1.1117 - digit1_accuracy: 0.6574 - digit2_accuracy: 0.6191 - val_loss: 1.9061 - val_digit1_loss: 0.8961 - val_digit2_loss: 1.0100 - val_digit1_accuracy: 0.6918 - val_digit2_accuracy: 0.6594\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9503 - digit1_loss: 0.9205 - digit2_loss: 1.0298 - digit1_accuracy: 0.6839 - digit2_accuracy: 0.6479 - val_loss: 1.7898 - val_digit1_loss: 0.8421 - val_digit2_loss: 0.9477 - val_digit1_accuracy: 0.7098 - val_digit2_accuracy: 0.6801\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8360 - digit1_loss: 0.8708 - digit2_loss: 0.9652 - digit1_accuracy: 0.7006 - digit2_accuracy: 0.6721 - val_loss: 1.7592 - val_digit1_loss: 0.8349 - val_digit2_loss: 0.9243 - val_digit1_accuracy: 0.7119 - val_digit2_accuracy: 0.6904\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7344 - digit1_loss: 0.8217 - digit2_loss: 0.9127 - digit1_accuracy: 0.7181 - digit2_accuracy: 0.6902 - val_loss: 1.6572 - val_digit1_loss: 0.7839 - val_digit2_loss: 0.8733 - val_digit1_accuracy: 0.7303 - val_digit2_accuracy: 0.7063\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6447 - digit1_loss: 0.7782 - digit2_loss: 0.8665 - digit1_accuracy: 0.7326 - digit2_accuracy: 0.7052 - val_loss: 1.6273 - val_digit1_loss: 0.7658 - val_digit2_loss: 0.8615 - val_digit1_accuracy: 0.7332 - val_digit2_accuracy: 0.7082\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5695 - digit1_loss: 0.7420 - digit2_loss: 0.8275 - digit1_accuracy: 0.7427 - digit2_accuracy: 0.7180 - val_loss: 1.6129 - val_digit1_loss: 0.7651 - val_digit2_loss: 0.8478 - val_digit1_accuracy: 0.7366 - val_digit2_accuracy: 0.7092\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5034 - digit1_loss: 0.7147 - digit2_loss: 0.7887 - digit1_accuracy: 0.7536 - digit2_accuracy: 0.7294 - val_loss: 1.5532 - val_digit1_loss: 0.7332 - val_digit2_loss: 0.8200 - val_digit1_accuracy: 0.7481 - val_digit2_accuracy: 0.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:11:23,276]\u001b[0m Trial 15 finished with value: 1.5532171726226807 and parameters: {'kernel_size': 4, 'num_filters': 42, 'dropout_rate': 0.40153979964899034}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 2.7765 - digit1_loss: 1.2909 - digit2_loss: 1.4856 - digit1_accuracy: 0.5459 - digit2_accuracy: 0.4640 - val_loss: 1.5830 - val_digit1_loss: 0.7168 - val_digit2_loss: 0.8662 - val_digit1_accuracy: 0.7592 - val_digit2_accuracy: 0.7062\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4333 - digit1_loss: 0.6582 - digit2_loss: 0.7752 - digit1_accuracy: 0.7751 - digit2_accuracy: 0.7353 - val_loss: 1.1177 - val_digit1_loss: 0.5082 - val_digit2_loss: 0.6095 - val_digit1_accuracy: 0.8314 - val_digit2_accuracy: 0.7977\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0292 - digit1_loss: 0.4776 - digit2_loss: 0.5516 - digit1_accuracy: 0.8369 - digit2_accuracy: 0.8156 - val_loss: 0.8283 - val_digit1_loss: 0.3829 - val_digit2_loss: 0.4454 - val_digit1_accuracy: 0.8747 - val_digit2_accuracy: 0.8513\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8005 - digit1_loss: 0.3746 - digit2_loss: 0.4259 - digit1_accuracy: 0.8739 - digit2_accuracy: 0.8569 - val_loss: 0.7313 - val_digit1_loss: 0.3492 - val_digit2_loss: 0.3821 - val_digit1_accuracy: 0.8848 - val_digit2_accuracy: 0.8751\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6445 - digit1_loss: 0.3030 - digit2_loss: 0.3415 - digit1_accuracy: 0.8969 - digit2_accuracy: 0.8863 - val_loss: 0.6621 - val_digit1_loss: 0.3116 - val_digit2_loss: 0.3506 - val_digit1_accuracy: 0.8961 - val_digit2_accuracy: 0.8793\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5392 - digit1_loss: 0.2531 - digit2_loss: 0.2861 - digit1_accuracy: 0.9157 - digit2_accuracy: 0.9044 - val_loss: 0.6485 - val_digit1_loss: 0.3099 - val_digit2_loss: 0.3386 - val_digit1_accuracy: 0.8967 - val_digit2_accuracy: 0.8903\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4490 - digit1_loss: 0.2103 - digit2_loss: 0.2387 - digit1_accuracy: 0.9283 - digit2_accuracy: 0.9182 - val_loss: 0.6810 - val_digit1_loss: 0.3322 - val_digit2_loss: 0.3488 - val_digit1_accuracy: 0.8941 - val_digit2_accuracy: 0.8858\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3793 - digit1_loss: 0.1769 - digit2_loss: 0.2024 - digit1_accuracy: 0.9391 - digit2_accuracy: 0.9317 - val_loss: 0.6200 - val_digit1_loss: 0.2918 - val_digit2_loss: 0.3282 - val_digit1_accuracy: 0.9040 - val_digit2_accuracy: 0.8955\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3198 - digit1_loss: 0.1500 - digit2_loss: 0.1698 - digit1_accuracy: 0.9476 - digit2_accuracy: 0.9421 - val_loss: 0.6545 - val_digit1_loss: 0.2984 - val_digit2_loss: 0.3562 - val_digit1_accuracy: 0.9052 - val_digit2_accuracy: 0.8925\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.2744 - digit1_loss: 0.1276 - digit2_loss: 0.1468 - digit1_accuracy: 0.9554 - digit2_accuracy: 0.9495 - val_loss: 0.7172 - val_digit1_loss: 0.3551 - val_digit2_loss: 0.3621 - val_digit1_accuracy: 0.9028 - val_digit2_accuracy: 0.8955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:12:03,138]\u001b[0m Trial 16 finished with value: 0.7171359062194824 and parameters: {'kernel_size': 5, 'num_filters': 117, 'dropout_rate': 0.21567287802923657}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 2.7086 - digit1_loss: 1.2742 - digit2_loss: 1.4344 - digit1_accuracy: 0.5500 - digit2_accuracy: 0.4858 - val_loss: 1.6996 - val_digit1_loss: 0.7782 - val_digit2_loss: 0.9215 - val_digit1_accuracy: 0.7333 - val_digit2_accuracy: 0.6844\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3986 - digit1_loss: 0.6430 - digit2_loss: 0.7556 - digit1_accuracy: 0.7818 - digit2_accuracy: 0.7426 - val_loss: 1.2206 - val_digit1_loss: 0.5719 - val_digit2_loss: 0.6486 - val_digit1_accuracy: 0.8038 - val_digit2_accuracy: 0.7818\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0136 - digit1_loss: 0.4707 - digit2_loss: 0.5429 - digit1_accuracy: 0.8407 - digit2_accuracy: 0.8202 - val_loss: 0.9798 - val_digit1_loss: 0.4613 - val_digit2_loss: 0.5185 - val_digit1_accuracy: 0.8418 - val_digit2_accuracy: 0.8265\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7989 - digit1_loss: 0.3770 - digit2_loss: 0.4219 - digit1_accuracy: 0.8742 - digit2_accuracy: 0.8607 - val_loss: 0.9143 - val_digit1_loss: 0.4336 - val_digit2_loss: 0.4807 - val_digit1_accuracy: 0.8511 - val_digit2_accuracy: 0.8384\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6508 - digit1_loss: 0.3059 - digit2_loss: 0.3449 - digit1_accuracy: 0.8967 - digit2_accuracy: 0.8848 - val_loss: 0.8178 - val_digit1_loss: 0.3958 - val_digit2_loss: 0.4220 - val_digit1_accuracy: 0.8676 - val_digit2_accuracy: 0.8605\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5384 - digit1_loss: 0.2530 - digit2_loss: 0.2854 - digit1_accuracy: 0.9153 - digit2_accuracy: 0.9044 - val_loss: 0.7913 - val_digit1_loss: 0.3778 - val_digit2_loss: 0.4135 - val_digit1_accuracy: 0.8736 - val_digit2_accuracy: 0.8612\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4507 - digit1_loss: 0.2114 - digit2_loss: 0.2393 - digit1_accuracy: 0.9276 - digit2_accuracy: 0.9196 - val_loss: 0.8821 - val_digit1_loss: 0.4545 - val_digit2_loss: 0.4276 - val_digit1_accuracy: 0.8586 - val_digit2_accuracy: 0.8628\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3685 - digit1_loss: 0.1754 - digit2_loss: 0.1931 - digit1_accuracy: 0.9405 - digit2_accuracy: 0.9351 - val_loss: 0.8136 - val_digit1_loss: 0.4059 - val_digit2_loss: 0.4076 - val_digit1_accuracy: 0.8712 - val_digit2_accuracy: 0.8709\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3062 - digit1_loss: 0.1440 - digit2_loss: 0.1622 - digit1_accuracy: 0.9516 - digit2_accuracy: 0.9451 - val_loss: 0.8301 - val_digit1_loss: 0.4224 - val_digit2_loss: 0.4077 - val_digit1_accuracy: 0.8707 - val_digit2_accuracy: 0.8691\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.2584 - digit1_loss: 0.1218 - digit2_loss: 0.1366 - digit1_accuracy: 0.9584 - digit2_accuracy: 0.9535 - val_loss: 0.8582 - val_digit1_loss: 0.4231 - val_digit2_loss: 0.4351 - val_digit1_accuracy: 0.8791 - val_digit2_accuracy: 0.8706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:12:41,568]\u001b[0m Trial 17 finished with value: 0.8581908941268921 and parameters: {'kernel_size': 5, 'num_filters': 78, 'dropout_rate': 0.0026715305674694934}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.3108 - digit1_loss: 1.5831 - digit2_loss: 1.7277 - digit1_accuracy: 0.4360 - digit2_accuracy: 0.3709 - val_loss: 2.5226 - val_digit1_loss: 1.1810 - val_digit2_loss: 1.3416 - val_digit1_accuracy: 0.5913 - val_digit2_accuracy: 0.5253\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2681 - digit1_loss: 1.0500 - digit2_loss: 1.2181 - digit1_accuracy: 0.6311 - digit2_accuracy: 0.5694 - val_loss: 1.9860 - val_digit1_loss: 0.9219 - val_digit2_loss: 1.0642 - val_digit1_accuracy: 0.6798 - val_digit2_accuracy: 0.6287\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8683 - digit1_loss: 0.8675 - digit2_loss: 1.0007 - digit1_accuracy: 0.6977 - digit2_accuracy: 0.6453 - val_loss: 1.7294 - val_digit1_loss: 0.8058 - val_digit2_loss: 0.9236 - val_digit1_accuracy: 0.7188 - val_digit2_accuracy: 0.6834\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6220 - digit1_loss: 0.7544 - digit2_loss: 0.8676 - digit1_accuracy: 0.7384 - digit2_accuracy: 0.6983 - val_loss: 1.6263 - val_digit1_loss: 0.7270 - val_digit2_loss: 0.8993 - val_digit1_accuracy: 0.7449 - val_digit2_accuracy: 0.6824\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4473 - digit1_loss: 0.6753 - digit2_loss: 0.7720 - digit1_accuracy: 0.7665 - digit2_accuracy: 0.7327 - val_loss: 1.4864 - val_digit1_loss: 0.6996 - val_digit2_loss: 0.7868 - val_digit1_accuracy: 0.7554 - val_digit2_accuracy: 0.7272\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3102 - digit1_loss: 0.6102 - digit2_loss: 0.7000 - digit1_accuracy: 0.7885 - digit2_accuracy: 0.7570 - val_loss: 1.4477 - val_digit1_loss: 0.6825 - val_digit2_loss: 0.7652 - val_digit1_accuracy: 0.7552 - val_digit2_accuracy: 0.7379\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1982 - digit1_loss: 0.5594 - digit2_loss: 0.6387 - digit1_accuracy: 0.8065 - digit2_accuracy: 0.7802 - val_loss: 1.4136 - val_digit1_loss: 0.6607 - val_digit2_loss: 0.7529 - val_digit1_accuracy: 0.7648 - val_digit2_accuracy: 0.7459\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1007 - digit1_loss: 0.5134 - digit2_loss: 0.5873 - digit1_accuracy: 0.8227 - digit2_accuracy: 0.7957 - val_loss: 1.3648 - val_digit1_loss: 0.6431 - val_digit2_loss: 0.7217 - val_digit1_accuracy: 0.7739 - val_digit2_accuracy: 0.7540\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0156 - digit1_loss: 0.4749 - digit2_loss: 0.5407 - digit1_accuracy: 0.8359 - digit2_accuracy: 0.8126 - val_loss: 1.3849 - val_digit1_loss: 0.6498 - val_digit2_loss: 0.7351 - val_digit1_accuracy: 0.7722 - val_digit2_accuracy: 0.7483\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.9365 - digit1_loss: 0.4365 - digit2_loss: 0.5000 - digit1_accuracy: 0.8477 - digit2_accuracy: 0.8256 - val_loss: 1.4031 - val_digit1_loss: 0.6790 - val_digit2_loss: 0.7241 - val_digit1_accuracy: 0.7736 - val_digit2_accuracy: 0.7597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:13:19,099]\u001b[0m Trial 18 finished with value: 1.4031291007995605 and parameters: {'kernel_size': 3, 'num_filters': 49, 'dropout_rate': 0.14061657926864668}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.4434 - digit1_loss: 1.6591 - digit2_loss: 1.7843 - digit1_accuracy: 0.4074 - digit2_accuracy: 0.3548 - val_loss: 2.5680 - val_digit1_loss: 1.1932 - val_digit2_loss: 1.3748 - val_digit1_accuracy: 0.5878 - val_digit2_accuracy: 0.5351\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.4692 - digit1_loss: 1.1710 - digit2_loss: 1.2981 - digit1_accuracy: 0.5962 - digit2_accuracy: 0.5507 - val_loss: 2.0518 - val_digit1_loss: 0.9729 - val_digit2_loss: 1.0789 - val_digit1_accuracy: 0.6684 - val_digit2_accuracy: 0.6363\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.1063 - digit1_loss: 1.0048 - digit2_loss: 1.1016 - digit1_accuracy: 0.6576 - digit2_accuracy: 0.6274 - val_loss: 1.8193 - val_digit1_loss: 0.8620 - val_digit2_loss: 0.9572 - val_digit1_accuracy: 0.7075 - val_digit2_accuracy: 0.6815\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8705 - digit1_loss: 0.8948 - digit2_loss: 0.9757 - digit1_accuracy: 0.6959 - digit2_accuracy: 0.6692 - val_loss: 1.6816 - val_digit1_loss: 0.8146 - val_digit2_loss: 0.8670 - val_digit1_accuracy: 0.7187 - val_digit2_accuracy: 0.7094\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7006 - digit1_loss: 0.8145 - digit2_loss: 0.8861 - digit1_accuracy: 0.7223 - digit2_accuracy: 0.7018 - val_loss: 1.5799 - val_digit1_loss: 0.7692 - val_digit2_loss: 0.8107 - val_digit1_accuracy: 0.7356 - val_digit2_accuracy: 0.7238\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5679 - digit1_loss: 0.7520 - digit2_loss: 0.8159 - digit1_accuracy: 0.7448 - digit2_accuracy: 0.7245 - val_loss: 1.5182 - val_digit1_loss: 0.7286 - val_digit2_loss: 0.7896 - val_digit1_accuracy: 0.7507 - val_digit2_accuracy: 0.7313\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4558 - digit1_loss: 0.6959 - digit2_loss: 0.7599 - digit1_accuracy: 0.7608 - digit2_accuracy: 0.7421 - val_loss: 1.4593 - val_digit1_loss: 0.6989 - val_digit2_loss: 0.7604 - val_digit1_accuracy: 0.7604 - val_digit2_accuracy: 0.7424\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3730 - digit1_loss: 0.6580 - digit2_loss: 0.7150 - digit1_accuracy: 0.7735 - digit2_accuracy: 0.7587 - val_loss: 1.4326 - val_digit1_loss: 0.6945 - val_digit2_loss: 0.7381 - val_digit1_accuracy: 0.7653 - val_digit2_accuracy: 0.7517\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2881 - digit1_loss: 0.6144 - digit2_loss: 0.6737 - digit1_accuracy: 0.7897 - digit2_accuracy: 0.7697 - val_loss: 1.4164 - val_digit1_loss: 0.6884 - val_digit2_loss: 0.7280 - val_digit1_accuracy: 0.7618 - val_digit2_accuracy: 0.7544\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2136 - digit1_loss: 0.5823 - digit2_loss: 0.6313 - digit1_accuracy: 0.7986 - digit2_accuracy: 0.7833 - val_loss: 1.3967 - val_digit1_loss: 0.6789 - val_digit2_loss: 0.7178 - val_digit1_accuracy: 0.7677 - val_digit2_accuracy: 0.7592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:13:57,910]\u001b[0m Trial 19 finished with value: 1.3967475891113281 and parameters: {'kernel_size': 4, 'num_filters': 78, 'dropout_rate': 0.41282610967503097}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 2.9113 - digit1_loss: 1.3657 - digit2_loss: 1.5456 - digit1_accuracy: 0.5223 - digit2_accuracy: 0.4411 - val_loss: 1.7026 - val_digit1_loss: 0.7642 - val_digit2_loss: 0.9384 - val_digit1_accuracy: 0.7446 - val_digit2_accuracy: 0.6952\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6075 - digit1_loss: 0.7364 - digit2_loss: 0.8711 - digit1_accuracy: 0.7481 - digit2_accuracy: 0.7013 - val_loss: 1.1544 - val_digit1_loss: 0.5444 - val_digit2_loss: 0.6100 - val_digit1_accuracy: 0.8152 - val_digit2_accuracy: 0.7988\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1810 - digit1_loss: 0.5466 - digit2_loss: 0.6344 - digit1_accuracy: 0.8165 - digit2_accuracy: 0.7853 - val_loss: 0.9082 - val_digit1_loss: 0.4319 - val_digit2_loss: 0.4763 - val_digit1_accuracy: 0.8572 - val_digit2_accuracy: 0.8415\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9432 - digit1_loss: 0.4381 - digit2_loss: 0.5051 - digit1_accuracy: 0.8534 - digit2_accuracy: 0.8305 - val_loss: 0.7860 - val_digit1_loss: 0.3692 - val_digit2_loss: 0.4168 - val_digit1_accuracy: 0.8792 - val_digit2_accuracy: 0.8596\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7787 - digit1_loss: 0.3628 - digit2_loss: 0.4159 - digit1_accuracy: 0.8777 - digit2_accuracy: 0.8609 - val_loss: 0.7233 - val_digit1_loss: 0.3355 - val_digit2_loss: 0.3878 - val_digit1_accuracy: 0.8919 - val_digit2_accuracy: 0.8724\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6623 - digit1_loss: 0.3101 - digit2_loss: 0.3522 - digit1_accuracy: 0.8949 - digit2_accuracy: 0.8818 - val_loss: 0.6928 - val_digit1_loss: 0.3311 - val_digit2_loss: 0.3617 - val_digit1_accuracy: 0.8903 - val_digit2_accuracy: 0.8819\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5766 - digit1_loss: 0.2718 - digit2_loss: 0.3048 - digit1_accuracy: 0.9081 - digit2_accuracy: 0.8971 - val_loss: 0.6658 - val_digit1_loss: 0.3292 - val_digit2_loss: 0.3366 - val_digit1_accuracy: 0.8917 - val_digit2_accuracy: 0.8873\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4998 - digit1_loss: 0.2316 - digit2_loss: 0.2682 - digit1_accuracy: 0.9220 - digit2_accuracy: 0.9096 - val_loss: 0.6430 - val_digit1_loss: 0.3031 - val_digit2_loss: 0.3399 - val_digit1_accuracy: 0.9038 - val_digit2_accuracy: 0.8857\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4325 - digit1_loss: 0.2013 - digit2_loss: 0.2312 - digit1_accuracy: 0.9311 - digit2_accuracy: 0.9224 - val_loss: 0.6266 - val_digit1_loss: 0.3038 - val_digit2_loss: 0.3228 - val_digit1_accuracy: 0.9001 - val_digit2_accuracy: 0.8919\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3889 - digit1_loss: 0.1827 - digit2_loss: 0.2063 - digit1_accuracy: 0.9369 - digit2_accuracy: 0.9297 - val_loss: 0.6294 - val_digit1_loss: 0.3055 - val_digit2_loss: 0.3239 - val_digit1_accuracy: 0.9090 - val_digit2_accuracy: 0.8981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:14:37,898]\u001b[0m Trial 20 finished with value: 0.6294062733650208 and parameters: {'kernel_size': 5, 'num_filters': 95, 'dropout_rate': 0.2857195851115556}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 2.8230 - digit1_loss: 1.3279 - digit2_loss: 1.4951 - digit1_accuracy: 0.5313 - digit2_accuracy: 0.4618 - val_loss: 1.5607 - val_digit1_loss: 0.7056 - val_digit2_loss: 0.8551 - val_digit1_accuracy: 0.7642 - val_digit2_accuracy: 0.7193\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4324 - digit1_loss: 0.6546 - digit2_loss: 0.7777 - digit1_accuracy: 0.7773 - digit2_accuracy: 0.7350 - val_loss: 1.0165 - val_digit1_loss: 0.4680 - val_digit2_loss: 0.5485 - val_digit1_accuracy: 0.8428 - val_digit2_accuracy: 0.8183\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0081 - digit1_loss: 0.4665 - digit2_loss: 0.5416 - digit1_accuracy: 0.8440 - digit2_accuracy: 0.8187 - val_loss: 0.8099 - val_digit1_loss: 0.3790 - val_digit2_loss: 0.4309 - val_digit1_accuracy: 0.8729 - val_digit2_accuracy: 0.8541\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7788 - digit1_loss: 0.3608 - digit2_loss: 0.4180 - digit1_accuracy: 0.8794 - digit2_accuracy: 0.8598 - val_loss: 0.7052 - val_digit1_loss: 0.3290 - val_digit2_loss: 0.3761 - val_digit1_accuracy: 0.8882 - val_digit2_accuracy: 0.8739\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6256 - digit1_loss: 0.2903 - digit2_loss: 0.3353 - digit1_accuracy: 0.9025 - digit2_accuracy: 0.8889 - val_loss: 0.6492 - val_digit1_loss: 0.3073 - val_digit2_loss: 0.3419 - val_digit1_accuracy: 0.8966 - val_digit2_accuracy: 0.8878\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5204 - digit1_loss: 0.2435 - digit2_loss: 0.2769 - digit1_accuracy: 0.9174 - digit2_accuracy: 0.9070 - val_loss: 0.6330 - val_digit1_loss: 0.2955 - val_digit2_loss: 0.3375 - val_digit1_accuracy: 0.9012 - val_digit2_accuracy: 0.8912\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4349 - digit1_loss: 0.2032 - digit2_loss: 0.2317 - digit1_accuracy: 0.9305 - digit2_accuracy: 0.9203 - val_loss: 0.6343 - val_digit1_loss: 0.3139 - val_digit2_loss: 0.3204 - val_digit1_accuracy: 0.8988 - val_digit2_accuracy: 0.8964\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3711 - digit1_loss: 0.1745 - digit2_loss: 0.1966 - digit1_accuracy: 0.9396 - digit2_accuracy: 0.9337 - val_loss: 0.5903 - val_digit1_loss: 0.2794 - val_digit2_loss: 0.3109 - val_digit1_accuracy: 0.9130 - val_digit2_accuracy: 0.9056\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3210 - digit1_loss: 0.1497 - digit2_loss: 0.1713 - digit1_accuracy: 0.9492 - digit2_accuracy: 0.9413 - val_loss: 0.6433 - val_digit1_loss: 0.3014 - val_digit2_loss: 0.3419 - val_digit1_accuracy: 0.9050 - val_digit2_accuracy: 0.8941\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.2688 - digit1_loss: 0.1262 - digit2_loss: 0.1426 - digit1_accuracy: 0.9566 - digit2_accuracy: 0.9501 - val_loss: 0.6507 - val_digit1_loss: 0.3006 - val_digit2_loss: 0.3500 - val_digit1_accuracy: 0.9129 - val_digit2_accuracy: 0.8992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:15:18,122]\u001b[0m Trial 21 finished with value: 0.6506657004356384 and parameters: {'kernel_size': 5, 'num_filters': 99, 'dropout_rate': 0.2668331857804391}. Best is trial 1 with value: 0.620613694190979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 2.9542 - digit1_loss: 1.3884 - digit2_loss: 1.5658 - digit1_accuracy: 0.5066 - digit2_accuracy: 0.4285 - val_loss: 1.7219 - val_digit1_loss: 0.7789 - val_digit2_loss: 0.9429 - val_digit1_accuracy: 0.7362 - val_digit2_accuracy: 0.6798\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5396 - digit1_loss: 0.7014 - digit2_loss: 0.8382 - digit1_accuracy: 0.7624 - digit2_accuracy: 0.7123 - val_loss: 1.0894 - val_digit1_loss: 0.4965 - val_digit2_loss: 0.5929 - val_digit1_accuracy: 0.8330 - val_digit2_accuracy: 0.8033\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1033 - digit1_loss: 0.5151 - digit2_loss: 0.5883 - digit1_accuracy: 0.8269 - digit2_accuracy: 0.8049 - val_loss: 0.8468 - val_digit1_loss: 0.3963 - val_digit2_loss: 0.4506 - val_digit1_accuracy: 0.8652 - val_digit2_accuracy: 0.8482\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8603 - digit1_loss: 0.4030 - digit2_loss: 0.4573 - digit1_accuracy: 0.8650 - digit2_accuracy: 0.8474 - val_loss: 0.7584 - val_digit1_loss: 0.3648 - val_digit2_loss: 0.3936 - val_digit1_accuracy: 0.8762 - val_digit2_accuracy: 0.8668\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7067 - digit1_loss: 0.3322 - digit2_loss: 0.3744 - digit1_accuracy: 0.8890 - digit2_accuracy: 0.8755 - val_loss: 0.6741 - val_digit1_loss: 0.3142 - val_digit2_loss: 0.3600 - val_digit1_accuracy: 0.8928 - val_digit2_accuracy: 0.8788\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5920 - digit1_loss: 0.2807 - digit2_loss: 0.3114 - digit1_accuracy: 0.9056 - digit2_accuracy: 0.8956 - val_loss: 0.6687 - val_digit1_loss: 0.3073 - val_digit2_loss: 0.3614 - val_digit1_accuracy: 0.8966 - val_digit2_accuracy: 0.8798\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5039 - digit1_loss: 0.2397 - digit2_loss: 0.2642 - digit1_accuracy: 0.9194 - digit2_accuracy: 0.9105 - val_loss: 0.6023 - val_digit1_loss: 0.2829 - val_digit2_loss: 0.3195 - val_digit1_accuracy: 0.9048 - val_digit2_accuracy: 0.8946\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4352 - digit1_loss: 0.2082 - digit2_loss: 0.2270 - digit1_accuracy: 0.9292 - digit2_accuracy: 0.9230 - val_loss: 0.6129 - val_digit1_loss: 0.2983 - val_digit2_loss: 0.3146 - val_digit1_accuracy: 0.9030 - val_digit2_accuracy: 0.9004\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3791 - digit1_loss: 0.1797 - digit2_loss: 0.1994 - digit1_accuracy: 0.9394 - digit2_accuracy: 0.9322 - val_loss: 0.5822 - val_digit1_loss: 0.2828 - val_digit2_loss: 0.2995 - val_digit1_accuracy: 0.9088 - val_digit2_accuracy: 0.9037\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3304 - digit1_loss: 0.1580 - digit2_loss: 0.1724 - digit1_accuracy: 0.9457 - digit2_accuracy: 0.9410 - val_loss: 0.5886 - val_digit1_loss: 0.2808 - val_digit2_loss: 0.3078 - val_digit1_accuracy: 0.9118 - val_digit2_accuracy: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:15:57,696]\u001b[0m Trial 22 finished with value: 0.5885637402534485 and parameters: {'kernel_size': 5, 'num_filters': 103, 'dropout_rate': 0.2971830474807617}. Best is trial 22 with value: 0.5885637402534485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.4560 - digit1_loss: 1.6518 - digit2_loss: 1.8042 - digit1_accuracy: 0.4157 - digit2_accuracy: 0.3439 - val_loss: 2.5148 - val_digit1_loss: 1.1684 - val_digit2_loss: 1.3464 - val_digit1_accuracy: 0.5993 - val_digit2_accuracy: 0.5447\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.4477 - digit1_loss: 1.1659 - digit2_loss: 1.2818 - digit1_accuracy: 0.6000 - digit2_accuracy: 0.5552 - val_loss: 2.0237 - val_digit1_loss: 0.9662 - val_digit2_loss: 1.0575 - val_digit1_accuracy: 0.6757 - val_digit2_accuracy: 0.6536\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.0632 - digit1_loss: 0.9916 - digit2_loss: 1.0716 - digit1_accuracy: 0.6605 - digit2_accuracy: 0.6352 - val_loss: 1.7798 - val_digit1_loss: 0.8501 - val_digit2_loss: 0.9297 - val_digit1_accuracy: 0.7122 - val_digit2_accuracy: 0.6908\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8364 - digit1_loss: 0.8866 - digit2_loss: 0.9498 - digit1_accuracy: 0.6984 - digit2_accuracy: 0.6761 - val_loss: 1.6196 - val_digit1_loss: 0.7796 - val_digit2_loss: 0.8400 - val_digit1_accuracy: 0.7331 - val_digit2_accuracy: 0.7171\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6624 - digit1_loss: 0.8007 - digit2_loss: 0.8617 - digit1_accuracy: 0.7279 - digit2_accuracy: 0.7097 - val_loss: 1.5203 - val_digit1_loss: 0.7356 - val_digit2_loss: 0.7847 - val_digit1_accuracy: 0.7467 - val_digit2_accuracy: 0.7343\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5297 - digit1_loss: 0.7403 - digit2_loss: 0.7894 - digit1_accuracy: 0.7509 - digit2_accuracy: 0.7355 - val_loss: 1.4566 - val_digit1_loss: 0.7011 - val_digit2_loss: 0.7555 - val_digit1_accuracy: 0.7603 - val_digit2_accuracy: 0.7448\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4173 - digit1_loss: 0.6904 - digit2_loss: 0.7270 - digit1_accuracy: 0.7658 - digit2_accuracy: 0.7519 - val_loss: 1.4128 - val_digit1_loss: 0.6895 - val_digit2_loss: 0.7233 - val_digit1_accuracy: 0.7607 - val_digit2_accuracy: 0.7523\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3338 - digit1_loss: 0.6496 - digit2_loss: 0.6842 - digit1_accuracy: 0.7785 - digit2_accuracy: 0.7687 - val_loss: 1.3724 - val_digit1_loss: 0.6652 - val_digit2_loss: 0.7072 - val_digit1_accuracy: 0.7671 - val_digit2_accuracy: 0.7595\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2403 - digit1_loss: 0.5976 - digit2_loss: 0.6428 - digit1_accuracy: 0.7952 - digit2_accuracy: 0.7821 - val_loss: 1.3699 - val_digit1_loss: 0.6668 - val_digit2_loss: 0.7031 - val_digit1_accuracy: 0.7718 - val_digit2_accuracy: 0.7653\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1641 - digit1_loss: 0.5658 - digit2_loss: 0.5984 - digit1_accuracy: 0.8053 - digit2_accuracy: 0.7951 - val_loss: 1.3621 - val_digit1_loss: 0.6616 - val_digit2_loss: 0.7005 - val_digit1_accuracy: 0.7697 - val_digit2_accuracy: 0.7658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:16:38,309]\u001b[0m Trial 23 finished with value: 1.3621145486831665 and parameters: {'kernel_size': 4, 'num_filters': 110, 'dropout_rate': 0.4054377456616818}. Best is trial 22 with value: 0.5885637402534485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.0301 - digit1_loss: 1.4323 - digit2_loss: 1.5978 - digit1_accuracy: 0.4892 - digit2_accuracy: 0.4209 - val_loss: 1.7571 - val_digit1_loss: 0.7797 - val_digit2_loss: 0.9774 - val_digit1_accuracy: 0.7393 - val_digit2_accuracy: 0.6750\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6517 - digit1_loss: 0.7565 - digit2_loss: 0.8952 - digit1_accuracy: 0.7440 - digit2_accuracy: 0.6932 - val_loss: 1.1504 - val_digit1_loss: 0.5331 - val_digit2_loss: 0.6173 - val_digit1_accuracy: 0.8216 - val_digit2_accuracy: 0.7991\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1981 - digit1_loss: 0.5596 - digit2_loss: 0.6385 - digit1_accuracy: 0.8112 - digit2_accuracy: 0.7836 - val_loss: 0.9310 - val_digit1_loss: 0.4337 - val_digit2_loss: 0.4973 - val_digit1_accuracy: 0.8538 - val_digit2_accuracy: 0.8346\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9732 - digit1_loss: 0.4566 - digit2_loss: 0.5166 - digit1_accuracy: 0.8460 - digit2_accuracy: 0.8272 - val_loss: 0.8234 - val_digit1_loss: 0.3855 - val_digit2_loss: 0.4379 - val_digit1_accuracy: 0.8723 - val_digit2_accuracy: 0.8562\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8085 - digit1_loss: 0.3813 - digit2_loss: 0.4273 - digit1_accuracy: 0.8729 - digit2_accuracy: 0.8588 - val_loss: 0.7467 - val_digit1_loss: 0.3473 - val_digit2_loss: 0.3994 - val_digit1_accuracy: 0.8800 - val_digit2_accuracy: 0.8657\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6908 - digit1_loss: 0.3261 - digit2_loss: 0.3647 - digit1_accuracy: 0.8908 - digit2_accuracy: 0.8794 - val_loss: 0.6827 - val_digit1_loss: 0.3342 - val_digit2_loss: 0.3485 - val_digit1_accuracy: 0.8895 - val_digit2_accuracy: 0.8826\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6027 - digit1_loss: 0.2825 - digit2_loss: 0.3202 - digit1_accuracy: 0.9054 - digit2_accuracy: 0.8923 - val_loss: 0.6797 - val_digit1_loss: 0.3386 - val_digit2_loss: 0.3412 - val_digit1_accuracy: 0.8865 - val_digit2_accuracy: 0.8894\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5316 - digit1_loss: 0.2520 - digit2_loss: 0.2796 - digit1_accuracy: 0.9149 - digit2_accuracy: 0.9074 - val_loss: 0.6470 - val_digit1_loss: 0.3093 - val_digit2_loss: 0.3377 - val_digit1_accuracy: 0.8994 - val_digit2_accuracy: 0.8887\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4638 - digit1_loss: 0.2186 - digit2_loss: 0.2452 - digit1_accuracy: 0.9252 - digit2_accuracy: 0.9173 - val_loss: 0.6649 - val_digit1_loss: 0.3120 - val_digit2_loss: 0.3529 - val_digit1_accuracy: 0.8979 - val_digit2_accuracy: 0.8870\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4106 - digit1_loss: 0.1963 - digit2_loss: 0.2142 - digit1_accuracy: 0.9329 - digit2_accuracy: 0.9274 - val_loss: 0.6410 - val_digit1_loss: 0.3113 - val_digit2_loss: 0.3297 - val_digit1_accuracy: 0.9030 - val_digit2_accuracy: 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:17:17,587]\u001b[0m Trial 24 finished with value: 0.6410363912582397 and parameters: {'kernel_size': 5, 'num_filters': 90, 'dropout_rate': 0.315515072170208}. Best is trial 22 with value: 0.5885637402534485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.1146 - digit1_loss: 1.4620 - digit2_loss: 1.6526 - digit1_accuracy: 0.4801 - digit2_accuracy: 0.3993 - val_loss: 1.7889 - val_digit1_loss: 0.8019 - val_digit2_loss: 0.9870 - val_digit1_accuracy: 0.7303 - val_digit2_accuracy: 0.6775\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7545 - digit1_loss: 0.8039 - digit2_loss: 0.9505 - digit1_accuracy: 0.7257 - digit2_accuracy: 0.6741 - val_loss: 1.1970 - val_digit1_loss: 0.5454 - val_digit2_loss: 0.6516 - val_digit1_accuracy: 0.8155 - val_digit2_accuracy: 0.7922\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2843 - digit1_loss: 0.5997 - digit2_loss: 0.6846 - digit1_accuracy: 0.7982 - digit2_accuracy: 0.7683 - val_loss: 0.9527 - val_digit1_loss: 0.4505 - val_digit2_loss: 0.5021 - val_digit1_accuracy: 0.8506 - val_digit2_accuracy: 0.8342\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0157 - digit1_loss: 0.4795 - digit2_loss: 0.5362 - digit1_accuracy: 0.8404 - digit2_accuracy: 0.8237 - val_loss: 0.7670 - val_digit1_loss: 0.3598 - val_digit2_loss: 0.4071 - val_digit1_accuracy: 0.8792 - val_digit2_accuracy: 0.8640\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8345 - digit1_loss: 0.3964 - digit2_loss: 0.4381 - digit1_accuracy: 0.8672 - digit2_accuracy: 0.8560 - val_loss: 0.6774 - val_digit1_loss: 0.3237 - val_digit2_loss: 0.3537 - val_digit1_accuracy: 0.8941 - val_digit2_accuracy: 0.8819\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7118 - digit1_loss: 0.3387 - digit2_loss: 0.3731 - digit1_accuracy: 0.8859 - digit2_accuracy: 0.8781 - val_loss: 0.6521 - val_digit1_loss: 0.3098 - val_digit2_loss: 0.3423 - val_digit1_accuracy: 0.8986 - val_digit2_accuracy: 0.8930\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6076 - digit1_loss: 0.2888 - digit2_loss: 0.3187 - digit1_accuracy: 0.9031 - digit2_accuracy: 0.8947 - val_loss: 0.6278 - val_digit1_loss: 0.3034 - val_digit2_loss: 0.3244 - val_digit1_accuracy: 0.9010 - val_digit2_accuracy: 0.8957\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5279 - digit1_loss: 0.2534 - digit2_loss: 0.2745 - digit1_accuracy: 0.9144 - digit2_accuracy: 0.9085 - val_loss: 0.5890 - val_digit1_loss: 0.2807 - val_digit2_loss: 0.3083 - val_digit1_accuracy: 0.9080 - val_digit2_accuracy: 0.8998\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4618 - digit1_loss: 0.2217 - digit2_loss: 0.2401 - digit1_accuracy: 0.9257 - digit2_accuracy: 0.9191 - val_loss: 0.6267 - val_digit1_loss: 0.3185 - val_digit2_loss: 0.3082 - val_digit1_accuracy: 0.9056 - val_digit2_accuracy: 0.9039\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4064 - digit1_loss: 0.1962 - digit2_loss: 0.2101 - digit1_accuracy: 0.9338 - digit2_accuracy: 0.9284 - val_loss: 0.5883 - val_digit1_loss: 0.2936 - val_digit2_loss: 0.2947 - val_digit1_accuracy: 0.9106 - val_digit2_accuracy: 0.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:17:57,524]\u001b[0m Trial 25 finished with value: 0.588302493095398 and parameters: {'kernel_size': 5, 'num_filters': 117, 'dropout_rate': 0.44144538848611603}. Best is trial 25 with value: 0.588302493095398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.4574 - digit1_loss: 1.6575 - digit2_loss: 1.8000 - digit1_accuracy: 0.4112 - digit2_accuracy: 0.3511 - val_loss: 2.4931 - val_digit1_loss: 1.1602 - val_digit2_loss: 1.3329 - val_digit1_accuracy: 0.6058 - val_digit2_accuracy: 0.5508\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.4328 - digit1_loss: 1.1473 - digit2_loss: 1.2855 - digit1_accuracy: 0.6065 - digit2_accuracy: 0.5577 - val_loss: 1.9800 - val_digit1_loss: 0.9280 - val_digit2_loss: 1.0519 - val_digit1_accuracy: 0.6857 - val_digit2_accuracy: 0.6465\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.0895 - digit1_loss: 0.9906 - digit2_loss: 1.0989 - digit1_accuracy: 0.6646 - digit2_accuracy: 0.6252 - val_loss: 1.7941 - val_digit1_loss: 0.8523 - val_digit2_loss: 0.9418 - val_digit1_accuracy: 0.7071 - val_digit2_accuracy: 0.6919\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8653 - digit1_loss: 0.8872 - digit2_loss: 0.9781 - digit1_accuracy: 0.6995 - digit2_accuracy: 0.6707 - val_loss: 1.6604 - val_digit1_loss: 0.7797 - val_digit2_loss: 0.8807 - val_digit1_accuracy: 0.7340 - val_digit2_accuracy: 0.7028\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6989 - digit1_loss: 0.8113 - digit2_loss: 0.8876 - digit1_accuracy: 0.7253 - digit2_accuracy: 0.6989 - val_loss: 1.5296 - val_digit1_loss: 0.7287 - val_digit2_loss: 0.8009 - val_digit1_accuracy: 0.7495 - val_digit2_accuracy: 0.7296\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5614 - digit1_loss: 0.7481 - digit2_loss: 0.8133 - digit1_accuracy: 0.7455 - digit2_accuracy: 0.7260 - val_loss: 1.4539 - val_digit1_loss: 0.6936 - val_digit2_loss: 0.7603 - val_digit1_accuracy: 0.7627 - val_digit2_accuracy: 0.7408\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4486 - digit1_loss: 0.6946 - digit2_loss: 0.7540 - digit1_accuracy: 0.7631 - digit2_accuracy: 0.7446 - val_loss: 1.4843 - val_digit1_loss: 0.7133 - val_digit2_loss: 0.7709 - val_digit1_accuracy: 0.7595 - val_digit2_accuracy: 0.7426\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3558 - digit1_loss: 0.6520 - digit2_loss: 0.7039 - digit1_accuracy: 0.7763 - digit2_accuracy: 0.7602 - val_loss: 1.3827 - val_digit1_loss: 0.6716 - val_digit2_loss: 0.7110 - val_digit1_accuracy: 0.7668 - val_digit2_accuracy: 0.7563\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2823 - digit1_loss: 0.6171 - digit2_loss: 0.6652 - digit1_accuracy: 0.7895 - digit2_accuracy: 0.7745 - val_loss: 1.3490 - val_digit1_loss: 0.6494 - val_digit2_loss: 0.6997 - val_digit1_accuracy: 0.7760 - val_digit2_accuracy: 0.7632\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2046 - digit1_loss: 0.5820 - digit2_loss: 0.6226 - digit1_accuracy: 0.8003 - digit2_accuracy: 0.7871 - val_loss: 1.3409 - val_digit1_loss: 0.6422 - val_digit2_loss: 0.6987 - val_digit1_accuracy: 0.7795 - val_digit2_accuracy: 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:18:37,764]\u001b[0m Trial 26 finished with value: 1.3409336805343628 and parameters: {'kernel_size': 4, 'num_filters': 127, 'dropout_rate': 0.43200006746297326}. Best is trial 25 with value: 0.588302493095398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.2113 - digit1_loss: 1.5180 - digit2_loss: 1.6933 - digit1_accuracy: 0.4597 - digit2_accuracy: 0.3834 - val_loss: 1.9162 - val_digit1_loss: 0.8527 - val_digit2_loss: 1.0635 - val_digit1_accuracy: 0.7135 - val_digit2_accuracy: 0.6447\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9018 - digit1_loss: 0.8715 - digit2_loss: 1.0303 - digit1_accuracy: 0.7016 - digit2_accuracy: 0.6431 - val_loss: 1.2311 - val_digit1_loss: 0.5549 - val_digit2_loss: 0.6762 - val_digit1_accuracy: 0.8213 - val_digit2_accuracy: 0.7872\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4390 - digit1_loss: 0.6706 - digit2_loss: 0.7684 - digit1_accuracy: 0.7751 - digit2_accuracy: 0.7386 - val_loss: 0.9503 - val_digit1_loss: 0.4399 - val_digit2_loss: 0.5105 - val_digit1_accuracy: 0.8549 - val_digit2_accuracy: 0.8390\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1594 - digit1_loss: 0.5477 - digit2_loss: 0.6118 - digit1_accuracy: 0.8166 - digit2_accuracy: 0.7944 - val_loss: 0.8030 - val_digit1_loss: 0.3788 - val_digit2_loss: 0.4242 - val_digit1_accuracy: 0.8773 - val_digit2_accuracy: 0.8620\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9716 - digit1_loss: 0.4598 - digit2_loss: 0.5118 - digit1_accuracy: 0.8453 - digit2_accuracy: 0.8269 - val_loss: 0.7398 - val_digit1_loss: 0.3474 - val_digit2_loss: 0.3924 - val_digit1_accuracy: 0.8838 - val_digit2_accuracy: 0.8698\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8320 - digit1_loss: 0.3961 - digit2_loss: 0.4359 - digit1_accuracy: 0.8677 - digit2_accuracy: 0.8526 - val_loss: 0.6853 - val_digit1_loss: 0.3241 - val_digit2_loss: 0.3612 - val_digit1_accuracy: 0.8908 - val_digit2_accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7154 - digit1_loss: 0.3439 - digit2_loss: 0.3715 - digit1_accuracy: 0.8855 - digit2_accuracy: 0.8739 - val_loss: 0.6039 - val_digit1_loss: 0.2876 - val_digit2_loss: 0.3164 - val_digit1_accuracy: 0.9051 - val_digit2_accuracy: 0.8967\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6286 - digit1_loss: 0.3014 - digit2_loss: 0.3272 - digit1_accuracy: 0.8985 - digit2_accuracy: 0.8887 - val_loss: 0.5838 - val_digit1_loss: 0.2819 - val_digit2_loss: 0.3019 - val_digit1_accuracy: 0.9093 - val_digit2_accuracy: 0.9014\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5598 - digit1_loss: 0.2710 - digit2_loss: 0.2888 - digit1_accuracy: 0.9095 - digit2_accuracy: 0.9022 - val_loss: 0.6120 - val_digit1_loss: 0.2840 - val_digit2_loss: 0.3280 - val_digit1_accuracy: 0.9108 - val_digit2_accuracy: 0.8938\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5029 - digit1_loss: 0.2429 - digit2_loss: 0.2600 - digit1_accuracy: 0.9172 - digit2_accuracy: 0.9118 - val_loss: 0.5655 - val_digit1_loss: 0.2770 - val_digit2_loss: 0.2885 - val_digit1_accuracy: 0.9118 - val_digit2_accuracy: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:19:17,544]\u001b[0m Trial 27 finished with value: 0.5655372142791748 and parameters: {'kernel_size': 5, 'num_filters': 116, 'dropout_rate': 0.452886453681836}. Best is trial 27 with value: 0.5655372142791748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.4567 - digit1_loss: 1.6540 - digit2_loss: 1.8026 - digit1_accuracy: 0.4150 - digit2_accuracy: 0.3441 - val_loss: 2.4934 - val_digit1_loss: 1.1702 - val_digit2_loss: 1.3233 - val_digit1_accuracy: 0.6024 - val_digit2_accuracy: 0.5464\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.4609 - digit1_loss: 1.1630 - digit2_loss: 1.2979 - digit1_accuracy: 0.6004 - digit2_accuracy: 0.5491 - val_loss: 2.0279 - val_digit1_loss: 0.9521 - val_digit2_loss: 1.0758 - val_digit1_accuracy: 0.6733 - val_digit2_accuracy: 0.6403\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.0942 - digit1_loss: 0.9934 - digit2_loss: 1.1008 - digit1_accuracy: 0.6610 - digit2_accuracy: 0.6244 - val_loss: 1.7771 - val_digit1_loss: 0.8345 - val_digit2_loss: 0.9427 - val_digit1_accuracy: 0.7171 - val_digit2_accuracy: 0.6859\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8615 - digit1_loss: 0.8879 - digit2_loss: 0.9736 - digit1_accuracy: 0.6995 - digit2_accuracy: 0.6668 - val_loss: 1.6203 - val_digit1_loss: 0.7677 - val_digit2_loss: 0.8526 - val_digit1_accuracy: 0.7377 - val_digit2_accuracy: 0.7162\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6846 - digit1_loss: 0.8089 - digit2_loss: 0.8757 - digit1_accuracy: 0.7272 - digit2_accuracy: 0.7026 - val_loss: 1.5137 - val_digit1_loss: 0.7238 - val_digit2_loss: 0.7899 - val_digit1_accuracy: 0.7573 - val_digit2_accuracy: 0.7354\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5572 - digit1_loss: 0.7497 - digit2_loss: 0.8076 - digit1_accuracy: 0.7473 - digit2_accuracy: 0.7257 - val_loss: 1.4524 - val_digit1_loss: 0.6954 - val_digit2_loss: 0.7570 - val_digit1_accuracy: 0.7663 - val_digit2_accuracy: 0.7489\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4493 - digit1_loss: 0.7004 - digit2_loss: 0.7489 - digit1_accuracy: 0.7618 - digit2_accuracy: 0.7473 - val_loss: 1.4049 - val_digit1_loss: 0.6765 - val_digit2_loss: 0.7285 - val_digit1_accuracy: 0.7698 - val_digit2_accuracy: 0.7562\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3562 - digit1_loss: 0.6532 - digit2_loss: 0.7030 - digit1_accuracy: 0.7751 - digit2_accuracy: 0.7614 - val_loss: 1.4195 - val_digit1_loss: 0.6790 - val_digit2_loss: 0.7405 - val_digit1_accuracy: 0.7683 - val_digit2_accuracy: 0.7512\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2737 - digit1_loss: 0.6153 - digit2_loss: 0.6584 - digit1_accuracy: 0.7896 - digit2_accuracy: 0.7746 - val_loss: 1.3686 - val_digit1_loss: 0.6562 - val_digit2_loss: 0.7124 - val_digit1_accuracy: 0.7762 - val_digit2_accuracy: 0.7623\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1979 - digit1_loss: 0.5773 - digit2_loss: 0.6206 - digit1_accuracy: 0.8008 - digit2_accuracy: 0.7842 - val_loss: 1.3392 - val_digit1_loss: 0.6500 - val_digit2_loss: 0.6893 - val_digit1_accuracy: 0.7802 - val_digit2_accuracy: 0.7715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:19:58,343]\u001b[0m Trial 28 finished with value: 1.3392205238342285 and parameters: {'kernel_size': 4, 'num_filters': 115, 'dropout_rate': 0.4416412695788082}. Best is trial 27 with value: 0.5655372142791748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.0228 - digit1_loss: 1.4127 - digit2_loss: 1.6100 - digit1_accuracy: 0.5047 - digit2_accuracy: 0.4189 - val_loss: 1.6729 - val_digit1_loss: 0.7474 - val_digit2_loss: 0.9255 - val_digit1_accuracy: 0.7492 - val_digit2_accuracy: 0.6970\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7158 - digit1_loss: 0.7847 - digit2_loss: 0.9311 - digit1_accuracy: 0.7323 - digit2_accuracy: 0.6806 - val_loss: 1.1040 - val_digit1_loss: 0.5082 - val_digit2_loss: 0.5958 - val_digit1_accuracy: 0.8317 - val_digit2_accuracy: 0.8124\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2512 - digit1_loss: 0.5791 - digit2_loss: 0.6721 - digit1_accuracy: 0.8070 - digit2_accuracy: 0.7740 - val_loss: 0.8704 - val_digit1_loss: 0.3979 - val_digit2_loss: 0.4725 - val_digit1_accuracy: 0.8640 - val_digit2_accuracy: 0.8443\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9922 - digit1_loss: 0.4607 - digit2_loss: 0.5315 - digit1_accuracy: 0.8469 - digit2_accuracy: 0.8231 - val_loss: 0.7688 - val_digit1_loss: 0.3515 - val_digit2_loss: 0.4174 - val_digit1_accuracy: 0.8806 - val_digit2_accuracy: 0.8619\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8073 - digit1_loss: 0.3761 - digit2_loss: 0.4311 - digit1_accuracy: 0.8744 - digit2_accuracy: 0.8564 - val_loss: 0.7009 - val_digit1_loss: 0.3303 - val_digit2_loss: 0.3706 - val_digit1_accuracy: 0.8903 - val_digit2_accuracy: 0.8785\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6936 - digit1_loss: 0.3292 - digit2_loss: 0.3644 - digit1_accuracy: 0.8908 - digit2_accuracy: 0.8779 - val_loss: 0.6162 - val_digit1_loss: 0.2865 - val_digit2_loss: 0.3298 - val_digit1_accuracy: 0.9038 - val_digit2_accuracy: 0.8907\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5904 - digit1_loss: 0.2791 - digit2_loss: 0.3113 - digit1_accuracy: 0.9061 - digit2_accuracy: 0.8957 - val_loss: 0.6054 - val_digit1_loss: 0.2824 - val_digit2_loss: 0.3230 - val_digit1_accuracy: 0.9038 - val_digit2_accuracy: 0.8943\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5133 - digit1_loss: 0.2433 - digit2_loss: 0.2699 - digit1_accuracy: 0.9196 - digit2_accuracy: 0.9093 - val_loss: 0.5898 - val_digit1_loss: 0.2771 - val_digit2_loss: 0.3128 - val_digit1_accuracy: 0.9099 - val_digit2_accuracy: 0.9003\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4502 - digit1_loss: 0.2110 - digit2_loss: 0.2392 - digit1_accuracy: 0.9292 - digit2_accuracy: 0.9198 - val_loss: 0.5736 - val_digit1_loss: 0.2770 - val_digit2_loss: 0.2966 - val_digit1_accuracy: 0.9127 - val_digit2_accuracy: 0.9047\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3988 - digit1_loss: 0.1901 - digit2_loss: 0.2088 - digit1_accuracy: 0.9350 - digit2_accuracy: 0.9291 - val_loss: 0.5660 - val_digit1_loss: 0.2691 - val_digit2_loss: 0.2968 - val_digit1_accuracy: 0.9166 - val_digit2_accuracy: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:20:38,431]\u001b[0m Trial 29 finished with value: 0.5659611225128174 and parameters: {'kernel_size': 5, 'num_filters': 119, 'dropout_rate': 0.4547292274086171}. Best is trial 27 with value: 0.5655372142791748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.0992 - digit1_loss: 1.4579 - digit2_loss: 1.6413 - digit1_accuracy: 0.4848 - digit2_accuracy: 0.4031 - val_loss: 1.7989 - val_digit1_loss: 0.8328 - val_digit2_loss: 0.9662 - val_digit1_accuracy: 0.7263 - val_digit2_accuracy: 0.6892\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6834 - digit1_loss: 0.7751 - digit2_loss: 0.9083 - digit1_accuracy: 0.7371 - digit2_accuracy: 0.6916 - val_loss: 1.0662 - val_digit1_loss: 0.4928 - val_digit2_loss: 0.5733 - val_digit1_accuracy: 0.8367 - val_digit2_accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1981 - digit1_loss: 0.5630 - digit2_loss: 0.6351 - digit1_accuracy: 0.8129 - digit2_accuracy: 0.7876 - val_loss: 0.8674 - val_digit1_loss: 0.3907 - val_digit2_loss: 0.4767 - val_digit1_accuracy: 0.8707 - val_digit2_accuracy: 0.8403\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9405 - digit1_loss: 0.4509 - digit2_loss: 0.4897 - digit1_accuracy: 0.8517 - digit2_accuracy: 0.8376 - val_loss: 0.7029 - val_digit1_loss: 0.3313 - val_digit2_loss: 0.3716 - val_digit1_accuracy: 0.8932 - val_digit2_accuracy: 0.8767\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7689 - digit1_loss: 0.3672 - digit2_loss: 0.4017 - digit1_accuracy: 0.8778 - digit2_accuracy: 0.8676 - val_loss: 0.6605 - val_digit1_loss: 0.3125 - val_digit2_loss: 0.3480 - val_digit1_accuracy: 0.8962 - val_digit2_accuracy: 0.8833\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6524 - digit1_loss: 0.3117 - digit2_loss: 0.3406 - digit1_accuracy: 0.8968 - digit2_accuracy: 0.8877 - val_loss: 0.6065 - val_digit1_loss: 0.2889 - val_digit2_loss: 0.3176 - val_digit1_accuracy: 0.9033 - val_digit2_accuracy: 0.8939\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5554 - digit1_loss: 0.2672 - digit2_loss: 0.2882 - digit1_accuracy: 0.9109 - digit2_accuracy: 0.9028 - val_loss: 0.5909 - val_digit1_loss: 0.2791 - val_digit2_loss: 0.3119 - val_digit1_accuracy: 0.9092 - val_digit2_accuracy: 0.8970\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4785 - digit1_loss: 0.2304 - digit2_loss: 0.2481 - digit1_accuracy: 0.9232 - digit2_accuracy: 0.9165 - val_loss: 0.5688 - val_digit1_loss: 0.2714 - val_digit2_loss: 0.2974 - val_digit1_accuracy: 0.9133 - val_digit2_accuracy: 0.9024\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4188 - digit1_loss: 0.2019 - digit2_loss: 0.2169 - digit1_accuracy: 0.9330 - digit2_accuracy: 0.9259 - val_loss: 0.5460 - val_digit1_loss: 0.2613 - val_digit2_loss: 0.2847 - val_digit1_accuracy: 0.9147 - val_digit2_accuracy: 0.9065\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3684 - digit1_loss: 0.1777 - digit2_loss: 0.1907 - digit1_accuracy: 0.9407 - digit2_accuracy: 0.9353 - val_loss: 0.5743 - val_digit1_loss: 0.2700 - val_digit2_loss: 0.3043 - val_digit1_accuracy: 0.9168 - val_digit2_accuracy: 0.9068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:21:18,019]\u001b[0m Trial 30 finished with value: 0.5742729306221008 and parameters: {'kernel_size': 5, 'num_filters': 117, 'dropout_rate': 0.4532027294569246}. Best is trial 27 with value: 0.5655372142791748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.1166 - digit1_loss: 1.4566 - digit2_loss: 1.6601 - digit1_accuracy: 0.4896 - digit2_accuracy: 0.4020 - val_loss: 1.8279 - val_digit1_loss: 0.8043 - val_digit2_loss: 1.0236 - val_digit1_accuracy: 0.7378 - val_digit2_accuracy: 0.6613\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7712 - digit1_loss: 0.8029 - digit2_loss: 0.9683 - digit1_accuracy: 0.7282 - digit2_accuracy: 0.6676 - val_loss: 1.1727 - val_digit1_loss: 0.5439 - val_digit2_loss: 0.6288 - val_digit1_accuracy: 0.8198 - val_digit2_accuracy: 0.8029\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3047 - digit1_loss: 0.6030 - digit2_loss: 0.7017 - digit1_accuracy: 0.8003 - digit2_accuracy: 0.7646 - val_loss: 0.9114 - val_digit1_loss: 0.4162 - val_digit2_loss: 0.4952 - val_digit1_accuracy: 0.8626 - val_digit2_accuracy: 0.8365\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0302 - digit1_loss: 0.4767 - digit2_loss: 0.5535 - digit1_accuracy: 0.8429 - digit2_accuracy: 0.8198 - val_loss: 0.7652 - val_digit1_loss: 0.3546 - val_digit2_loss: 0.4105 - val_digit1_accuracy: 0.8804 - val_digit2_accuracy: 0.8666\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8456 - digit1_loss: 0.3957 - digit2_loss: 0.4499 - digit1_accuracy: 0.8686 - digit2_accuracy: 0.8516 - val_loss: 0.7282 - val_digit1_loss: 0.3473 - val_digit2_loss: 0.3808 - val_digit1_accuracy: 0.8848 - val_digit2_accuracy: 0.8790\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7119 - digit1_loss: 0.3347 - digit2_loss: 0.3772 - digit1_accuracy: 0.8901 - digit2_accuracy: 0.8746 - val_loss: 0.6308 - val_digit1_loss: 0.2898 - val_digit2_loss: 0.3410 - val_digit1_accuracy: 0.9013 - val_digit2_accuracy: 0.8878\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6067 - digit1_loss: 0.2858 - digit2_loss: 0.3209 - digit1_accuracy: 0.9043 - digit2_accuracy: 0.8947 - val_loss: 0.6138 - val_digit1_loss: 0.2851 - val_digit2_loss: 0.3287 - val_digit1_accuracy: 0.9062 - val_digit2_accuracy: 0.8937\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5217 - digit1_loss: 0.2465 - digit2_loss: 0.2752 - digit1_accuracy: 0.9190 - digit2_accuracy: 0.9092 - val_loss: 0.6409 - val_digit1_loss: 0.3054 - val_digit2_loss: 0.3355 - val_digit1_accuracy: 0.9046 - val_digit2_accuracy: 0.8945\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4620 - digit1_loss: 0.2185 - digit2_loss: 0.2435 - digit1_accuracy: 0.9264 - digit2_accuracy: 0.9189 - val_loss: 0.6063 - val_digit1_loss: 0.2866 - val_digit2_loss: 0.3197 - val_digit1_accuracy: 0.9101 - val_digit2_accuracy: 0.8998\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4078 - digit1_loss: 0.1920 - digit2_loss: 0.2158 - digit1_accuracy: 0.9355 - digit2_accuracy: 0.9269 - val_loss: 0.5959 - val_digit1_loss: 0.2791 - val_digit2_loss: 0.3169 - val_digit1_accuracy: 0.9111 - val_digit2_accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:21:58,003]\u001b[0m Trial 31 finished with value: 0.5959402918815613 and parameters: {'kernel_size': 5, 'num_filters': 119, 'dropout_rate': 0.4566323463422974}. Best is trial 27 with value: 0.5655372142791748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 2.8846 - digit1_loss: 1.3421 - digit2_loss: 1.5424 - digit1_accuracy: 0.5272 - digit2_accuracy: 0.4437 - val_loss: 1.5854 - val_digit1_loss: 0.6979 - val_digit2_loss: 0.8875 - val_digit1_accuracy: 0.7673 - val_digit2_accuracy: 0.7164\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4946 - digit1_loss: 0.6877 - digit2_loss: 0.8069 - digit1_accuracy: 0.7677 - digit2_accuracy: 0.7270 - val_loss: 1.0025 - val_digit1_loss: 0.4681 - val_digit2_loss: 0.5344 - val_digit1_accuracy: 0.8442 - val_digit2_accuracy: 0.8275\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0635 - digit1_loss: 0.4959 - digit2_loss: 0.5675 - digit1_accuracy: 0.8338 - digit2_accuracy: 0.8127 - val_loss: 0.8020 - val_digit1_loss: 0.3749 - val_digit2_loss: 0.4271 - val_digit1_accuracy: 0.8742 - val_digit2_accuracy: 0.8561\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8384 - digit1_loss: 0.3948 - digit2_loss: 0.4436 - digit1_accuracy: 0.8684 - digit2_accuracy: 0.8552 - val_loss: 0.6851 - val_digit1_loss: 0.3211 - val_digit2_loss: 0.3640 - val_digit1_accuracy: 0.8934 - val_digit2_accuracy: 0.8782\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6919 - digit1_loss: 0.3250 - digit2_loss: 0.3669 - digit1_accuracy: 0.8934 - digit2_accuracy: 0.8791 - val_loss: 0.6284 - val_digit1_loss: 0.2972 - val_digit2_loss: 0.3312 - val_digit1_accuracy: 0.9012 - val_digit2_accuracy: 0.8924\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5806 - digit1_loss: 0.2739 - digit2_loss: 0.3068 - digit1_accuracy: 0.9082 - digit2_accuracy: 0.8986 - val_loss: 0.6303 - val_digit1_loss: 0.3071 - val_digit2_loss: 0.3232 - val_digit1_accuracy: 0.8979 - val_digit2_accuracy: 0.8957\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4979 - digit1_loss: 0.2366 - digit2_loss: 0.2613 - digit1_accuracy: 0.9211 - digit2_accuracy: 0.9125 - val_loss: 0.5876 - val_digit1_loss: 0.2849 - val_digit2_loss: 0.3028 - val_digit1_accuracy: 0.9078 - val_digit2_accuracy: 0.9053\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4333 - digit1_loss: 0.2057 - digit2_loss: 0.2277 - digit1_accuracy: 0.9309 - digit2_accuracy: 0.9236 - val_loss: 0.5759 - val_digit1_loss: 0.2798 - val_digit2_loss: 0.2961 - val_digit1_accuracy: 0.9098 - val_digit2_accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3726 - digit1_loss: 0.1749 - digit2_loss: 0.1977 - digit1_accuracy: 0.9410 - digit2_accuracy: 0.9342 - val_loss: 0.5834 - val_digit1_loss: 0.2691 - val_digit2_loss: 0.3142 - val_digit1_accuracy: 0.9176 - val_digit2_accuracy: 0.9025\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3312 - digit1_loss: 0.1552 - digit2_loss: 0.1759 - digit1_accuracy: 0.9476 - digit2_accuracy: 0.9411 - val_loss: 0.5910 - val_digit1_loss: 0.2818 - val_digit2_loss: 0.3092 - val_digit1_accuracy: 0.9154 - val_digit2_accuracy: 0.9082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:22:37,378]\u001b[0m Trial 32 finished with value: 0.5909639596939087 and parameters: {'kernel_size': 5, 'num_filters': 109, 'dropout_rate': 0.3796413902782618}. Best is trial 27 with value: 0.5655372142791748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.3213 - digit1_loss: 1.5450 - digit2_loss: 1.7763 - digit1_accuracy: 0.4497 - digit2_accuracy: 0.3426 - val_loss: 1.9965 - val_digit1_loss: 0.8630 - val_digit2_loss: 1.1335 - val_digit1_accuracy: 0.7162 - val_digit2_accuracy: 0.6317\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8857 - digit1_loss: 0.8496 - digit2_loss: 1.0362 - digit1_accuracy: 0.7126 - digit2_accuracy: 0.6417 - val_loss: 1.2134 - val_digit1_loss: 0.5427 - val_digit2_loss: 0.6707 - val_digit1_accuracy: 0.8249 - val_digit2_accuracy: 0.7903\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3610 - digit1_loss: 0.6268 - digit2_loss: 0.7341 - digit1_accuracy: 0.7913 - digit2_accuracy: 0.7539 - val_loss: 0.9339 - val_digit1_loss: 0.4231 - val_digit2_loss: 0.5107 - val_digit1_accuracy: 0.8637 - val_digit2_accuracy: 0.8351\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0950 - digit1_loss: 0.5123 - digit2_loss: 0.5827 - digit1_accuracy: 0.8301 - digit2_accuracy: 0.8079 - val_loss: 0.7786 - val_digit1_loss: 0.3528 - val_digit2_loss: 0.4258 - val_digit1_accuracy: 0.8863 - val_digit2_accuracy: 0.8602\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9014 - digit1_loss: 0.4254 - digit2_loss: 0.4761 - digit1_accuracy: 0.8590 - digit2_accuracy: 0.8416 - val_loss: 0.6887 - val_digit1_loss: 0.3218 - val_digit2_loss: 0.3670 - val_digit1_accuracy: 0.8949 - val_digit2_accuracy: 0.8784\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7828 - digit1_loss: 0.3702 - digit2_loss: 0.4127 - digit1_accuracy: 0.8772 - digit2_accuracy: 0.8645 - val_loss: 0.6831 - val_digit1_loss: 0.3233 - val_digit2_loss: 0.3599 - val_digit1_accuracy: 0.8938 - val_digit2_accuracy: 0.8819\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6796 - digit1_loss: 0.3270 - digit2_loss: 0.3526 - digit1_accuracy: 0.8930 - digit2_accuracy: 0.8851 - val_loss: 0.6334 - val_digit1_loss: 0.2950 - val_digit2_loss: 0.3384 - val_digit1_accuracy: 0.9038 - val_digit2_accuracy: 0.8925\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5932 - digit1_loss: 0.2865 - digit2_loss: 0.3067 - digit1_accuracy: 0.9059 - digit2_accuracy: 0.8989 - val_loss: 0.6058 - val_digit1_loss: 0.2860 - val_digit2_loss: 0.3198 - val_digit1_accuracy: 0.9073 - val_digit2_accuracy: 0.8959\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5364 - digit1_loss: 0.2615 - digit2_loss: 0.2748 - digit1_accuracy: 0.9137 - digit2_accuracy: 0.9087 - val_loss: 0.5824 - val_digit1_loss: 0.2678 - val_digit2_loss: 0.3147 - val_digit1_accuracy: 0.9122 - val_digit2_accuracy: 0.9006\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4680 - digit1_loss: 0.2241 - digit2_loss: 0.2440 - digit1_accuracy: 0.9251 - digit2_accuracy: 0.9168 - val_loss: 0.5846 - val_digit1_loss: 0.2781 - val_digit2_loss: 0.3065 - val_digit1_accuracy: 0.9133 - val_digit2_accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:23:16,781]\u001b[0m Trial 33 finished with value: 0.584572970867157 and parameters: {'kernel_size': 5, 'num_filters': 109, 'dropout_rate': 0.4668393079731908}. Best is trial 27 with value: 0.5655372142791748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.1361 - digit1_loss: 1.4707 - digit2_loss: 1.6654 - digit1_accuracy: 0.4786 - digit2_accuracy: 0.3960 - val_loss: 1.7969 - val_digit1_loss: 0.7927 - val_digit2_loss: 1.0042 - val_digit1_accuracy: 0.7424 - val_digit2_accuracy: 0.6731\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7994 - digit1_loss: 0.8259 - digit2_loss: 0.9734 - digit1_accuracy: 0.7183 - digit2_accuracy: 0.6658 - val_loss: 1.2131 - val_digit1_loss: 0.5621 - val_digit2_loss: 0.6510 - val_digit1_accuracy: 0.8183 - val_digit2_accuracy: 0.7987\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3459 - digit1_loss: 0.6292 - digit2_loss: 0.7167 - digit1_accuracy: 0.7898 - digit2_accuracy: 0.7567 - val_loss: 0.9121 - val_digit1_loss: 0.4251 - val_digit2_loss: 0.4870 - val_digit1_accuracy: 0.8612 - val_digit2_accuracy: 0.8404\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0808 - digit1_loss: 0.5059 - digit2_loss: 0.5749 - digit1_accuracy: 0.8302 - digit2_accuracy: 0.8093 - val_loss: 0.7395 - val_digit1_loss: 0.3423 - val_digit2_loss: 0.3972 - val_digit1_accuracy: 0.8874 - val_digit2_accuracy: 0.8695\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8939 - digit1_loss: 0.4218 - digit2_loss: 0.4721 - digit1_accuracy: 0.8593 - digit2_accuracy: 0.8426 - val_loss: 0.6637 - val_digit1_loss: 0.3073 - val_digit2_loss: 0.3564 - val_digit1_accuracy: 0.8935 - val_digit2_accuracy: 0.8813\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7680 - digit1_loss: 0.3629 - digit2_loss: 0.4050 - digit1_accuracy: 0.8800 - digit2_accuracy: 0.8663 - val_loss: 0.6620 - val_digit1_loss: 0.3279 - val_digit2_loss: 0.3341 - val_digit1_accuracy: 0.8931 - val_digit2_accuracy: 0.8898\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6632 - digit1_loss: 0.3174 - digit2_loss: 0.3458 - digit1_accuracy: 0.8945 - digit2_accuracy: 0.8875 - val_loss: 0.6096 - val_digit1_loss: 0.2800 - val_digit2_loss: 0.3296 - val_digit1_accuracy: 0.9066 - val_digit2_accuracy: 0.8923\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5789 - digit1_loss: 0.2777 - digit2_loss: 0.3012 - digit1_accuracy: 0.9063 - digit2_accuracy: 0.9003 - val_loss: 0.5781 - val_digit1_loss: 0.2769 - val_digit2_loss: 0.3012 - val_digit1_accuracy: 0.9118 - val_digit2_accuracy: 0.9008\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5115 - digit1_loss: 0.2466 - digit2_loss: 0.2649 - digit1_accuracy: 0.9162 - digit2_accuracy: 0.9118 - val_loss: 0.5665 - val_digit1_loss: 0.2804 - val_digit2_loss: 0.2861 - val_digit1_accuracy: 0.9094 - val_digit2_accuracy: 0.9073\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4566 - digit1_loss: 0.2167 - digit2_loss: 0.2399 - digit1_accuracy: 0.9262 - digit2_accuracy: 0.9190 - val_loss: 0.5755 - val_digit1_loss: 0.2775 - val_digit2_loss: 0.2979 - val_digit1_accuracy: 0.9128 - val_digit2_accuracy: 0.9050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:23:57,870]\u001b[0m Trial 34 finished with value: 0.5754623413085938 and parameters: {'kernel_size': 5, 'num_filters': 121, 'dropout_rate': 0.4677555330302026}. Best is trial 27 with value: 0.5655372142791748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.0760 - digit1_loss: 1.4578 - digit2_loss: 1.6182 - digit1_accuracy: 0.4836 - digit2_accuracy: 0.4171 - val_loss: 1.7126 - val_digit1_loss: 0.7532 - val_digit2_loss: 0.9594 - val_digit1_accuracy: 0.7559 - val_digit2_accuracy: 0.6860\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6969 - digit1_loss: 0.7952 - digit2_loss: 0.9018 - digit1_accuracy: 0.7335 - digit2_accuracy: 0.6957 - val_loss: 1.0428 - val_digit1_loss: 0.4857 - val_digit2_loss: 0.5571 - val_digit1_accuracy: 0.8393 - val_digit2_accuracy: 0.8266\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2293 - digit1_loss: 0.5774 - digit2_loss: 0.6518 - digit1_accuracy: 0.8084 - digit2_accuracy: 0.7844 - val_loss: 0.8595 - val_digit1_loss: 0.3945 - val_digit2_loss: 0.4650 - val_digit1_accuracy: 0.8711 - val_digit2_accuracy: 0.8496\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9777 - digit1_loss: 0.4618 - digit2_loss: 0.5158 - digit1_accuracy: 0.8494 - digit2_accuracy: 0.8291 - val_loss: 0.7160 - val_digit1_loss: 0.3392 - val_digit2_loss: 0.3768 - val_digit1_accuracy: 0.8852 - val_digit2_accuracy: 0.8752\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8054 - digit1_loss: 0.3856 - digit2_loss: 0.4199 - digit1_accuracy: 0.8729 - digit2_accuracy: 0.8615 - val_loss: 0.6914 - val_digit1_loss: 0.3357 - val_digit2_loss: 0.3557 - val_digit1_accuracy: 0.8864 - val_digit2_accuracy: 0.8881\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6927 - digit1_loss: 0.3315 - digit2_loss: 0.3612 - digit1_accuracy: 0.8900 - digit2_accuracy: 0.8812 - val_loss: 0.6086 - val_digit1_loss: 0.2932 - val_digit2_loss: 0.3154 - val_digit1_accuracy: 0.9029 - val_digit2_accuracy: 0.8974\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5936 - digit1_loss: 0.2862 - digit2_loss: 0.3074 - digit1_accuracy: 0.9065 - digit2_accuracy: 0.8992 - val_loss: 0.5819 - val_digit1_loss: 0.2729 - val_digit2_loss: 0.3090 - val_digit1_accuracy: 0.9122 - val_digit2_accuracy: 0.9009\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5161 - digit1_loss: 0.2458 - digit2_loss: 0.2703 - digit1_accuracy: 0.9179 - digit2_accuracy: 0.9107 - val_loss: 0.5745 - val_digit1_loss: 0.2787 - val_digit2_loss: 0.2958 - val_digit1_accuracy: 0.9143 - val_digit2_accuracy: 0.9054\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4556 - digit1_loss: 0.2212 - digit2_loss: 0.2345 - digit1_accuracy: 0.9252 - digit2_accuracy: 0.9203 - val_loss: 0.5919 - val_digit1_loss: 0.2815 - val_digit2_loss: 0.3104 - val_digit1_accuracy: 0.9175 - val_digit2_accuracy: 0.9104\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4149 - digit1_loss: 0.1970 - digit2_loss: 0.2179 - digit1_accuracy: 0.9346 - digit2_accuracy: 0.9279 - val_loss: 0.5531 - val_digit1_loss: 0.2635 - val_digit2_loss: 0.2895 - val_digit1_accuracy: 0.9194 - val_digit2_accuracy: 0.9135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:24:38,157]\u001b[0m Trial 35 finished with value: 0.5530703663825989 and parameters: {'kernel_size': 5, 'num_filters': 124, 'dropout_rate': 0.4958595207926921}. Best is trial 35 with value: 0.5530703663825989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.1388 - digit1_loss: 1.4748 - digit2_loss: 1.6641 - digit1_accuracy: 0.4799 - digit2_accuracy: 0.3882 - val_loss: 1.8164 - val_digit1_loss: 0.8055 - val_digit2_loss: 1.0109 - val_digit1_accuracy: 0.7387 - val_digit2_accuracy: 0.6695\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7704 - digit1_loss: 0.8153 - digit2_loss: 0.9551 - digit1_accuracy: 0.7251 - digit2_accuracy: 0.6690 - val_loss: 1.0915 - val_digit1_loss: 0.4935 - val_digit2_loss: 0.5980 - val_digit1_accuracy: 0.8426 - val_digit2_accuracy: 0.8082\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2861 - digit1_loss: 0.6024 - digit2_loss: 0.6837 - digit1_accuracy: 0.7994 - digit2_accuracy: 0.7713 - val_loss: 0.8485 - val_digit1_loss: 0.4064 - val_digit2_loss: 0.4420 - val_digit1_accuracy: 0.8665 - val_digit2_accuracy: 0.8611\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9892 - digit1_loss: 0.4683 - digit2_loss: 0.5209 - digit1_accuracy: 0.8458 - digit2_accuracy: 0.8276 - val_loss: 0.7338 - val_digit1_loss: 0.3583 - val_digit2_loss: 0.3756 - val_digit1_accuracy: 0.8817 - val_digit2_accuracy: 0.8765\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8139 - digit1_loss: 0.3877 - digit2_loss: 0.4262 - digit1_accuracy: 0.8729 - digit2_accuracy: 0.8584 - val_loss: 0.6460 - val_digit1_loss: 0.3002 - val_digit2_loss: 0.3458 - val_digit1_accuracy: 0.9003 - val_digit2_accuracy: 0.8820\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6777 - digit1_loss: 0.3197 - digit2_loss: 0.3581 - digit1_accuracy: 0.8960 - digit2_accuracy: 0.8819 - val_loss: 0.5871 - val_digit1_loss: 0.2818 - val_digit2_loss: 0.3053 - val_digit1_accuracy: 0.9057 - val_digit2_accuracy: 0.9006\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5787 - digit1_loss: 0.2754 - digit2_loss: 0.3033 - digit1_accuracy: 0.9091 - digit2_accuracy: 0.8989 - val_loss: 0.5686 - val_digit1_loss: 0.2772 - val_digit2_loss: 0.2914 - val_digit1_accuracy: 0.9070 - val_digit2_accuracy: 0.9052\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5025 - digit1_loss: 0.2409 - digit2_loss: 0.2616 - digit1_accuracy: 0.9205 - digit2_accuracy: 0.9123 - val_loss: 0.5906 - val_digit1_loss: 0.2860 - val_digit2_loss: 0.3046 - val_digit1_accuracy: 0.9096 - val_digit2_accuracy: 0.9021\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4437 - digit1_loss: 0.2141 - digit2_loss: 0.2296 - digit1_accuracy: 0.9274 - digit2_accuracy: 0.9225 - val_loss: 0.5810 - val_digit1_loss: 0.2797 - val_digit2_loss: 0.3014 - val_digit1_accuracy: 0.9121 - val_digit2_accuracy: 0.9047\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3847 - digit1_loss: 0.1842 - digit2_loss: 0.2005 - digit1_accuracy: 0.9386 - digit2_accuracy: 0.9331 - val_loss: 0.5606 - val_digit1_loss: 0.2601 - val_digit2_loss: 0.3004 - val_digit1_accuracy: 0.9160 - val_digit2_accuracy: 0.9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:25:17,815]\u001b[0m Trial 36 finished with value: 0.5605815052986145 and parameters: {'kernel_size': 5, 'num_filters': 128, 'dropout_rate': 0.49709419048961645}. Best is trial 35 with value: 0.5530703663825989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.4667 - digit1_loss: 1.6663 - digit2_loss: 1.8004 - digit1_accuracy: 0.4088 - digit2_accuracy: 0.3447 - val_loss: 2.5097 - val_digit1_loss: 1.1617 - val_digit2_loss: 1.3481 - val_digit1_accuracy: 0.6028 - val_digit2_accuracy: 0.5377\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.4577 - digit1_loss: 1.1702 - digit2_loss: 1.2875 - digit1_accuracy: 0.6016 - digit2_accuracy: 0.5547 - val_loss: 1.9703 - val_digit1_loss: 0.9264 - val_digit2_loss: 1.0439 - val_digit1_accuracy: 0.6859 - val_digit2_accuracy: 0.6454\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.0864 - digit1_loss: 1.0001 - digit2_loss: 1.0863 - digit1_accuracy: 0.6629 - digit2_accuracy: 0.6316 - val_loss: 1.7485 - val_digit1_loss: 0.8281 - val_digit2_loss: 0.9205 - val_digit1_accuracy: 0.7236 - val_digit2_accuracy: 0.6963\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8516 - digit1_loss: 0.8929 - digit2_loss: 0.9587 - digit1_accuracy: 0.7000 - digit2_accuracy: 0.6792 - val_loss: 1.5751 - val_digit1_loss: 0.7559 - val_digit2_loss: 0.8192 - val_digit1_accuracy: 0.7442 - val_digit2_accuracy: 0.7261\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6829 - digit1_loss: 0.8136 - digit2_loss: 0.8693 - digit1_accuracy: 0.7275 - digit2_accuracy: 0.7103 - val_loss: 1.4876 - val_digit1_loss: 0.7159 - val_digit2_loss: 0.7716 - val_digit1_accuracy: 0.7598 - val_digit2_accuracy: 0.7452\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5477 - digit1_loss: 0.7472 - digit2_loss: 0.8005 - digit1_accuracy: 0.7463 - digit2_accuracy: 0.7311 - val_loss: 1.4150 - val_digit1_loss: 0.6821 - val_digit2_loss: 0.7329 - val_digit1_accuracy: 0.7695 - val_digit2_accuracy: 0.7546\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4339 - digit1_loss: 0.6948 - digit2_loss: 0.7390 - digit1_accuracy: 0.7635 - digit2_accuracy: 0.7534 - val_loss: 1.4219 - val_digit1_loss: 0.7006 - val_digit2_loss: 0.7212 - val_digit1_accuracy: 0.7639 - val_digit2_accuracy: 0.7583\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3392 - digit1_loss: 0.6493 - digit2_loss: 0.6899 - digit1_accuracy: 0.7802 - digit2_accuracy: 0.7665 - val_loss: 1.3552 - val_digit1_loss: 0.6586 - val_digit2_loss: 0.6966 - val_digit1_accuracy: 0.7752 - val_digit2_accuracy: 0.7671\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2503 - digit1_loss: 0.6064 - digit2_loss: 0.6438 - digit1_accuracy: 0.7946 - digit2_accuracy: 0.7828 - val_loss: 1.3255 - val_digit1_loss: 0.6435 - val_digit2_loss: 0.6820 - val_digit1_accuracy: 0.7817 - val_digit2_accuracy: 0.7757\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1877 - digit1_loss: 0.5746 - digit2_loss: 0.6131 - digit1_accuracy: 0.8042 - digit2_accuracy: 0.7937 - val_loss: 1.2944 - val_digit1_loss: 0.6268 - val_digit2_loss: 0.6676 - val_digit1_accuracy: 0.7859 - val_digit2_accuracy: 0.7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:25:58,021]\u001b[0m Trial 37 finished with value: 1.2943828105926514 and parameters: {'kernel_size': 4, 'num_filters': 126, 'dropout_rate': 0.49602194452146736}. Best is trial 35 with value: 0.5530703663825989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.1711 - digit1_loss: 1.4903 - digit2_loss: 1.6809 - digit1_accuracy: 0.4730 - digit2_accuracy: 0.3882 - val_loss: 1.8054 - val_digit1_loss: 0.8047 - val_digit2_loss: 1.0008 - val_digit1_accuracy: 0.7308 - val_digit2_accuracy: 0.6790\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8081 - digit1_loss: 0.8306 - digit2_loss: 0.9775 - digit1_accuracy: 0.7178 - digit2_accuracy: 0.6631 - val_loss: 1.1155 - val_digit1_loss: 0.5116 - val_digit2_loss: 0.6039 - val_digit1_accuracy: 0.8331 - val_digit2_accuracy: 0.8119\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3291 - digit1_loss: 0.6189 - digit2_loss: 0.7102 - digit1_accuracy: 0.7935 - digit2_accuracy: 0.7610 - val_loss: 0.9100 - val_digit1_loss: 0.4239 - val_digit2_loss: 0.4862 - val_digit1_accuracy: 0.8599 - val_digit2_accuracy: 0.8457\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0610 - digit1_loss: 0.5052 - digit2_loss: 0.5558 - digit1_accuracy: 0.8329 - digit2_accuracy: 0.8143 - val_loss: 0.7412 - val_digit1_loss: 0.3491 - val_digit2_loss: 0.3921 - val_digit1_accuracy: 0.8843 - val_digit2_accuracy: 0.8752\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8753 - digit1_loss: 0.4156 - digit2_loss: 0.4598 - digit1_accuracy: 0.8627 - digit2_accuracy: 0.8468 - val_loss: 0.7137 - val_digit1_loss: 0.3455 - val_digit2_loss: 0.3683 - val_digit1_accuracy: 0.8884 - val_digit2_accuracy: 0.8776\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7528 - digit1_loss: 0.3606 - digit2_loss: 0.3922 - digit1_accuracy: 0.8799 - digit2_accuracy: 0.8700 - val_loss: 0.6048 - val_digit1_loss: 0.2879 - val_digit2_loss: 0.3169 - val_digit1_accuracy: 0.9042 - val_digit2_accuracy: 0.8953\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6405 - digit1_loss: 0.3094 - digit2_loss: 0.3312 - digit1_accuracy: 0.8974 - digit2_accuracy: 0.8890 - val_loss: 0.5832 - val_digit1_loss: 0.2794 - val_digit2_loss: 0.3038 - val_digit1_accuracy: 0.9097 - val_digit2_accuracy: 0.9047\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5690 - digit1_loss: 0.2729 - digit2_loss: 0.2961 - digit1_accuracy: 0.9095 - digit2_accuracy: 0.9024 - val_loss: 0.5892 - val_digit1_loss: 0.2867 - val_digit2_loss: 0.3025 - val_digit1_accuracy: 0.9091 - val_digit2_accuracy: 0.9012\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5027 - digit1_loss: 0.2458 - digit2_loss: 0.2569 - digit1_accuracy: 0.9178 - digit2_accuracy: 0.9145 - val_loss: 0.5528 - val_digit1_loss: 0.2669 - val_digit2_loss: 0.2860 - val_digit1_accuracy: 0.9169 - val_digit2_accuracy: 0.9110\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4472 - digit1_loss: 0.2183 - digit2_loss: 0.2289 - digit1_accuracy: 0.9258 - digit2_accuracy: 0.9237 - val_loss: 0.5645 - val_digit1_loss: 0.2670 - val_digit2_loss: 0.2976 - val_digit1_accuracy: 0.9172 - val_digit2_accuracy: 0.9078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:26:39,048]\u001b[0m Trial 38 finished with value: 0.5645385980606079 and parameters: {'kernel_size': 5, 'num_filters': 123, 'dropout_rate': 0.4960586853952015}. Best is trial 35 with value: 0.5530703663825989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.5390 - digit1_loss: 1.6992 - digit2_loss: 1.8399 - digit1_accuracy: 0.3949 - digit2_accuracy: 0.3316 - val_loss: 2.6318 - val_digit1_loss: 1.2344 - val_digit2_loss: 1.3974 - val_digit1_accuracy: 0.5740 - val_digit2_accuracy: 0.5305\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.5721 - digit1_loss: 1.2175 - digit2_loss: 1.3546 - digit1_accuracy: 0.5816 - digit2_accuracy: 0.5303 - val_loss: 2.0756 - val_digit1_loss: 0.9759 - val_digit2_loss: 1.0996 - val_digit1_accuracy: 0.6677 - val_digit2_accuracy: 0.6332\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.1906 - digit1_loss: 1.0425 - digit2_loss: 1.1481 - digit1_accuracy: 0.6447 - digit2_accuracy: 0.6094 - val_loss: 1.8209 - val_digit1_loss: 0.8623 - val_digit2_loss: 0.9586 - val_digit1_accuracy: 0.7161 - val_digit2_accuracy: 0.6887\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9479 - digit1_loss: 0.9310 - digit2_loss: 1.0169 - digit1_accuracy: 0.6874 - digit2_accuracy: 0.6537 - val_loss: 1.6635 - val_digit1_loss: 0.7971 - val_digit2_loss: 0.8664 - val_digit1_accuracy: 0.7321 - val_digit2_accuracy: 0.7087\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7681 - digit1_loss: 0.8443 - digit2_loss: 0.9238 - digit1_accuracy: 0.7143 - digit2_accuracy: 0.6868 - val_loss: 1.5441 - val_digit1_loss: 0.7380 - val_digit2_loss: 0.8061 - val_digit1_accuracy: 0.7512 - val_digit2_accuracy: 0.7317\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6318 - digit1_loss: 0.7805 - digit2_loss: 0.8513 - digit1_accuracy: 0.7360 - digit2_accuracy: 0.7124 - val_loss: 1.5100 - val_digit1_loss: 0.7294 - val_digit2_loss: 0.7806 - val_digit1_accuracy: 0.7528 - val_digit2_accuracy: 0.7357\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5168 - digit1_loss: 0.7271 - digit2_loss: 0.7898 - digit1_accuracy: 0.7526 - digit2_accuracy: 0.7326 - val_loss: 1.4578 - val_digit1_loss: 0.6994 - val_digit2_loss: 0.7585 - val_digit1_accuracy: 0.7623 - val_digit2_accuracy: 0.7408\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4336 - digit1_loss: 0.6881 - digit2_loss: 0.7455 - digit1_accuracy: 0.7663 - digit2_accuracy: 0.7470 - val_loss: 1.4047 - val_digit1_loss: 0.6723 - val_digit2_loss: 0.7323 - val_digit1_accuracy: 0.7673 - val_digit2_accuracy: 0.7546\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3468 - digit1_loss: 0.6441 - digit2_loss: 0.7027 - digit1_accuracy: 0.7816 - digit2_accuracy: 0.7615 - val_loss: 1.3561 - val_digit1_loss: 0.6469 - val_digit2_loss: 0.7091 - val_digit1_accuracy: 0.7778 - val_digit2_accuracy: 0.7611\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2771 - digit1_loss: 0.6109 - digit2_loss: 0.6663 - digit1_accuracy: 0.7908 - digit2_accuracy: 0.7736 - val_loss: 1.3532 - val_digit1_loss: 0.6530 - val_digit2_loss: 0.7001 - val_digit1_accuracy: 0.7779 - val_digit2_accuracy: 0.7623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:27:19,774]\u001b[0m Trial 39 finished with value: 1.3531653881072998 and parameters: {'kernel_size': 4, 'num_filters': 105, 'dropout_rate': 0.4991377474755065}. Best is trial 35 with value: 0.5530703663825989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.0274 - digit1_loss: 1.4198 - digit2_loss: 1.6076 - digit1_accuracy: 0.4956 - digit2_accuracy: 0.4124 - val_loss: 1.7603 - val_digit1_loss: 0.7864 - val_digit2_loss: 0.9738 - val_digit1_accuracy: 0.7392 - val_digit2_accuracy: 0.6798\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6919 - digit1_loss: 0.7845 - digit2_loss: 0.9073 - digit1_accuracy: 0.7326 - digit2_accuracy: 0.6893 - val_loss: 1.1168 - val_digit1_loss: 0.5163 - val_digit2_loss: 0.6005 - val_digit1_accuracy: 0.8338 - val_digit2_accuracy: 0.8114\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2281 - digit1_loss: 0.5748 - digit2_loss: 0.6534 - digit1_accuracy: 0.8077 - digit2_accuracy: 0.7818 - val_loss: 0.8608 - val_digit1_loss: 0.4056 - val_digit2_loss: 0.4552 - val_digit1_accuracy: 0.8670 - val_digit2_accuracy: 0.8553\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9617 - digit1_loss: 0.4516 - digit2_loss: 0.5101 - digit1_accuracy: 0.8520 - digit2_accuracy: 0.8314 - val_loss: 0.7179 - val_digit1_loss: 0.3386 - val_digit2_loss: 0.3794 - val_digit1_accuracy: 0.8861 - val_digit2_accuracy: 0.8732\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7895 - digit1_loss: 0.3739 - digit2_loss: 0.4156 - digit1_accuracy: 0.8747 - digit2_accuracy: 0.8619 - val_loss: 0.6296 - val_digit1_loss: 0.3012 - val_digit2_loss: 0.3284 - val_digit1_accuracy: 0.8995 - val_digit2_accuracy: 0.8911\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6626 - digit1_loss: 0.3155 - digit2_loss: 0.3471 - digit1_accuracy: 0.8945 - digit2_accuracy: 0.8847 - val_loss: 0.6112 - val_digit1_loss: 0.2898 - val_digit2_loss: 0.3214 - val_digit1_accuracy: 0.9046 - val_digit2_accuracy: 0.8928\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5714 - digit1_loss: 0.2702 - digit2_loss: 0.3012 - digit1_accuracy: 0.9092 - digit2_accuracy: 0.8985 - val_loss: 0.5815 - val_digit1_loss: 0.2748 - val_digit2_loss: 0.3067 - val_digit1_accuracy: 0.9108 - val_digit2_accuracy: 0.8994\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4893 - digit1_loss: 0.2341 - digit2_loss: 0.2553 - digit1_accuracy: 0.9209 - digit2_accuracy: 0.9143 - val_loss: 0.6244 - val_digit1_loss: 0.3294 - val_digit2_loss: 0.2950 - val_digit1_accuracy: 0.8961 - val_digit2_accuracy: 0.9068\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4257 - digit1_loss: 0.2015 - digit2_loss: 0.2242 - digit1_accuracy: 0.9316 - digit2_accuracy: 0.9245 - val_loss: 0.5517 - val_digit1_loss: 0.2653 - val_digit2_loss: 0.2864 - val_digit1_accuracy: 0.9146 - val_digit2_accuracy: 0.9086\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3807 - digit1_loss: 0.1794 - digit2_loss: 0.2013 - digit1_accuracy: 0.9392 - digit2_accuracy: 0.9313 - val_loss: 0.5548 - val_digit1_loss: 0.2705 - val_digit2_loss: 0.2843 - val_digit1_accuracy: 0.9197 - val_digit2_accuracy: 0.9133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:27:59,959]\u001b[0m Trial 40 finished with value: 0.5547700524330139 and parameters: {'kernel_size': 5, 'num_filters': 125, 'dropout_rate': 0.4214649414400315}. Best is trial 35 with value: 0.5530703663825989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.1175 - digit1_loss: 1.4770 - digit2_loss: 1.6405 - digit1_accuracy: 0.4725 - digit2_accuracy: 0.4072 - val_loss: 1.7915 - val_digit1_loss: 0.8012 - val_digit2_loss: 0.9903 - val_digit1_accuracy: 0.7293 - val_digit2_accuracy: 0.6768\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7173 - digit1_loss: 0.7900 - digit2_loss: 0.9273 - digit1_accuracy: 0.7308 - digit2_accuracy: 0.6831 - val_loss: 1.1408 - val_digit1_loss: 0.5260 - val_digit2_loss: 0.6148 - val_digit1_accuracy: 0.8222 - val_digit2_accuracy: 0.7984\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2644 - digit1_loss: 0.5860 - digit2_loss: 0.6784 - digit1_accuracy: 0.8046 - digit2_accuracy: 0.7737 - val_loss: 0.9045 - val_digit1_loss: 0.4226 - val_digit2_loss: 0.4819 - val_digit1_accuracy: 0.8653 - val_digit2_accuracy: 0.8439\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9857 - digit1_loss: 0.4580 - digit2_loss: 0.5277 - digit1_accuracy: 0.8475 - digit2_accuracy: 0.8249 - val_loss: 0.7616 - val_digit1_loss: 0.3570 - val_digit2_loss: 0.4046 - val_digit1_accuracy: 0.8810 - val_digit2_accuracy: 0.8653\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8193 - digit1_loss: 0.3888 - digit2_loss: 0.4305 - digit1_accuracy: 0.8712 - digit2_accuracy: 0.8569 - val_loss: 0.7318 - val_digit1_loss: 0.3502 - val_digit2_loss: 0.3816 - val_digit1_accuracy: 0.8813 - val_digit2_accuracy: 0.8733\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6907 - digit1_loss: 0.3261 - digit2_loss: 0.3646 - digit1_accuracy: 0.8909 - digit2_accuracy: 0.8773 - val_loss: 0.6887 - val_digit1_loss: 0.3243 - val_digit2_loss: 0.3644 - val_digit1_accuracy: 0.8938 - val_digit2_accuracy: 0.8806\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5967 - digit1_loss: 0.2870 - digit2_loss: 0.3098 - digit1_accuracy: 0.9044 - digit2_accuracy: 0.8971 - val_loss: 0.6036 - val_digit1_loss: 0.2840 - val_digit2_loss: 0.3196 - val_digit1_accuracy: 0.9064 - val_digit2_accuracy: 0.8988\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5202 - digit1_loss: 0.2464 - digit2_loss: 0.2739 - digit1_accuracy: 0.9187 - digit2_accuracy: 0.9081 - val_loss: 0.5842 - val_digit1_loss: 0.2793 - val_digit2_loss: 0.3049 - val_digit1_accuracy: 0.9110 - val_digit2_accuracy: 0.9026\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4535 - digit1_loss: 0.2144 - digit2_loss: 0.2391 - digit1_accuracy: 0.9276 - digit2_accuracy: 0.9203 - val_loss: 0.6052 - val_digit1_loss: 0.2827 - val_digit2_loss: 0.3224 - val_digit1_accuracy: 0.9109 - val_digit2_accuracy: 0.9022\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4026 - digit1_loss: 0.1922 - digit2_loss: 0.2103 - digit1_accuracy: 0.9348 - digit2_accuracy: 0.9287 - val_loss: 0.6338 - val_digit1_loss: 0.3020 - val_digit2_loss: 0.3318 - val_digit1_accuracy: 0.9107 - val_digit2_accuracy: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:28:41,031]\u001b[0m Trial 41 finished with value: 0.6337525844573975 and parameters: {'kernel_size': 5, 'num_filters': 123, 'dropout_rate': 0.42797534734002246}. Best is trial 35 with value: 0.5530703663825989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 2.9566 - digit1_loss: 1.3966 - digit2_loss: 1.5600 - digit1_accuracy: 0.5040 - digit2_accuracy: 0.4358 - val_loss: 1.6575 - val_digit1_loss: 0.7458 - val_digit2_loss: 0.9117 - val_digit1_accuracy: 0.7581 - val_digit2_accuracy: 0.7043\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5695 - digit1_loss: 0.7294 - digit2_loss: 0.8402 - digit1_accuracy: 0.7542 - digit2_accuracy: 0.7134 - val_loss: 1.0851 - val_digit1_loss: 0.5006 - val_digit2_loss: 0.5845 - val_digit1_accuracy: 0.8367 - val_digit2_accuracy: 0.8092\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1246 - digit1_loss: 0.5311 - digit2_loss: 0.5935 - digit1_accuracy: 0.8226 - digit2_accuracy: 0.8035 - val_loss: 0.8428 - val_digit1_loss: 0.3968 - val_digit2_loss: 0.4460 - val_digit1_accuracy: 0.8705 - val_digit2_accuracy: 0.8566\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8776 - digit1_loss: 0.4157 - digit2_loss: 0.4619 - digit1_accuracy: 0.8599 - digit2_accuracy: 0.8471 - val_loss: 0.7049 - val_digit1_loss: 0.3353 - val_digit2_loss: 0.3696 - val_digit1_accuracy: 0.8873 - val_digit2_accuracy: 0.8784\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7220 - digit1_loss: 0.3430 - digit2_loss: 0.3790 - digit1_accuracy: 0.8864 - digit2_accuracy: 0.8756 - val_loss: 0.6739 - val_digit1_loss: 0.3115 - val_digit2_loss: 0.3624 - val_digit1_accuracy: 0.8973 - val_digit2_accuracy: 0.8809\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6023 - digit1_loss: 0.2841 - digit2_loss: 0.3181 - digit1_accuracy: 0.9060 - digit2_accuracy: 0.8945 - val_loss: 0.6299 - val_digit1_loss: 0.2925 - val_digit2_loss: 0.3374 - val_digit1_accuracy: 0.9049 - val_digit2_accuracy: 0.8893\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5189 - digit1_loss: 0.2479 - digit2_loss: 0.2709 - digit1_accuracy: 0.9182 - digit2_accuracy: 0.9104 - val_loss: 0.5903 - val_digit1_loss: 0.2822 - val_digit2_loss: 0.3080 - val_digit1_accuracy: 0.9078 - val_digit2_accuracy: 0.9014\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4472 - digit1_loss: 0.2120 - digit2_loss: 0.2352 - digit1_accuracy: 0.9296 - digit2_accuracy: 0.9222 - val_loss: 0.6089 - val_digit1_loss: 0.2912 - val_digit2_loss: 0.3177 - val_digit1_accuracy: 0.9078 - val_digit2_accuracy: 0.8992\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3911 - digit1_loss: 0.1877 - digit2_loss: 0.2034 - digit1_accuracy: 0.9360 - digit2_accuracy: 0.9311 - val_loss: 0.6420 - val_digit1_loss: 0.2942 - val_digit2_loss: 0.3478 - val_digit1_accuracy: 0.9088 - val_digit2_accuracy: 0.8955\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3414 - digit1_loss: 0.1643 - digit2_loss: 0.1771 - digit1_accuracy: 0.9435 - digit2_accuracy: 0.9388 - val_loss: 0.6063 - val_digit1_loss: 0.2820 - val_digit2_loss: 0.3243 - val_digit1_accuracy: 0.9127 - val_digit2_accuracy: 0.9002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:29:20,508]\u001b[0m Trial 42 finished with value: 0.6062671542167664 and parameters: {'kernel_size': 5, 'num_filters': 128, 'dropout_rate': 0.38350956072942916}. Best is trial 35 with value: 0.5530703663825989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.1399 - digit1_loss: 1.4699 - digit2_loss: 1.6700 - digit1_accuracy: 0.4801 - digit2_accuracy: 0.3931 - val_loss: 1.8332 - val_digit1_loss: 0.8053 - val_digit2_loss: 1.0279 - val_digit1_accuracy: 0.7333 - val_digit2_accuracy: 0.6637\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7369 - digit1_loss: 0.7948 - digit2_loss: 0.9420 - digit1_accuracy: 0.7285 - digit2_accuracy: 0.6777 - val_loss: 1.0799 - val_digit1_loss: 0.4885 - val_digit2_loss: 0.5915 - val_digit1_accuracy: 0.8422 - val_digit2_accuracy: 0.8128\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2431 - digit1_loss: 0.5780 - digit2_loss: 0.6652 - digit1_accuracy: 0.8077 - digit2_accuracy: 0.7752 - val_loss: 0.8269 - val_digit1_loss: 0.3861 - val_digit2_loss: 0.4408 - val_digit1_accuracy: 0.8751 - val_digit2_accuracy: 0.8579\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9966 - digit1_loss: 0.4695 - digit2_loss: 0.5271 - digit1_accuracy: 0.8456 - digit2_accuracy: 0.8268 - val_loss: 0.7465 - val_digit1_loss: 0.3505 - val_digit2_loss: 0.3960 - val_digit1_accuracy: 0.8880 - val_digit2_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8219 - digit1_loss: 0.3865 - digit2_loss: 0.4354 - digit1_accuracy: 0.8722 - digit2_accuracy: 0.8571 - val_loss: 0.7248 - val_digit1_loss: 0.3598 - val_digit2_loss: 0.3651 - val_digit1_accuracy: 0.8804 - val_digit2_accuracy: 0.8808\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7103 - digit1_loss: 0.3328 - digit2_loss: 0.3775 - digit1_accuracy: 0.8894 - digit2_accuracy: 0.8764 - val_loss: 0.6117 - val_digit1_loss: 0.2888 - val_digit2_loss: 0.3228 - val_digit1_accuracy: 0.9038 - val_digit2_accuracy: 0.8925\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6021 - digit1_loss: 0.2840 - digit2_loss: 0.3181 - digit1_accuracy: 0.9049 - digit2_accuracy: 0.8959 - val_loss: 0.5721 - val_digit1_loss: 0.2762 - val_digit2_loss: 0.2959 - val_digit1_accuracy: 0.9092 - val_digit2_accuracy: 0.9023\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5260 - digit1_loss: 0.2489 - digit2_loss: 0.2771 - digit1_accuracy: 0.9168 - digit2_accuracy: 0.9085 - val_loss: 0.5746 - val_digit1_loss: 0.2765 - val_digit2_loss: 0.2981 - val_digit1_accuracy: 0.9111 - val_digit2_accuracy: 0.9064\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4686 - digit1_loss: 0.2218 - digit2_loss: 0.2468 - digit1_accuracy: 0.9262 - digit2_accuracy: 0.9166 - val_loss: 0.5537 - val_digit1_loss: 0.2645 - val_digit2_loss: 0.2892 - val_digit1_accuracy: 0.9154 - val_digit2_accuracy: 0.9105\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4129 - digit1_loss: 0.1973 - digit2_loss: 0.2156 - digit1_accuracy: 0.9330 - digit2_accuracy: 0.9278 - val_loss: 0.5292 - val_digit1_loss: 0.2567 - val_digit2_loss: 0.2725 - val_digit1_accuracy: 0.9199 - val_digit2_accuracy: 0.9165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:30:01,396]\u001b[0m Trial 43 finished with value: 0.5292015075683594 and parameters: {'kernel_size': 5, 'num_filters': 113, 'dropout_rate': 0.47592726919130585}. Best is trial 43 with value: 0.5292015075683594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.1095 - digit1_loss: 1.4600 - digit2_loss: 1.6495 - digit1_accuracy: 0.4858 - digit2_accuracy: 0.4006 - val_loss: 1.7426 - val_digit1_loss: 0.7712 - val_digit2_loss: 0.9714 - val_digit1_accuracy: 0.7484 - val_digit2_accuracy: 0.6823\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7377 - digit1_loss: 0.7968 - digit2_loss: 0.9409 - digit1_accuracy: 0.7309 - digit2_accuracy: 0.6749 - val_loss: 1.0828 - val_digit1_loss: 0.4945 - val_digit2_loss: 0.5883 - val_digit1_accuracy: 0.8424 - val_digit2_accuracy: 0.8109\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2519 - digit1_loss: 0.5825 - digit2_loss: 0.6694 - digit1_accuracy: 0.8091 - digit2_accuracy: 0.7778 - val_loss: 0.8320 - val_digit1_loss: 0.3919 - val_digit2_loss: 0.4401 - val_digit1_accuracy: 0.8713 - val_digit2_accuracy: 0.8596\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9737 - digit1_loss: 0.4544 - digit2_loss: 0.5193 - digit1_accuracy: 0.8512 - digit2_accuracy: 0.8284 - val_loss: 0.7414 - val_digit1_loss: 0.3566 - val_digit2_loss: 0.3848 - val_digit1_accuracy: 0.8842 - val_digit2_accuracy: 0.8705\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7959 - digit1_loss: 0.3745 - digit2_loss: 0.4215 - digit1_accuracy: 0.8766 - digit2_accuracy: 0.8614 - val_loss: 0.6535 - val_digit1_loss: 0.3095 - val_digit2_loss: 0.3440 - val_digit1_accuracy: 0.8966 - val_digit2_accuracy: 0.8814\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6624 - digit1_loss: 0.3077 - digit2_loss: 0.3547 - digit1_accuracy: 0.8982 - digit2_accuracy: 0.8828 - val_loss: 0.5903 - val_digit1_loss: 0.2802 - val_digit2_loss: 0.3101 - val_digit1_accuracy: 0.9050 - val_digit2_accuracy: 0.8970\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5709 - digit1_loss: 0.2700 - digit2_loss: 0.3009 - digit1_accuracy: 0.9104 - digit2_accuracy: 0.9009 - val_loss: 0.5741 - val_digit1_loss: 0.2755 - val_digit2_loss: 0.2986 - val_digit1_accuracy: 0.9114 - val_digit2_accuracy: 0.9023\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4991 - digit1_loss: 0.2359 - digit2_loss: 0.2633 - digit1_accuracy: 0.9213 - digit2_accuracy: 0.9113 - val_loss: 0.5640 - val_digit1_loss: 0.2745 - val_digit2_loss: 0.2895 - val_digit1_accuracy: 0.9128 - val_digit2_accuracy: 0.9057\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4287 - digit1_loss: 0.2010 - digit2_loss: 0.2278 - digit1_accuracy: 0.9325 - digit2_accuracy: 0.9222 - val_loss: 0.5876 - val_digit1_loss: 0.2812 - val_digit2_loss: 0.3063 - val_digit1_accuracy: 0.9162 - val_digit2_accuracy: 0.9039\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3925 - digit1_loss: 0.1862 - digit2_loss: 0.2062 - digit1_accuracy: 0.9377 - digit2_accuracy: 0.9316 - val_loss: 0.5742 - val_digit1_loss: 0.2769 - val_digit2_loss: 0.2973 - val_digit1_accuracy: 0.9164 - val_digit2_accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:30:42,335]\u001b[0m Trial 44 finished with value: 0.5741586685180664 and parameters: {'kernel_size': 5, 'num_filters': 123, 'dropout_rate': 0.4773618199796893}. Best is trial 43 with value: 0.5292015075683594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.3256 - digit1_loss: 1.5667 - digit2_loss: 1.7589 - digit1_accuracy: 0.4436 - digit2_accuracy: 0.3566 - val_loss: 1.9578 - val_digit1_loss: 0.8453 - val_digit2_loss: 1.1125 - val_digit1_accuracy: 0.7247 - val_digit2_accuracy: 0.6352\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.0310 - digit1_loss: 0.9244 - digit2_loss: 1.1065 - digit1_accuracy: 0.6856 - digit2_accuracy: 0.6163 - val_loss: 1.2837 - val_digit1_loss: 0.5789 - val_digit2_loss: 0.7048 - val_digit1_accuracy: 0.8157 - val_digit2_accuracy: 0.7818\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4857 - digit1_loss: 0.6880 - digit2_loss: 0.7977 - digit1_accuracy: 0.7681 - digit2_accuracy: 0.7282 - val_loss: 0.9703 - val_digit1_loss: 0.4372 - val_digit2_loss: 0.5331 - val_digit1_accuracy: 0.8562 - val_digit2_accuracy: 0.8290\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1520 - digit1_loss: 0.5463 - digit2_loss: 0.6058 - digit1_accuracy: 0.8193 - digit2_accuracy: 0.7981 - val_loss: 0.8321 - val_digit1_loss: 0.3893 - val_digit2_loss: 0.4427 - val_digit1_accuracy: 0.8721 - val_digit2_accuracy: 0.8555\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9433 - digit1_loss: 0.4464 - digit2_loss: 0.4970 - digit1_accuracy: 0.8530 - digit2_accuracy: 0.8372 - val_loss: 0.6945 - val_digit1_loss: 0.3254 - val_digit2_loss: 0.3691 - val_digit1_accuracy: 0.8917 - val_digit2_accuracy: 0.8795\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7922 - digit1_loss: 0.3800 - digit2_loss: 0.4122 - digit1_accuracy: 0.8744 - digit2_accuracy: 0.8634 - val_loss: 0.6438 - val_digit1_loss: 0.3069 - val_digit2_loss: 0.3369 - val_digit1_accuracy: 0.8988 - val_digit2_accuracy: 0.8894\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6793 - digit1_loss: 0.3229 - digit2_loss: 0.3564 - digit1_accuracy: 0.8917 - digit2_accuracy: 0.8838 - val_loss: 0.6013 - val_digit1_loss: 0.2925 - val_digit2_loss: 0.3088 - val_digit1_accuracy: 0.9051 - val_digit2_accuracy: 0.8985\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6014 - digit1_loss: 0.2874 - digit2_loss: 0.3140 - digit1_accuracy: 0.9023 - digit2_accuracy: 0.8966 - val_loss: 0.5888 - val_digit1_loss: 0.2842 - val_digit2_loss: 0.3046 - val_digit1_accuracy: 0.9086 - val_digit2_accuracy: 0.9004\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5258 - digit1_loss: 0.2532 - digit2_loss: 0.2725 - digit1_accuracy: 0.9153 - digit2_accuracy: 0.9083 - val_loss: 0.5674 - val_digit1_loss: 0.2755 - val_digit2_loss: 0.2919 - val_digit1_accuracy: 0.9122 - val_digit2_accuracy: 0.9079\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4687 - digit1_loss: 0.2235 - digit2_loss: 0.2452 - digit1_accuracy: 0.9253 - digit2_accuracy: 0.9192 - val_loss: 0.5925 - val_digit1_loss: 0.3033 - val_digit2_loss: 0.2893 - val_digit1_accuracy: 0.9099 - val_digit2_accuracy: 0.9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:31:23,001]\u001b[0m Trial 45 finished with value: 0.5925275087356567 and parameters: {'kernel_size': 5, 'num_filters': 113, 'dropout_rate': 0.4994871469617414}. Best is trial 43 with value: 0.5292015075683594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 3.1272 - digit1_loss: 1.4867 - digit2_loss: 1.6405 - digit1_accuracy: 0.4721 - digit2_accuracy: 0.4032 - val_loss: 1.7772 - val_digit1_loss: 0.8284 - val_digit2_loss: 0.9487 - val_digit1_accuracy: 0.7198 - val_digit2_accuracy: 0.6962\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7202 - digit1_loss: 0.8031 - digit2_loss: 0.9171 - digit1_accuracy: 0.7267 - digit2_accuracy: 0.6860 - val_loss: 1.1328 - val_digit1_loss: 0.5319 - val_digit2_loss: 0.6010 - val_digit1_accuracy: 0.8291 - val_digit2_accuracy: 0.8139\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2678 - digit1_loss: 0.6028 - digit2_loss: 0.6650 - digit1_accuracy: 0.7992 - digit2_accuracy: 0.7773 - val_loss: 0.8722 - val_digit1_loss: 0.4119 - val_digit2_loss: 0.4603 - val_digit1_accuracy: 0.8666 - val_digit2_accuracy: 0.8531\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0142 - digit1_loss: 0.4833 - digit2_loss: 0.5309 - digit1_accuracy: 0.8392 - digit2_accuracy: 0.8253 - val_loss: 0.7593 - val_digit1_loss: 0.3549 - val_digit2_loss: 0.4045 - val_digit1_accuracy: 0.8824 - val_digit2_accuracy: 0.8682\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8417 - digit1_loss: 0.3993 - digit2_loss: 0.4423 - digit1_accuracy: 0.8674 - digit2_accuracy: 0.8537 - val_loss: 0.6679 - val_digit1_loss: 0.3171 - val_digit2_loss: 0.3508 - val_digit1_accuracy: 0.8941 - val_digit2_accuracy: 0.8850\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.7226 - digit1_loss: 0.3481 - digit2_loss: 0.3745 - digit1_accuracy: 0.8842 - digit2_accuracy: 0.8751 - val_loss: 0.6296 - val_digit1_loss: 0.2998 - val_digit2_loss: 0.3298 - val_digit1_accuracy: 0.9004 - val_digit2_accuracy: 0.8921\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6264 - digit1_loss: 0.2999 - digit2_loss: 0.3264 - digit1_accuracy: 0.9005 - digit2_accuracy: 0.8911 - val_loss: 0.6152 - val_digit1_loss: 0.2937 - val_digit2_loss: 0.3215 - val_digit1_accuracy: 0.9032 - val_digit2_accuracy: 0.8938\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5516 - digit1_loss: 0.2669 - digit2_loss: 0.2847 - digit1_accuracy: 0.9111 - digit2_accuracy: 0.9063 - val_loss: 0.5800 - val_digit1_loss: 0.2761 - val_digit2_loss: 0.3039 - val_digit1_accuracy: 0.9098 - val_digit2_accuracy: 0.9013\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4883 - digit1_loss: 0.2368 - digit2_loss: 0.2515 - digit1_accuracy: 0.9190 - digit2_accuracy: 0.9131 - val_loss: 0.6021 - val_digit1_loss: 0.2909 - val_digit2_loss: 0.3113 - val_digit1_accuracy: 0.9060 - val_digit2_accuracy: 0.9003\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4451 - digit1_loss: 0.2157 - digit2_loss: 0.2293 - digit1_accuracy: 0.9260 - digit2_accuracy: 0.9237 - val_loss: 0.5690 - val_digit1_loss: 0.2782 - val_digit2_loss: 0.2908 - val_digit1_accuracy: 0.9124 - val_digit2_accuracy: 0.9089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:32:03,152]\u001b[0m Trial 46 finished with value: 0.5689681172370911 and parameters: {'kernel_size': 5, 'num_filters': 106, 'dropout_rate': 0.4766709560964869}. Best is trial 43 with value: 0.5292015075683594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.5147 - digit1_loss: 1.6889 - digit2_loss: 1.8259 - digit1_accuracy: 0.3967 - digit2_accuracy: 0.3354 - val_loss: 2.5972 - val_digit1_loss: 1.2060 - val_digit2_loss: 1.3912 - val_digit1_accuracy: 0.5817 - val_digit2_accuracy: 0.5146\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.5786 - digit1_loss: 1.2201 - digit2_loss: 1.3584 - digit1_accuracy: 0.5784 - digit2_accuracy: 0.5263 - val_loss: 2.1422 - val_digit1_loss: 0.9992 - val_digit2_loss: 1.1429 - val_digit1_accuracy: 0.6612 - val_digit2_accuracy: 0.6182\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2238 - digit1_loss: 1.0530 - digit2_loss: 1.1708 - digit1_accuracy: 0.6398 - digit2_accuracy: 0.5974 - val_loss: 1.8786 - val_digit1_loss: 0.8872 - val_digit2_loss: 0.9914 - val_digit1_accuracy: 0.7040 - val_digit2_accuracy: 0.6711\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9983 - digit1_loss: 0.9516 - digit2_loss: 1.0467 - digit1_accuracy: 0.6751 - digit2_accuracy: 0.6434 - val_loss: 1.7411 - val_digit1_loss: 0.8276 - val_digit2_loss: 0.9134 - val_digit1_accuracy: 0.7186 - val_digit2_accuracy: 0.6942\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8380 - digit1_loss: 0.8744 - digit2_loss: 0.9636 - digit1_accuracy: 0.7037 - digit2_accuracy: 0.6716 - val_loss: 1.6418 - val_digit1_loss: 0.7770 - val_digit2_loss: 0.8648 - val_digit1_accuracy: 0.7371 - val_digit2_accuracy: 0.7083\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7099 - digit1_loss: 0.8144 - digit2_loss: 0.8955 - digit1_accuracy: 0.7211 - digit2_accuracy: 0.6970 - val_loss: 1.5619 - val_digit1_loss: 0.7530 - val_digit2_loss: 0.8089 - val_digit1_accuracy: 0.7421 - val_digit2_accuracy: 0.7315\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6038 - digit1_loss: 0.7665 - digit2_loss: 0.8373 - digit1_accuracy: 0.7380 - digit2_accuracy: 0.7150 - val_loss: 1.5227 - val_digit1_loss: 0.7251 - val_digit2_loss: 0.7975 - val_digit1_accuracy: 0.7543 - val_digit2_accuracy: 0.7330\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5170 - digit1_loss: 0.7252 - digit2_loss: 0.7919 - digit1_accuracy: 0.7499 - digit2_accuracy: 0.7296 - val_loss: 1.4992 - val_digit1_loss: 0.7259 - val_digit2_loss: 0.7733 - val_digit1_accuracy: 0.7490 - val_digit2_accuracy: 0.7407\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4318 - digit1_loss: 0.6872 - digit2_loss: 0.7446 - digit1_accuracy: 0.7624 - digit2_accuracy: 0.7457 - val_loss: 1.4440 - val_digit1_loss: 0.6984 - val_digit2_loss: 0.7456 - val_digit1_accuracy: 0.7599 - val_digit2_accuracy: 0.7510\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3586 - digit1_loss: 0.6511 - digit2_loss: 0.7075 - digit1_accuracy: 0.7746 - digit2_accuracy: 0.7583 - val_loss: 1.4463 - val_digit1_loss: 0.6982 - val_digit2_loss: 0.7481 - val_digit1_accuracy: 0.7586 - val_digit2_accuracy: 0.7524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:32:42,116]\u001b[0m Trial 47 finished with value: 1.4463030099868774 and parameters: {'kernel_size': 4, 'num_filters': 84, 'dropout_rate': 0.4229864956152027}. Best is trial 43 with value: 0.5292015075683594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 3.3363 - digit1_loss: 1.5982 - digit2_loss: 1.7381 - digit1_accuracy: 0.4267 - digit2_accuracy: 0.3617 - val_loss: 2.4110 - val_digit1_loss: 1.1168 - val_digit2_loss: 1.2943 - val_digit1_accuracy: 0.6094 - val_digit2_accuracy: 0.5426\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.3240 - digit1_loss: 1.0830 - digit2_loss: 1.2410 - digit1_accuracy: 0.6237 - digit2_accuracy: 0.5596 - val_loss: 1.8656 - val_digit1_loss: 0.8634 - val_digit2_loss: 1.0022 - val_digit1_accuracy: 0.6958 - val_digit2_accuracy: 0.6616\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9201 - digit1_loss: 0.8910 - digit2_loss: 1.0291 - digit1_accuracy: 0.6912 - digit2_accuracy: 0.6410 - val_loss: 1.6080 - val_digit1_loss: 0.7456 - val_digit2_loss: 0.8624 - val_digit1_accuracy: 0.7450 - val_digit2_accuracy: 0.7141\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6665 - digit1_loss: 0.7758 - digit2_loss: 0.8908 - digit1_accuracy: 0.7323 - digit2_accuracy: 0.6932 - val_loss: 1.4671 - val_digit1_loss: 0.6808 - val_digit2_loss: 0.7863 - val_digit1_accuracy: 0.7628 - val_digit2_accuracy: 0.7371\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4860 - digit1_loss: 0.6884 - digit2_loss: 0.7976 - digit1_accuracy: 0.7620 - digit2_accuracy: 0.7272 - val_loss: 1.3347 - val_digit1_loss: 0.6215 - val_digit2_loss: 0.7132 - val_digit1_accuracy: 0.7824 - val_digit2_accuracy: 0.7594\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3397 - digit1_loss: 0.6254 - digit2_loss: 0.7143 - digit1_accuracy: 0.7821 - digit2_accuracy: 0.7568 - val_loss: 1.2827 - val_digit1_loss: 0.5959 - val_digit2_loss: 0.6868 - val_digit1_accuracy: 0.7943 - val_digit2_accuracy: 0.7705\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2224 - digit1_loss: 0.5728 - digit2_loss: 0.6495 - digit1_accuracy: 0.8012 - digit2_accuracy: 0.7787 - val_loss: 1.2762 - val_digit1_loss: 0.5835 - val_digit2_loss: 0.6928 - val_digit1_accuracy: 0.7984 - val_digit2_accuracy: 0.7702\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1228 - digit1_loss: 0.5304 - digit2_loss: 0.5923 - digit1_accuracy: 0.8147 - digit2_accuracy: 0.7972 - val_loss: 1.2206 - val_digit1_loss: 0.5719 - val_digit2_loss: 0.6487 - val_digit1_accuracy: 0.8011 - val_digit2_accuracy: 0.7826\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0341 - digit1_loss: 0.4859 - digit2_loss: 0.5482 - digit1_accuracy: 0.8289 - digit2_accuracy: 0.8110 - val_loss: 1.2398 - val_digit1_loss: 0.5721 - val_digit2_loss: 0.6677 - val_digit1_accuracy: 0.8043 - val_digit2_accuracy: 0.7780\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.9628 - digit1_loss: 0.4522 - digit2_loss: 0.5107 - digit1_accuracy: 0.8391 - digit2_accuracy: 0.8228 - val_loss: 1.1843 - val_digit1_loss: 0.5586 - val_digit2_loss: 0.6257 - val_digit1_accuracy: 0.8098 - val_digit2_accuracy: 0.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:33:21,307]\u001b[0m Trial 48 finished with value: 1.184295415878296 and parameters: {'kernel_size': 3, 'num_filters': 99, 'dropout_rate': 0.3321163746341075}. Best is trial 43 with value: 0.5292015075683594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 2.9804 - digit1_loss: 1.4003 - digit2_loss: 1.5802 - digit1_accuracy: 0.5051 - digit2_accuracy: 0.4312 - val_loss: 1.6300 - val_digit1_loss: 0.7332 - val_digit2_loss: 0.8968 - val_digit1_accuracy: 0.7578 - val_digit2_accuracy: 0.7117\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5419 - digit1_loss: 0.7217 - digit2_loss: 0.8202 - digit1_accuracy: 0.7554 - digit2_accuracy: 0.7212 - val_loss: 1.0490 - val_digit1_loss: 0.4795 - val_digit2_loss: 0.5695 - val_digit1_accuracy: 0.8406 - val_digit2_accuracy: 0.8159\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0860 - digit1_loss: 0.5107 - digit2_loss: 0.5753 - digit1_accuracy: 0.8285 - digit2_accuracy: 0.8096 - val_loss: 0.7727 - val_digit1_loss: 0.3670 - val_digit2_loss: 0.4057 - val_digit1_accuracy: 0.8804 - val_digit2_accuracy: 0.8659\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.8477 - digit1_loss: 0.4055 - digit2_loss: 0.4422 - digit1_accuracy: 0.8656 - digit2_accuracy: 0.8548 - val_loss: 0.7017 - val_digit1_loss: 0.3461 - val_digit2_loss: 0.3556 - val_digit1_accuracy: 0.8846 - val_digit2_accuracy: 0.8832\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.6914 - digit1_loss: 0.3320 - digit2_loss: 0.3595 - digit1_accuracy: 0.8902 - digit2_accuracy: 0.8809 - val_loss: 0.6446 - val_digit1_loss: 0.3128 - val_digit2_loss: 0.3318 - val_digit1_accuracy: 0.8970 - val_digit2_accuracy: 0.8894\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5769 - digit1_loss: 0.2754 - digit2_loss: 0.3015 - digit1_accuracy: 0.9100 - digit2_accuracy: 0.9011 - val_loss: 0.6177 - val_digit1_loss: 0.3063 - val_digit2_loss: 0.3114 - val_digit1_accuracy: 0.9001 - val_digit2_accuracy: 0.8981\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4838 - digit1_loss: 0.2319 - digit2_loss: 0.2519 - digit1_accuracy: 0.9227 - digit2_accuracy: 0.9154 - val_loss: 0.6111 - val_digit1_loss: 0.2959 - val_digit2_loss: 0.3152 - val_digit1_accuracy: 0.9074 - val_digit2_accuracy: 0.9024\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4139 - digit1_loss: 0.1974 - digit2_loss: 0.2165 - digit1_accuracy: 0.9346 - digit2_accuracy: 0.9278 - val_loss: 0.5795 - val_digit1_loss: 0.2891 - val_digit2_loss: 0.2904 - val_digit1_accuracy: 0.9068 - val_digit2_accuracy: 0.9073\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3646 - digit1_loss: 0.1755 - digit2_loss: 0.1890 - digit1_accuracy: 0.9413 - digit2_accuracy: 0.9365 - val_loss: 0.5994 - val_digit1_loss: 0.2907 - val_digit2_loss: 0.3087 - val_digit1_accuracy: 0.9150 - val_digit2_accuracy: 0.9055\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3221 - digit1_loss: 0.1549 - digit2_loss: 0.1672 - digit1_accuracy: 0.9474 - digit2_accuracy: 0.9429 - val_loss: 0.5919 - val_digit1_loss: 0.2752 - val_digit2_loss: 0.3166 - val_digit1_accuracy: 0.9161 - val_digit2_accuracy: 0.9056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 03:34:00,933]\u001b[0m Trial 49 finished with value: 0.5918611884117126 and parameters: {'kernel_size': 5, 'num_filters': 124, 'dropout_rate': 0.3842527552220268}. Best is trial 43 with value: 0.5292015075683594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value:  0.5292015075683594\n",
      "  Params: \n",
      "    kernel_size: 5\n",
      "    num_filters: 113\n",
      "    dropout_rate: 0.47592726919130585\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def optimize_model(trial):\n",
    "    # Define the hyperparameters that you want to optimize\n",
    "    kernel_size = trial.suggest_int('kernel_size', 2, 5)\n",
    "    num_filters = trial.suggest_int('num_filters', 8, 128)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0, 0.5)\n",
    "    \n",
    "    # Create the model with the optimized hyperparameters\n",
    "    inputs = Input(shape=(32, 32, 1))\n",
    "    x = Conv2D(num_filters, kernel_size=(kernel_size, kernel_size), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(num_filters*2, kernel_size=(kernel_size, kernel_size), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output1 = Dense(10, activation='softmax', name='digit1')(x)\n",
    "    output2 = Dense(10, activation='softmax', name='digit2')(x)\n",
    "    model = Model(inputs, [output1, output2])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model and return the validation loss\n",
    "    model.fit(train_X, [train_Y1, train_Y2], batch_size=64, epochs=10, validation_data=(test_X, [test_Y1, test_Y2]))\n",
    "    return model.evaluate(test_X, [test_Y1, test_Y2], verbose=0)[0]\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(optimize_model, n_trials=50)\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value: \", study.best_trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoW4jNEWpmBu"
   },
   "source": [
    "Best parameters are kernel_size = 5, num_filters = 113, and dropout_rate = 0.47592726919130585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWXT3aAHpuZk"
   },
   "source": [
    "# 5 fold cross-validation with best model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "OziRJ0jxuJSA",
    "outputId": "58765636-1892-4e5d-e6c2-d259bd63113d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/200\n",
      "750/750 [==============================] - 4s 4ms/step - loss: 3.1118 - digit1_loss: 1.4559 - digit2_loss: 1.6559 - digit1_accuracy: 0.4864 - digit2_accuracy: 0.3983\n",
      "Epoch 2/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.8091 - digit1_loss: 0.8252 - digit2_loss: 0.9840 - digit1_accuracy: 0.7195 - digit2_accuracy: 0.6628\n",
      "Epoch 3/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.3327 - digit1_loss: 0.6203 - digit2_loss: 0.7124 - digit1_accuracy: 0.7945 - digit2_accuracy: 0.7598\n",
      "Epoch 4/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.0591 - digit1_loss: 0.4999 - digit2_loss: 0.5592 - digit1_accuracy: 0.8343 - digit2_accuracy: 0.8149\n",
      "Epoch 5/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.8850 - digit1_loss: 0.4155 - digit2_loss: 0.4695 - digit1_accuracy: 0.8637 - digit2_accuracy: 0.8468\n",
      "Epoch 6/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7486 - digit1_loss: 0.3579 - digit2_loss: 0.3907 - digit1_accuracy: 0.8835 - digit2_accuracy: 0.8724\n",
      "Epoch 7/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6465 - digit1_loss: 0.3048 - digit2_loss: 0.3417 - digit1_accuracy: 0.8985 - digit2_accuracy: 0.8871\n",
      "Epoch 8/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.5654 - digit1_loss: 0.2708 - digit2_loss: 0.2946 - digit1_accuracy: 0.9104 - digit2_accuracy: 0.9024\n",
      "Epoch 9/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.4922 - digit1_loss: 0.2330 - digit2_loss: 0.2592 - digit1_accuracy: 0.9220 - digit2_accuracy: 0.9130\n",
      "Epoch 10/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.4332 - digit1_loss: 0.2069 - digit2_loss: 0.2263 - digit1_accuracy: 0.9289 - digit2_accuracy: 0.9254\n",
      "Epoch 11/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3935 - digit1_loss: 0.1869 - digit2_loss: 0.2066 - digit1_accuracy: 0.9365 - digit2_accuracy: 0.9301\n",
      "Epoch 12/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3505 - digit1_loss: 0.1659 - digit2_loss: 0.1846 - digit1_accuracy: 0.9445 - digit2_accuracy: 0.9381\n",
      "Epoch 13/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3237 - digit1_loss: 0.1545 - digit2_loss: 0.1692 - digit1_accuracy: 0.9461 - digit2_accuracy: 0.9439\n",
      "Epoch 14/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2890 - digit1_loss: 0.1380 - digit2_loss: 0.1510 - digit1_accuracy: 0.9522 - digit2_accuracy: 0.9478\n",
      "Epoch 15/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2706 - digit1_loss: 0.1298 - digit2_loss: 0.1408 - digit1_accuracy: 0.9543 - digit2_accuracy: 0.9516\n",
      "Epoch 16/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2442 - digit1_loss: 0.1160 - digit2_loss: 0.1282 - digit1_accuracy: 0.9602 - digit2_accuracy: 0.9564\n",
      "Epoch 17/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2317 - digit1_loss: 0.1117 - digit2_loss: 0.1200 - digit1_accuracy: 0.9611 - digit2_accuracy: 0.9590\n",
      "Epoch 18/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2150 - digit1_loss: 0.1032 - digit2_loss: 0.1119 - digit1_accuracy: 0.9643 - digit2_accuracy: 0.9611\n",
      "Epoch 19/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1999 - digit1_loss: 0.0962 - digit2_loss: 0.1037 - digit1_accuracy: 0.9664 - digit2_accuracy: 0.9653\n",
      "Epoch 20/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1882 - digit1_loss: 0.0905 - digit2_loss: 0.0977 - digit1_accuracy: 0.9678 - digit2_accuracy: 0.9666\n",
      "Epoch 21/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1848 - digit1_loss: 0.0876 - digit2_loss: 0.0971 - digit1_accuracy: 0.9700 - digit2_accuracy: 0.9671\n",
      "Epoch 22/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1782 - digit1_loss: 0.0880 - digit2_loss: 0.0902 - digit1_accuracy: 0.9697 - digit2_accuracy: 0.9692\n",
      "Epoch 23/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1595 - digit1_loss: 0.0746 - digit2_loss: 0.0849 - digit1_accuracy: 0.9740 - digit2_accuracy: 0.9704\n",
      "Epoch 24/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1498 - digit1_loss: 0.0717 - digit2_loss: 0.0781 - digit1_accuracy: 0.9749 - digit2_accuracy: 0.9733\n",
      "Epoch 25/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1494 - digit1_loss: 0.0718 - digit2_loss: 0.0775 - digit1_accuracy: 0.9751 - digit2_accuracy: 0.9739\n",
      "Epoch 26/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1426 - digit1_loss: 0.0685 - digit2_loss: 0.0740 - digit1_accuracy: 0.9764 - digit2_accuracy: 0.9754\n",
      "Epoch 27/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1479 - digit1_loss: 0.0703 - digit2_loss: 0.0776 - digit1_accuracy: 0.9771 - digit2_accuracy: 0.9733\n",
      "Epoch 28/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1323 - digit1_loss: 0.0645 - digit2_loss: 0.0678 - digit1_accuracy: 0.9787 - digit2_accuracy: 0.9770\n",
      "Epoch 29/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1342 - digit1_loss: 0.0678 - digit2_loss: 0.0664 - digit1_accuracy: 0.9775 - digit2_accuracy: 0.9772\n",
      "Epoch 30/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1250 - digit1_loss: 0.0590 - digit2_loss: 0.0660 - digit1_accuracy: 0.9800 - digit2_accuracy: 0.9784\n",
      "Epoch 31/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1207 - digit1_loss: 0.0560 - digit2_loss: 0.0647 - digit1_accuracy: 0.9813 - digit2_accuracy: 0.9782\n",
      "Epoch 32/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1227 - digit1_loss: 0.0623 - digit2_loss: 0.0604 - digit1_accuracy: 0.9804 - digit2_accuracy: 0.9793\n",
      "Epoch 33/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1085 - digit1_loss: 0.0520 - digit2_loss: 0.0565 - digit1_accuracy: 0.9826 - digit2_accuracy: 0.9801\n",
      "Epoch 34/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1052 - digit1_loss: 0.0502 - digit2_loss: 0.0549 - digit1_accuracy: 0.9833 - digit2_accuracy: 0.9810\n",
      "Epoch 35/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1060 - digit1_loss: 0.0505 - digit2_loss: 0.0555 - digit1_accuracy: 0.9830 - digit2_accuracy: 0.9806\n",
      "Epoch 36/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1101 - digit1_loss: 0.0546 - digit2_loss: 0.0555 - digit1_accuracy: 0.9820 - digit2_accuracy: 0.9815\n",
      "Epoch 37/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1033 - digit1_loss: 0.0513 - digit2_loss: 0.0520 - digit1_accuracy: 0.9832 - digit2_accuracy: 0.9828\n",
      "Epoch 38/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1040 - digit1_loss: 0.0483 - digit2_loss: 0.0558 - digit1_accuracy: 0.9839 - digit2_accuracy: 0.9816\n",
      "Epoch 39/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0948 - digit1_loss: 0.0464 - digit2_loss: 0.0485 - digit1_accuracy: 0.9845 - digit2_accuracy: 0.9830\n",
      "Epoch 40/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0956 - digit1_loss: 0.0445 - digit2_loss: 0.0511 - digit1_accuracy: 0.9854 - digit2_accuracy: 0.9824\n",
      "Epoch 41/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0911 - digit1_loss: 0.0457 - digit2_loss: 0.0455 - digit1_accuracy: 0.9844 - digit2_accuracy: 0.9849\n",
      "Epoch 42/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0851 - digit1_loss: 0.0416 - digit2_loss: 0.0435 - digit1_accuracy: 0.9867 - digit2_accuracy: 0.9857\n",
      "Epoch 43/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0902 - digit1_loss: 0.0426 - digit2_loss: 0.0476 - digit1_accuracy: 0.9853 - digit2_accuracy: 0.9841\n",
      "Epoch 44/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0874 - digit1_loss: 0.0443 - digit2_loss: 0.0431 - digit1_accuracy: 0.9851 - digit2_accuracy: 0.9860\n",
      "Epoch 45/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0926 - digit1_loss: 0.0454 - digit2_loss: 0.0472 - digit1_accuracy: 0.9860 - digit2_accuracy: 0.9842\n",
      "Epoch 46/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0840 - digit1_loss: 0.0418 - digit2_loss: 0.0422 - digit1_accuracy: 0.9866 - digit2_accuracy: 0.9864\n",
      "Epoch 47/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0840 - digit1_loss: 0.0402 - digit2_loss: 0.0438 - digit1_accuracy: 0.9872 - digit2_accuracy: 0.9857\n",
      "Epoch 48/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0801 - digit1_loss: 0.0392 - digit2_loss: 0.0409 - digit1_accuracy: 0.9869 - digit2_accuracy: 0.9865\n",
      "Epoch 49/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0771 - digit1_loss: 0.0375 - digit2_loss: 0.0396 - digit1_accuracy: 0.9878 - digit2_accuracy: 0.9871\n",
      "Epoch 50/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0807 - digit1_loss: 0.0400 - digit2_loss: 0.0407 - digit1_accuracy: 0.9869 - digit2_accuracy: 0.9868\n",
      "Epoch 51/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0798 - digit1_loss: 0.0381 - digit2_loss: 0.0417 - digit1_accuracy: 0.9876 - digit2_accuracy: 0.9866\n",
      "Epoch 52/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0770 - digit1_loss: 0.0371 - digit2_loss: 0.0399 - digit1_accuracy: 0.9881 - digit2_accuracy: 0.9868\n",
      "Epoch 53/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0809 - digit1_loss: 0.0424 - digit2_loss: 0.0385 - digit1_accuracy: 0.9870 - digit2_accuracy: 0.9874\n",
      "Epoch 54/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0740 - digit1_loss: 0.0371 - digit2_loss: 0.0368 - digit1_accuracy: 0.9880 - digit2_accuracy: 0.9880\n",
      "Epoch 55/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0710 - digit1_loss: 0.0351 - digit2_loss: 0.0359 - digit1_accuracy: 0.9892 - digit2_accuracy: 0.9880\n",
      "Epoch 56/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0766 - digit1_loss: 0.0364 - digit2_loss: 0.0403 - digit1_accuracy: 0.9888 - digit2_accuracy: 0.9872\n",
      "Epoch 57/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0788 - digit1_loss: 0.0392 - digit2_loss: 0.0396 - digit1_accuracy: 0.9878 - digit2_accuracy: 0.9875\n",
      "Epoch 58/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0716 - digit1_loss: 0.0341 - digit2_loss: 0.0375 - digit1_accuracy: 0.9894 - digit2_accuracy: 0.9880\n",
      "Epoch 59/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0679 - digit1_loss: 0.0329 - digit2_loss: 0.0350 - digit1_accuracy: 0.9895 - digit2_accuracy: 0.9889\n",
      "Epoch 60/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0707 - digit1_loss: 0.0374 - digit2_loss: 0.0334 - digit1_accuracy: 0.9882 - digit2_accuracy: 0.9894\n",
      "Epoch 61/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0695 - digit1_loss: 0.0343 - digit2_loss: 0.0352 - digit1_accuracy: 0.9884 - digit2_accuracy: 0.9880\n",
      "Epoch 62/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0674 - digit1_loss: 0.0329 - digit2_loss: 0.0345 - digit1_accuracy: 0.9898 - digit2_accuracy: 0.9893\n",
      "Epoch 63/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0709 - digit1_loss: 0.0374 - digit2_loss: 0.0335 - digit1_accuracy: 0.9890 - digit2_accuracy: 0.9890\n",
      "Epoch 64/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0645 - digit1_loss: 0.0304 - digit2_loss: 0.0341 - digit1_accuracy: 0.9905 - digit2_accuracy: 0.9892\n",
      "Epoch 65/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0669 - digit1_loss: 0.0334 - digit2_loss: 0.0335 - digit1_accuracy: 0.9899 - digit2_accuracy: 0.9891\n",
      "Epoch 66/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0679 - digit1_loss: 0.0323 - digit2_loss: 0.0356 - digit1_accuracy: 0.9898 - digit2_accuracy: 0.9890\n",
      "Epoch 67/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0662 - digit1_loss: 0.0322 - digit2_loss: 0.0340 - digit1_accuracy: 0.9905 - digit2_accuracy: 0.9891\n",
      "Epoch 68/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0700 - digit1_loss: 0.0334 - digit2_loss: 0.0366 - digit1_accuracy: 0.9891 - digit2_accuracy: 0.9885\n",
      "Epoch 69/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0640 - digit1_loss: 0.0327 - digit2_loss: 0.0312 - digit1_accuracy: 0.9897 - digit2_accuracy: 0.9901\n",
      "Epoch 70/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0612 - digit1_loss: 0.0303 - digit2_loss: 0.0310 - digit1_accuracy: 0.9908 - digit2_accuracy: 0.9907\n",
      "Epoch 71/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0573 - digit1_loss: 0.0296 - digit2_loss: 0.0277 - digit1_accuracy: 0.9905 - digit2_accuracy: 0.9912\n",
      "Epoch 72/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0669 - digit1_loss: 0.0338 - digit2_loss: 0.0331 - digit1_accuracy: 0.9899 - digit2_accuracy: 0.9895\n",
      "Epoch 73/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0610 - digit1_loss: 0.0313 - digit2_loss: 0.0296 - digit1_accuracy: 0.9908 - digit2_accuracy: 0.9904\n",
      "Epoch 74/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0672 - digit1_loss: 0.0318 - digit2_loss: 0.0354 - digit1_accuracy: 0.9904 - digit2_accuracy: 0.9898\n",
      "Epoch 75/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0639 - digit1_loss: 0.0319 - digit2_loss: 0.0320 - digit1_accuracy: 0.9905 - digit2_accuracy: 0.9897\n",
      "Epoch 76/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0604 - digit1_loss: 0.0303 - digit2_loss: 0.0302 - digit1_accuracy: 0.9908 - digit2_accuracy: 0.9904\n",
      "Epoch 77/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0613 - digit1_loss: 0.0294 - digit2_loss: 0.0319 - digit1_accuracy: 0.9908 - digit2_accuracy: 0.9900\n",
      "Epoch 78/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0568 - digit1_loss: 0.0297 - digit2_loss: 0.0271 - digit1_accuracy: 0.9906 - digit2_accuracy: 0.9909\n",
      "Epoch 79/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0576 - digit1_loss: 0.0292 - digit2_loss: 0.0284 - digit1_accuracy: 0.9913 - digit2_accuracy: 0.9919\n",
      "Epoch 80/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0586 - digit1_loss: 0.0281 - digit2_loss: 0.0306 - digit1_accuracy: 0.9916 - digit2_accuracy: 0.9911\n",
      "Epoch 81/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0659 - digit1_loss: 0.0323 - digit2_loss: 0.0336 - digit1_accuracy: 0.9906 - digit2_accuracy: 0.9898\n",
      "Epoch 82/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0547 - digit1_loss: 0.0264 - digit2_loss: 0.0283 - digit1_accuracy: 0.9917 - digit2_accuracy: 0.9914\n",
      "Epoch 83/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0577 - digit1_loss: 0.0294 - digit2_loss: 0.0284 - digit1_accuracy: 0.9908 - digit2_accuracy: 0.9910\n",
      "Epoch 84/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0540 - digit1_loss: 0.0269 - digit2_loss: 0.0272 - digit1_accuracy: 0.9916 - digit2_accuracy: 0.9919\n",
      "Epoch 85/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0521 - digit1_loss: 0.0265 - digit2_loss: 0.0256 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9916\n",
      "Epoch 86/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0570 - digit1_loss: 0.0284 - digit2_loss: 0.0287 - digit1_accuracy: 0.9913 - digit2_accuracy: 0.9916\n",
      "Epoch 87/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0533 - digit1_loss: 0.0246 - digit2_loss: 0.0287 - digit1_accuracy: 0.9919 - digit2_accuracy: 0.9913\n",
      "Epoch 88/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0600 - digit1_loss: 0.0303 - digit2_loss: 0.0296 - digit1_accuracy: 0.9912 - digit2_accuracy: 0.9909\n",
      "Epoch 89/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0530 - digit1_loss: 0.0255 - digit2_loss: 0.0275 - digit1_accuracy: 0.9918 - digit2_accuracy: 0.9919\n",
      "Epoch 90/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0530 - digit1_loss: 0.0269 - digit2_loss: 0.0261 - digit1_accuracy: 0.9922 - digit2_accuracy: 0.9920\n",
      "Epoch 91/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0573 - digit1_loss: 0.0288 - digit2_loss: 0.0285 - digit1_accuracy: 0.9915 - digit2_accuracy: 0.9918\n",
      "Epoch 92/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0588 - digit1_loss: 0.0304 - digit2_loss: 0.0284 - digit1_accuracy: 0.9910 - digit2_accuracy: 0.9916\n",
      "Epoch 93/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0567 - digit1_loss: 0.0294 - digit2_loss: 0.0273 - digit1_accuracy: 0.9908 - digit2_accuracy: 0.9918\n",
      "Epoch 94/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0526 - digit1_loss: 0.0267 - digit2_loss: 0.0259 - digit1_accuracy: 0.9924 - digit2_accuracy: 0.9915\n",
      "Epoch 95/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0535 - digit1_loss: 0.0271 - digit2_loss: 0.0265 - digit1_accuracy: 0.9922 - digit2_accuracy: 0.9922\n",
      "Epoch 96/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0569 - digit1_loss: 0.0264 - digit2_loss: 0.0305 - digit1_accuracy: 0.9924 - digit2_accuracy: 0.9910\n",
      "Epoch 97/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0500 - digit1_loss: 0.0232 - digit2_loss: 0.0268 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9923\n",
      "Epoch 98/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0567 - digit1_loss: 0.0299 - digit2_loss: 0.0268 - digit1_accuracy: 0.9920 - digit2_accuracy: 0.9916\n",
      "Epoch 99/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0556 - digit1_loss: 0.0279 - digit2_loss: 0.0277 - digit1_accuracy: 0.9917 - digit2_accuracy: 0.9921\n",
      "Epoch 100/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0481 - digit1_loss: 0.0252 - digit2_loss: 0.0229 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9930\n",
      "Epoch 101/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0544 - digit1_loss: 0.0278 - digit2_loss: 0.0266 - digit1_accuracy: 0.9917 - digit2_accuracy: 0.9928\n",
      "Epoch 102/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0510 - digit1_loss: 0.0246 - digit2_loss: 0.0264 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9925\n",
      "Epoch 103/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0467 - digit1_loss: 0.0241 - digit2_loss: 0.0226 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9935\n",
      "Epoch 104/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0513 - digit1_loss: 0.0256 - digit2_loss: 0.0257 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9925\n",
      "Epoch 105/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0508 - digit1_loss: 0.0253 - digit2_loss: 0.0254 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9923\n",
      "Epoch 106/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0534 - digit1_loss: 0.0273 - digit2_loss: 0.0261 - digit1_accuracy: 0.9922 - digit2_accuracy: 0.9924\n",
      "Epoch 107/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0471 - digit1_loss: 0.0218 - digit2_loss: 0.0252 - digit1_accuracy: 0.9934 - digit2_accuracy: 0.9927\n",
      "Epoch 108/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0501 - digit1_loss: 0.0248 - digit2_loss: 0.0253 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9929\n",
      "Epoch 109/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0510 - digit1_loss: 0.0275 - digit2_loss: 0.0235 - digit1_accuracy: 0.9924 - digit2_accuracy: 0.9930\n",
      "Epoch 110/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0569 - digit1_loss: 0.0265 - digit2_loss: 0.0304 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9917\n",
      "Epoch 111/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0518 - digit1_loss: 0.0281 - digit2_loss: 0.0237 - digit1_accuracy: 0.9923 - digit2_accuracy: 0.9928\n",
      "Epoch 112/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0516 - digit1_loss: 0.0256 - digit2_loss: 0.0260 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9928\n",
      "Epoch 113/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0385 - digit1_loss: 0.0194 - digit2_loss: 0.0190 - digit1_accuracy: 0.9943 - digit2_accuracy: 0.9942\n",
      "Epoch 114/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0551 - digit1_loss: 0.0268 - digit2_loss: 0.0283 - digit1_accuracy: 0.9924 - digit2_accuracy: 0.9924\n",
      "Epoch 115/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0458 - digit1_loss: 0.0224 - digit2_loss: 0.0234 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9935\n",
      "Epoch 116/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0488 - digit1_loss: 0.0260 - digit2_loss: 0.0228 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9932\n",
      "Epoch 117/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0514 - digit1_loss: 0.0251 - digit2_loss: 0.0263 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9921\n",
      "Epoch 118/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0422 - digit1_loss: 0.0226 - digit2_loss: 0.0196 - digit1_accuracy: 0.9936 - digit2_accuracy: 0.9941\n",
      "Epoch 119/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0527 - digit1_loss: 0.0263 - digit2_loss: 0.0264 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9925\n",
      "Epoch 120/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0403 - digit1_loss: 0.0186 - digit2_loss: 0.0217 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9936\n",
      "Epoch 121/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0499 - digit1_loss: 0.0248 - digit2_loss: 0.0251 - digit1_accuracy: 0.9930 - digit2_accuracy: 0.9932\n",
      "Epoch 122/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0506 - digit1_loss: 0.0259 - digit2_loss: 0.0246 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9926\n",
      "Epoch 123/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0485 - digit1_loss: 0.0237 - digit2_loss: 0.0248 - digit1_accuracy: 0.9935 - digit2_accuracy: 0.9933\n",
      "Epoch 124/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0457 - digit1_loss: 0.0229 - digit2_loss: 0.0228 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9939\n",
      "Epoch 125/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0436 - digit1_loss: 0.0225 - digit2_loss: 0.0210 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9942\n",
      "Epoch 126/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0473 - digit1_loss: 0.0244 - digit2_loss: 0.0228 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9932\n",
      "Epoch 127/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0536 - digit1_loss: 0.0250 - digit2_loss: 0.0285 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9924\n",
      "Epoch 128/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0488 - digit1_loss: 0.0238 - digit2_loss: 0.0250 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9928\n",
      "Epoch 129/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0402 - digit1_loss: 0.0203 - digit2_loss: 0.0199 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9947\n",
      "Epoch 130/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0488 - digit1_loss: 0.0228 - digit2_loss: 0.0259 - digit1_accuracy: 0.9934 - digit2_accuracy: 0.9927\n",
      "Epoch 131/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0481 - digit1_loss: 0.0246 - digit2_loss: 0.0235 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9931\n",
      "Epoch 132/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0461 - digit1_loss: 0.0243 - digit2_loss: 0.0218 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9935\n",
      "Epoch 133/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0424 - digit1_loss: 0.0212 - digit2_loss: 0.0212 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9940\n",
      "Epoch 134/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0507 - digit1_loss: 0.0253 - digit2_loss: 0.0254 - digit1_accuracy: 0.9930 - digit2_accuracy: 0.9932\n",
      "Epoch 135/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0471 - digit1_loss: 0.0245 - digit2_loss: 0.0225 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9937\n",
      "Epoch 136/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0407 - digit1_loss: 0.0198 - digit2_loss: 0.0209 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9944\n",
      "Epoch 137/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0402 - digit1_loss: 0.0203 - digit2_loss: 0.0200 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9940\n",
      "Epoch 138/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0421 - digit1_loss: 0.0207 - digit2_loss: 0.0213 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9940\n",
      "Epoch 139/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0568 - digit1_loss: 0.0295 - digit2_loss: 0.0274 - digit1_accuracy: 0.9925 - digit2_accuracy: 0.9923\n",
      "Epoch 140/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0406 - digit1_loss: 0.0197 - digit2_loss: 0.0209 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9940\n",
      "Epoch 141/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0394 - digit1_loss: 0.0213 - digit2_loss: 0.0182 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9948\n",
      "Epoch 142/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0464 - digit1_loss: 0.0229 - digit2_loss: 0.0235 - digit1_accuracy: 0.9934 - digit2_accuracy: 0.9938\n",
      "Epoch 143/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0504 - digit1_loss: 0.0255 - digit2_loss: 0.0249 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9930\n",
      "Epoch 144/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0444 - digit1_loss: 0.0218 - digit2_loss: 0.0226 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9936\n",
      "Epoch 145/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0450 - digit1_loss: 0.0197 - digit2_loss: 0.0254 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9935\n",
      "Epoch 146/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0415 - digit1_loss: 0.0217 - digit2_loss: 0.0198 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9946\n",
      "Epoch 147/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0422 - digit1_loss: 0.0205 - digit2_loss: 0.0218 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9940\n",
      "Epoch 148/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0451 - digit1_loss: 0.0226 - digit2_loss: 0.0225 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9945\n",
      "Epoch 149/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0482 - digit1_loss: 0.0246 - digit2_loss: 0.0237 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9934\n",
      "Epoch 150/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0414 - digit1_loss: 0.0204 - digit2_loss: 0.0210 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9942\n",
      "Epoch 151/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0423 - digit1_loss: 0.0210 - digit2_loss: 0.0213 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9941\n",
      "Epoch 152/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0374 - digit1_loss: 0.0178 - digit2_loss: 0.0196 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9949\n",
      "Epoch 153/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0505 - digit1_loss: 0.0247 - digit2_loss: 0.0258 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9938\n",
      "Epoch 154/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0507 - digit1_loss: 0.0257 - digit2_loss: 0.0249 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9936\n",
      "Epoch 155/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0427 - digit1_loss: 0.0231 - digit2_loss: 0.0196 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9942\n",
      "Epoch 156/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0457 - digit1_loss: 0.0229 - digit2_loss: 0.0228 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9940\n",
      "Epoch 157/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0396 - digit1_loss: 0.0197 - digit2_loss: 0.0199 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9945\n",
      "Epoch 158/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0454 - digit1_loss: 0.0228 - digit2_loss: 0.0226 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9941\n",
      "Epoch 159/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0406 - digit1_loss: 0.0185 - digit2_loss: 0.0220 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9941\n",
      "Epoch 160/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0366 - digit1_loss: 0.0177 - digit2_loss: 0.0189 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9947\n",
      "Epoch 161/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0459 - digit1_loss: 0.0246 - digit2_loss: 0.0213 - digit1_accuracy: 0.9935 - digit2_accuracy: 0.9943\n",
      "Epoch 162/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0423 - digit1_loss: 0.0207 - digit2_loss: 0.0216 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9944\n",
      "Epoch 163/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0425 - digit1_loss: 0.0195 - digit2_loss: 0.0230 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9945\n",
      "Epoch 164/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0369 - digit1_loss: 0.0172 - digit2_loss: 0.0197 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9947\n",
      "Epoch 165/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0432 - digit1_loss: 0.0211 - digit2_loss: 0.0221 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9941\n",
      "Epoch 166/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0436 - digit1_loss: 0.0213 - digit2_loss: 0.0222 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9941\n",
      "Epoch 167/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0476 - digit1_loss: 0.0228 - digit2_loss: 0.0248 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9932\n",
      "Epoch 168/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0401 - digit1_loss: 0.0210 - digit2_loss: 0.0191 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9946\n",
      "Epoch 169/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0452 - digit1_loss: 0.0219 - digit2_loss: 0.0233 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9936\n",
      "Epoch 170/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0344 - digit1_loss: 0.0168 - digit2_loss: 0.0176 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9953\n",
      "Epoch 171/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0423 - digit1_loss: 0.0222 - digit2_loss: 0.0201 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9949\n",
      "Epoch 172/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0440 - digit1_loss: 0.0222 - digit2_loss: 0.0218 - digit1_accuracy: 0.9943 - digit2_accuracy: 0.9943\n",
      "Epoch 173/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0473 - digit1_loss: 0.0236 - digit2_loss: 0.0238 - digit1_accuracy: 0.9943 - digit2_accuracy: 0.9942\n",
      "Epoch 174/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0400 - digit1_loss: 0.0173 - digit2_loss: 0.0227 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9943\n",
      "Epoch 175/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0431 - digit1_loss: 0.0221 - digit2_loss: 0.0210 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9948\n",
      "Epoch 176/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0408 - digit1_loss: 0.0228 - digit2_loss: 0.0181 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9951\n",
      "Epoch 177/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0387 - digit1_loss: 0.0184 - digit2_loss: 0.0203 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9948\n",
      "Epoch 178/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0391 - digit1_loss: 0.0198 - digit2_loss: 0.0194 - digit1_accuracy: 0.9953 - digit2_accuracy: 0.9951\n",
      "Epoch 179/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0397 - digit1_loss: 0.0199 - digit2_loss: 0.0198 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9947\n",
      "Epoch 180/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0438 - digit1_loss: 0.0214 - digit2_loss: 0.0224 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9939\n",
      "Epoch 181/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0419 - digit1_loss: 0.0200 - digit2_loss: 0.0220 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9944\n",
      "Epoch 182/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0426 - digit1_loss: 0.0212 - digit2_loss: 0.0213 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9945\n",
      "Epoch 183/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0383 - digit1_loss: 0.0206 - digit2_loss: 0.0178 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9946\n",
      "Epoch 184/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0404 - digit1_loss: 0.0209 - digit2_loss: 0.0195 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9945\n",
      "Epoch 185/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0328 - digit1_loss: 0.0161 - digit2_loss: 0.0167 - digit1_accuracy: 0.9956 - digit2_accuracy: 0.9955\n",
      "Epoch 186/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0438 - digit1_loss: 0.0215 - digit2_loss: 0.0223 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9944\n",
      "Epoch 187/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0488 - digit1_loss: 0.0250 - digit2_loss: 0.0238 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9936\n",
      "Epoch 188/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0424 - digit1_loss: 0.0211 - digit2_loss: 0.0214 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9944\n",
      "Epoch 189/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0431 - digit1_loss: 0.0223 - digit2_loss: 0.0209 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9949\n",
      "Epoch 190/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0393 - digit1_loss: 0.0179 - digit2_loss: 0.0214 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9948\n",
      "Epoch 191/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0386 - digit1_loss: 0.0175 - digit2_loss: 0.0211 - digit1_accuracy: 0.9953 - digit2_accuracy: 0.9944\n",
      "Epoch 192/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0316 - digit1_loss: 0.0154 - digit2_loss: 0.0162 - digit1_accuracy: 0.9959 - digit2_accuracy: 0.9954\n",
      "Epoch 193/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0412 - digit1_loss: 0.0211 - digit2_loss: 0.0201 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9944\n",
      "Epoch 194/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0451 - digit1_loss: 0.0226 - digit2_loss: 0.0225 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9945\n",
      "Epoch 195/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0374 - digit1_loss: 0.0195 - digit2_loss: 0.0179 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9948\n",
      "Epoch 196/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0449 - digit1_loss: 0.0231 - digit2_loss: 0.0218 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9944\n",
      "Epoch 197/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0415 - digit1_loss: 0.0212 - digit2_loss: 0.0204 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9950\n",
      "Epoch 198/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0361 - digit1_loss: 0.0167 - digit2_loss: 0.0195 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9945\n",
      "Epoch 199/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0372 - digit1_loss: 0.0171 - digit2_loss: 0.0201 - digit1_accuracy: 0.9961 - digit2_accuracy: 0.9950\n",
      "Epoch 200/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0345 - digit1_loss: 0.0167 - digit2_loss: 0.0178 - digit1_accuracy: 0.9957 - digit2_accuracy: 0.9954\n",
      "loss : 2.1093502044677734\n",
      "digit1_loss : 1.042899250984192\n",
      "digit2_loss : 1.0664499998092651\n",
      "digit1_accuracy : 0.9265833497047424\n",
      "digit2_accuracy : 0.9238333106040955\n",
      "Fold 2\n",
      "Epoch 1/200\n",
      "750/750 [==============================] - 4s 4ms/step - loss: 3.2361 - digit1_loss: 1.5105 - digit2_loss: 1.7257 - digit1_accuracy: 0.4603 - digit2_accuracy: 0.3668\n",
      "Epoch 2/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.8162 - digit1_loss: 0.8251 - digit2_loss: 0.9912 - digit1_accuracy: 0.7205 - digit2_accuracy: 0.6590\n",
      "Epoch 3/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.3298 - digit1_loss: 0.6163 - digit2_loss: 0.7136 - digit1_accuracy: 0.7942 - digit2_accuracy: 0.7596\n",
      "Epoch 4/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.0562 - digit1_loss: 0.4980 - digit2_loss: 0.5582 - digit1_accuracy: 0.8360 - digit2_accuracy: 0.8163\n",
      "Epoch 5/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.8841 - digit1_loss: 0.4171 - digit2_loss: 0.4669 - digit1_accuracy: 0.8611 - digit2_accuracy: 0.8462\n",
      "Epoch 6/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7505 - digit1_loss: 0.3598 - digit2_loss: 0.3907 - digit1_accuracy: 0.8809 - digit2_accuracy: 0.8723\n",
      "Epoch 7/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6501 - digit1_loss: 0.3125 - digit2_loss: 0.3375 - digit1_accuracy: 0.8953 - digit2_accuracy: 0.8874\n",
      "Epoch 8/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.5698 - digit1_loss: 0.2758 - digit2_loss: 0.2939 - digit1_accuracy: 0.9085 - digit2_accuracy: 0.9028\n",
      "Epoch 9/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.4957 - digit1_loss: 0.2384 - digit2_loss: 0.2573 - digit1_accuracy: 0.9196 - digit2_accuracy: 0.9143\n",
      "Epoch 10/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.4441 - digit1_loss: 0.2116 - digit2_loss: 0.2325 - digit1_accuracy: 0.9293 - digit2_accuracy: 0.9221\n",
      "Epoch 11/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3940 - digit1_loss: 0.1897 - digit2_loss: 0.2042 - digit1_accuracy: 0.9351 - digit2_accuracy: 0.9321\n",
      "Epoch 12/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3575 - digit1_loss: 0.1728 - digit2_loss: 0.1846 - digit1_accuracy: 0.9408 - digit2_accuracy: 0.9375\n",
      "Epoch 13/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3193 - digit1_loss: 0.1568 - digit2_loss: 0.1625 - digit1_accuracy: 0.9451 - digit2_accuracy: 0.9439\n",
      "Epoch 14/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2955 - digit1_loss: 0.1405 - digit2_loss: 0.1550 - digit1_accuracy: 0.9510 - digit2_accuracy: 0.9474\n",
      "Epoch 15/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2690 - digit1_loss: 0.1313 - digit2_loss: 0.1377 - digit1_accuracy: 0.9550 - digit2_accuracy: 0.9527\n",
      "Epoch 16/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2466 - digit1_loss: 0.1190 - digit2_loss: 0.1276 - digit1_accuracy: 0.9602 - digit2_accuracy: 0.9564\n",
      "Epoch 17/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2288 - digit1_loss: 0.1109 - digit2_loss: 0.1179 - digit1_accuracy: 0.9626 - digit2_accuracy: 0.9599\n",
      "Epoch 18/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2175 - digit1_loss: 0.1057 - digit2_loss: 0.1118 - digit1_accuracy: 0.9641 - digit2_accuracy: 0.9622\n",
      "Epoch 19/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2049 - digit1_loss: 0.0969 - digit2_loss: 0.1080 - digit1_accuracy: 0.9655 - digit2_accuracy: 0.9632\n",
      "Epoch 20/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1893 - digit1_loss: 0.0926 - digit2_loss: 0.0967 - digit1_accuracy: 0.9694 - digit2_accuracy: 0.9666\n",
      "Epoch 21/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1830 - digit1_loss: 0.0891 - digit2_loss: 0.0939 - digit1_accuracy: 0.9694 - digit2_accuracy: 0.9673\n",
      "Epoch 22/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1673 - digit1_loss: 0.0832 - digit2_loss: 0.0841 - digit1_accuracy: 0.9714 - digit2_accuracy: 0.9699\n",
      "Epoch 23/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1611 - digit1_loss: 0.0791 - digit2_loss: 0.0820 - digit1_accuracy: 0.9734 - digit2_accuracy: 0.9726\n",
      "Epoch 24/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1577 - digit1_loss: 0.0779 - digit2_loss: 0.0798 - digit1_accuracy: 0.9729 - digit2_accuracy: 0.9731\n",
      "Epoch 25/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1541 - digit1_loss: 0.0749 - digit2_loss: 0.0793 - digit1_accuracy: 0.9739 - digit2_accuracy: 0.9732\n",
      "Epoch 26/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1474 - digit1_loss: 0.0727 - digit2_loss: 0.0747 - digit1_accuracy: 0.9749 - digit2_accuracy: 0.9758\n",
      "Epoch 27/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1322 - digit1_loss: 0.0636 - digit2_loss: 0.0686 - digit1_accuracy: 0.9787 - digit2_accuracy: 0.9764\n",
      "Epoch 28/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1332 - digit1_loss: 0.0651 - digit2_loss: 0.0680 - digit1_accuracy: 0.9778 - digit2_accuracy: 0.9771\n",
      "Epoch 29/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1316 - digit1_loss: 0.0649 - digit2_loss: 0.0667 - digit1_accuracy: 0.9774 - digit2_accuracy: 0.9775\n",
      "Epoch 30/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1185 - digit1_loss: 0.0591 - digit2_loss: 0.0595 - digit1_accuracy: 0.9800 - digit2_accuracy: 0.9791\n",
      "Epoch 31/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1200 - digit1_loss: 0.0585 - digit2_loss: 0.0615 - digit1_accuracy: 0.9800 - digit2_accuracy: 0.9790\n",
      "Epoch 32/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1201 - digit1_loss: 0.0604 - digit2_loss: 0.0597 - digit1_accuracy: 0.9800 - digit2_accuracy: 0.9795\n",
      "Epoch 33/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1174 - digit1_loss: 0.0597 - digit2_loss: 0.0577 - digit1_accuracy: 0.9801 - digit2_accuracy: 0.9802\n",
      "Epoch 34/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1111 - digit1_loss: 0.0533 - digit2_loss: 0.0578 - digit1_accuracy: 0.9822 - digit2_accuracy: 0.9814\n",
      "Epoch 35/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1097 - digit1_loss: 0.0537 - digit2_loss: 0.0560 - digit1_accuracy: 0.9822 - digit2_accuracy: 0.9812\n",
      "Epoch 36/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1038 - digit1_loss: 0.0505 - digit2_loss: 0.0533 - digit1_accuracy: 0.9831 - digit2_accuracy: 0.9816\n",
      "Epoch 37/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0996 - digit1_loss: 0.0479 - digit2_loss: 0.0517 - digit1_accuracy: 0.9841 - digit2_accuracy: 0.9830\n",
      "Epoch 38/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1032 - digit1_loss: 0.0512 - digit2_loss: 0.0519 - digit1_accuracy: 0.9830 - digit2_accuracy: 0.9828\n",
      "Epoch 39/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0982 - digit1_loss: 0.0461 - digit2_loss: 0.0521 - digit1_accuracy: 0.9852 - digit2_accuracy: 0.9829\n",
      "Epoch 40/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0945 - digit1_loss: 0.0449 - digit2_loss: 0.0496 - digit1_accuracy: 0.9851 - digit2_accuracy: 0.9838\n",
      "Epoch 41/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0977 - digit1_loss: 0.0477 - digit2_loss: 0.0500 - digit1_accuracy: 0.9845 - digit2_accuracy: 0.9840\n",
      "Epoch 42/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0880 - digit1_loss: 0.0437 - digit2_loss: 0.0444 - digit1_accuracy: 0.9851 - digit2_accuracy: 0.9851\n",
      "Epoch 43/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0915 - digit1_loss: 0.0438 - digit2_loss: 0.0477 - digit1_accuracy: 0.9859 - digit2_accuracy: 0.9839\n",
      "Epoch 44/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0869 - digit1_loss: 0.0413 - digit2_loss: 0.0456 - digit1_accuracy: 0.9862 - digit2_accuracy: 0.9855\n",
      "Epoch 45/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0876 - digit1_loss: 0.0420 - digit2_loss: 0.0455 - digit1_accuracy: 0.9863 - digit2_accuracy: 0.9854\n",
      "Epoch 46/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0922 - digit1_loss: 0.0454 - digit2_loss: 0.0467 - digit1_accuracy: 0.9853 - digit2_accuracy: 0.9850\n",
      "Epoch 47/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0830 - digit1_loss: 0.0380 - digit2_loss: 0.0450 - digit1_accuracy: 0.9876 - digit2_accuracy: 0.9854\n",
      "Epoch 48/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0832 - digit1_loss: 0.0397 - digit2_loss: 0.0435 - digit1_accuracy: 0.9868 - digit2_accuracy: 0.9863\n",
      "Epoch 49/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0827 - digit1_loss: 0.0424 - digit2_loss: 0.0403 - digit1_accuracy: 0.9861 - digit2_accuracy: 0.9872\n",
      "Epoch 50/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0782 - digit1_loss: 0.0372 - digit2_loss: 0.0410 - digit1_accuracy: 0.9875 - digit2_accuracy: 0.9869\n",
      "Epoch 51/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0801 - digit1_loss: 0.0373 - digit2_loss: 0.0428 - digit1_accuracy: 0.9883 - digit2_accuracy: 0.9864\n",
      "Epoch 52/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0744 - digit1_loss: 0.0357 - digit2_loss: 0.0387 - digit1_accuracy: 0.9886 - digit2_accuracy: 0.9876\n",
      "Epoch 53/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0688 - digit1_loss: 0.0347 - digit2_loss: 0.0341 - digit1_accuracy: 0.9884 - digit2_accuracy: 0.9894\n",
      "Epoch 54/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0827 - digit1_loss: 0.0406 - digit2_loss: 0.0421 - digit1_accuracy: 0.9871 - digit2_accuracy: 0.9872\n",
      "Epoch 55/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0730 - digit1_loss: 0.0360 - digit2_loss: 0.0371 - digit1_accuracy: 0.9886 - digit2_accuracy: 0.9883\n",
      "Epoch 56/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0766 - digit1_loss: 0.0371 - digit2_loss: 0.0395 - digit1_accuracy: 0.9882 - digit2_accuracy: 0.9875\n",
      "Epoch 57/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0698 - digit1_loss: 0.0324 - digit2_loss: 0.0375 - digit1_accuracy: 0.9899 - digit2_accuracy: 0.9880\n",
      "Epoch 58/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0771 - digit1_loss: 0.0387 - digit2_loss: 0.0385 - digit1_accuracy: 0.9884 - digit2_accuracy: 0.9876\n",
      "Epoch 59/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0701 - digit1_loss: 0.0343 - digit2_loss: 0.0358 - digit1_accuracy: 0.9894 - digit2_accuracy: 0.9885\n",
      "Epoch 60/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0678 - digit1_loss: 0.0334 - digit2_loss: 0.0344 - digit1_accuracy: 0.9893 - digit2_accuracy: 0.9904\n",
      "Epoch 61/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0690 - digit1_loss: 0.0332 - digit2_loss: 0.0358 - digit1_accuracy: 0.9894 - digit2_accuracy: 0.9885\n",
      "Epoch 62/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0609 - digit1_loss: 0.0288 - digit2_loss: 0.0321 - digit1_accuracy: 0.9907 - digit2_accuracy: 0.9898\n",
      "Epoch 63/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0705 - digit1_loss: 0.0348 - digit2_loss: 0.0357 - digit1_accuracy: 0.9893 - digit2_accuracy: 0.9890\n",
      "Epoch 64/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0658 - digit1_loss: 0.0348 - digit2_loss: 0.0310 - digit1_accuracy: 0.9893 - digit2_accuracy: 0.9902\n",
      "Epoch 65/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0702 - digit1_loss: 0.0342 - digit2_loss: 0.0359 - digit1_accuracy: 0.9895 - digit2_accuracy: 0.9890\n",
      "Epoch 66/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0625 - digit1_loss: 0.0307 - digit2_loss: 0.0318 - digit1_accuracy: 0.9901 - digit2_accuracy: 0.9903\n",
      "Epoch 67/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0692 - digit1_loss: 0.0346 - digit2_loss: 0.0347 - digit1_accuracy: 0.9891 - digit2_accuracy: 0.9892\n",
      "Epoch 68/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0658 - digit1_loss: 0.0328 - digit2_loss: 0.0330 - digit1_accuracy: 0.9896 - digit2_accuracy: 0.9898\n",
      "Epoch 69/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0609 - digit1_loss: 0.0280 - digit2_loss: 0.0329 - digit1_accuracy: 0.9910 - digit2_accuracy: 0.9900\n",
      "Epoch 70/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0640 - digit1_loss: 0.0313 - digit2_loss: 0.0327 - digit1_accuracy: 0.9903 - digit2_accuracy: 0.9899\n",
      "Epoch 71/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0641 - digit1_loss: 0.0325 - digit2_loss: 0.0316 - digit1_accuracy: 0.9904 - digit2_accuracy: 0.9899\n",
      "Epoch 72/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0599 - digit1_loss: 0.0296 - digit2_loss: 0.0303 - digit1_accuracy: 0.9911 - digit2_accuracy: 0.9912\n",
      "Epoch 73/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0600 - digit1_loss: 0.0285 - digit2_loss: 0.0315 - digit1_accuracy: 0.9914 - digit2_accuracy: 0.9901\n",
      "Epoch 74/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0622 - digit1_loss: 0.0298 - digit2_loss: 0.0324 - digit1_accuracy: 0.9913 - digit2_accuracy: 0.9904\n",
      "Epoch 75/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0641 - digit1_loss: 0.0298 - digit2_loss: 0.0343 - digit1_accuracy: 0.9911 - digit2_accuracy: 0.9900\n",
      "Epoch 76/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0656 - digit1_loss: 0.0322 - digit2_loss: 0.0334 - digit1_accuracy: 0.9907 - digit2_accuracy: 0.9902\n",
      "Epoch 77/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0580 - digit1_loss: 0.0284 - digit2_loss: 0.0296 - digit1_accuracy: 0.9920 - digit2_accuracy: 0.9907\n",
      "Epoch 78/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0599 - digit1_loss: 0.0303 - digit2_loss: 0.0296 - digit1_accuracy: 0.9904 - digit2_accuracy: 0.9914\n",
      "Epoch 79/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0567 - digit1_loss: 0.0287 - digit2_loss: 0.0280 - digit1_accuracy: 0.9914 - digit2_accuracy: 0.9913\n",
      "Epoch 80/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0590 - digit1_loss: 0.0290 - digit2_loss: 0.0300 - digit1_accuracy: 0.9907 - digit2_accuracy: 0.9912\n",
      "Epoch 81/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0545 - digit1_loss: 0.0255 - digit2_loss: 0.0289 - digit1_accuracy: 0.9918 - digit2_accuracy: 0.9916\n",
      "Epoch 82/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0544 - digit1_loss: 0.0252 - digit2_loss: 0.0292 - digit1_accuracy: 0.9922 - digit2_accuracy: 0.9912\n",
      "Epoch 83/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0553 - digit1_loss: 0.0262 - digit2_loss: 0.0291 - digit1_accuracy: 0.9918 - digit2_accuracy: 0.9909\n",
      "Epoch 84/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0571 - digit1_loss: 0.0279 - digit2_loss: 0.0292 - digit1_accuracy: 0.9918 - digit2_accuracy: 0.9911\n",
      "Epoch 85/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0564 - digit1_loss: 0.0278 - digit2_loss: 0.0286 - digit1_accuracy: 0.9912 - digit2_accuracy: 0.9913\n",
      "Epoch 86/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0550 - digit1_loss: 0.0262 - digit2_loss: 0.0288 - digit1_accuracy: 0.9924 - digit2_accuracy: 0.9915\n",
      "Epoch 87/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0565 - digit1_loss: 0.0277 - digit2_loss: 0.0288 - digit1_accuracy: 0.9917 - digit2_accuracy: 0.9915\n",
      "Epoch 88/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0531 - digit1_loss: 0.0250 - digit2_loss: 0.0281 - digit1_accuracy: 0.9925 - digit2_accuracy: 0.9913\n",
      "Epoch 89/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0487 - digit1_loss: 0.0244 - digit2_loss: 0.0243 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9928\n",
      "Epoch 90/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0492 - digit1_loss: 0.0236 - digit2_loss: 0.0257 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9925\n",
      "Epoch 91/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0562 - digit1_loss: 0.0268 - digit2_loss: 0.0294 - digit1_accuracy: 0.9916 - digit2_accuracy: 0.9916\n",
      "Epoch 92/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0513 - digit1_loss: 0.0247 - digit2_loss: 0.0266 - digit1_accuracy: 0.9924 - digit2_accuracy: 0.9918\n",
      "Epoch 93/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0476 - digit1_loss: 0.0226 - digit2_loss: 0.0250 - digit1_accuracy: 0.9935 - digit2_accuracy: 0.9929\n",
      "Epoch 94/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0535 - digit1_loss: 0.0272 - digit2_loss: 0.0263 - digit1_accuracy: 0.9923 - digit2_accuracy: 0.9923\n",
      "Epoch 95/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0575 - digit1_loss: 0.0280 - digit2_loss: 0.0294 - digit1_accuracy: 0.9915 - digit2_accuracy: 0.9914\n",
      "Epoch 96/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0524 - digit1_loss: 0.0240 - digit2_loss: 0.0284 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9919\n",
      "Epoch 97/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0520 - digit1_loss: 0.0252 - digit2_loss: 0.0268 - digit1_accuracy: 0.9927 - digit2_accuracy: 0.9918\n",
      "Epoch 98/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0522 - digit1_loss: 0.0241 - digit2_loss: 0.0281 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9922\n",
      "Epoch 99/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0514 - digit1_loss: 0.0252 - digit2_loss: 0.0261 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9925\n",
      "Epoch 100/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0508 - digit1_loss: 0.0246 - digit2_loss: 0.0262 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9922\n",
      "Epoch 101/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0526 - digit1_loss: 0.0249 - digit2_loss: 0.0278 - digit1_accuracy: 0.9930 - digit2_accuracy: 0.9924\n",
      "Epoch 102/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0540 - digit1_loss: 0.0273 - digit2_loss: 0.0267 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9925\n",
      "Epoch 103/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0530 - digit1_loss: 0.0275 - digit2_loss: 0.0255 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9930\n",
      "Epoch 104/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0539 - digit1_loss: 0.0258 - digit2_loss: 0.0281 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9923\n",
      "Epoch 105/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0491 - digit1_loss: 0.0253 - digit2_loss: 0.0238 - digit1_accuracy: 0.9923 - digit2_accuracy: 0.9929\n",
      "Epoch 106/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0523 - digit1_loss: 0.0251 - digit2_loss: 0.0273 - digit1_accuracy: 0.9934 - digit2_accuracy: 0.9922\n",
      "Epoch 107/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0471 - digit1_loss: 0.0226 - digit2_loss: 0.0244 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9927\n",
      "Epoch 108/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0509 - digit1_loss: 0.0253 - digit2_loss: 0.0256 - digit1_accuracy: 0.9930 - digit2_accuracy: 0.9926\n",
      "Epoch 109/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0466 - digit1_loss: 0.0221 - digit2_loss: 0.0245 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9930\n",
      "Epoch 110/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0479 - digit1_loss: 0.0231 - digit2_loss: 0.0247 - digit1_accuracy: 0.9935 - digit2_accuracy: 0.9929\n",
      "Epoch 111/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0497 - digit1_loss: 0.0245 - digit2_loss: 0.0252 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9931\n",
      "Epoch 112/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0477 - digit1_loss: 0.0255 - digit2_loss: 0.0222 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9934\n",
      "Epoch 113/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0444 - digit1_loss: 0.0221 - digit2_loss: 0.0223 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9924\n",
      "Epoch 114/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0535 - digit1_loss: 0.0254 - digit2_loss: 0.0281 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9919\n",
      "Epoch 115/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0474 - digit1_loss: 0.0225 - digit2_loss: 0.0249 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9926\n",
      "Epoch 116/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0432 - digit1_loss: 0.0212 - digit2_loss: 0.0220 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9934\n",
      "Epoch 117/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0476 - digit1_loss: 0.0236 - digit2_loss: 0.0240 - digit1_accuracy: 0.9936 - digit2_accuracy: 0.9935\n",
      "Epoch 118/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0425 - digit1_loss: 0.0200 - digit2_loss: 0.0225 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9929\n",
      "Epoch 119/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0432 - digit1_loss: 0.0197 - digit2_loss: 0.0235 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9927\n",
      "Epoch 120/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0472 - digit1_loss: 0.0246 - digit2_loss: 0.0226 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9940\n",
      "Epoch 121/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0487 - digit1_loss: 0.0248 - digit2_loss: 0.0238 - digit1_accuracy: 0.9934 - digit2_accuracy: 0.9935\n",
      "Epoch 122/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0497 - digit1_loss: 0.0227 - digit2_loss: 0.0270 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9931\n",
      "Epoch 123/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0419 - digit1_loss: 0.0209 - digit2_loss: 0.0210 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9940\n",
      "Epoch 124/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0457 - digit1_loss: 0.0216 - digit2_loss: 0.0242 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9932\n",
      "Epoch 125/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0466 - digit1_loss: 0.0211 - digit2_loss: 0.0254 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9934\n",
      "Epoch 126/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0445 - digit1_loss: 0.0213 - digit2_loss: 0.0232 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9938\n",
      "Epoch 127/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0484 - digit1_loss: 0.0248 - digit2_loss: 0.0236 - digit1_accuracy: 0.9936 - digit2_accuracy: 0.9936\n",
      "Epoch 128/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0445 - digit1_loss: 0.0234 - digit2_loss: 0.0211 - digit1_accuracy: 0.9936 - digit2_accuracy: 0.9940\n",
      "Epoch 129/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0429 - digit1_loss: 0.0195 - digit2_loss: 0.0234 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9933\n",
      "Epoch 130/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0482 - digit1_loss: 0.0239 - digit2_loss: 0.0243 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9934\n",
      "Epoch 131/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0450 - digit1_loss: 0.0216 - digit2_loss: 0.0234 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9935\n",
      "Epoch 132/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0441 - digit1_loss: 0.0209 - digit2_loss: 0.0232 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9937\n",
      "Epoch 133/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0457 - digit1_loss: 0.0223 - digit2_loss: 0.0234 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9937\n",
      "Epoch 134/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0464 - digit1_loss: 0.0228 - digit2_loss: 0.0235 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9936\n",
      "Epoch 135/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0429 - digit1_loss: 0.0210 - digit2_loss: 0.0219 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9939\n",
      "Epoch 136/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0421 - digit1_loss: 0.0210 - digit2_loss: 0.0212 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9945\n",
      "Epoch 137/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0382 - digit1_loss: 0.0184 - digit2_loss: 0.0198 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9944\n",
      "Epoch 138/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0447 - digit1_loss: 0.0236 - digit2_loss: 0.0212 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9936\n",
      "Epoch 139/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0474 - digit1_loss: 0.0229 - digit2_loss: 0.0246 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9930\n",
      "Epoch 140/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0444 - digit1_loss: 0.0204 - digit2_loss: 0.0240 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9937\n",
      "Epoch 141/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0430 - digit1_loss: 0.0200 - digit2_loss: 0.0230 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9940\n",
      "Epoch 142/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0464 - digit1_loss: 0.0243 - digit2_loss: 0.0221 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9940\n",
      "Epoch 143/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0392 - digit1_loss: 0.0207 - digit2_loss: 0.0185 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9946\n",
      "Epoch 144/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0433 - digit1_loss: 0.0224 - digit2_loss: 0.0209 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9941\n",
      "Epoch 145/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0450 - digit1_loss: 0.0198 - digit2_loss: 0.0252 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9935\n",
      "Epoch 146/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0359 - digit1_loss: 0.0168 - digit2_loss: 0.0191 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9948\n",
      "Epoch 147/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0424 - digit1_loss: 0.0209 - digit2_loss: 0.0216 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9941\n",
      "Epoch 148/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0447 - digit1_loss: 0.0210 - digit2_loss: 0.0238 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9942\n",
      "Epoch 149/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0450 - digit1_loss: 0.0210 - digit2_loss: 0.0240 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9938\n",
      "Epoch 150/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0376 - digit1_loss: 0.0207 - digit2_loss: 0.0169 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9952\n",
      "Epoch 151/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0493 - digit1_loss: 0.0235 - digit2_loss: 0.0258 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9930\n",
      "Epoch 152/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0364 - digit1_loss: 0.0178 - digit2_loss: 0.0185 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9949\n",
      "Epoch 153/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0405 - digit1_loss: 0.0200 - digit2_loss: 0.0205 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9946\n",
      "Epoch 154/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0392 - digit1_loss: 0.0195 - digit2_loss: 0.0196 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9949\n",
      "Epoch 155/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0452 - digit1_loss: 0.0234 - digit2_loss: 0.0217 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9940\n",
      "Epoch 156/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0370 - digit1_loss: 0.0179 - digit2_loss: 0.0191 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9944\n",
      "Epoch 157/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0569 - digit1_loss: 0.0264 - digit2_loss: 0.0305 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9925\n",
      "Epoch 158/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0390 - digit1_loss: 0.0187 - digit2_loss: 0.0203 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9941\n",
      "Epoch 159/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0392 - digit1_loss: 0.0196 - digit2_loss: 0.0195 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9951\n",
      "Epoch 160/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0423 - digit1_loss: 0.0206 - digit2_loss: 0.0216 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9939\n",
      "Epoch 161/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0409 - digit1_loss: 0.0182 - digit2_loss: 0.0226 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9941\n",
      "Epoch 162/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0394 - digit1_loss: 0.0200 - digit2_loss: 0.0195 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9946\n",
      "Epoch 163/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0458 - digit1_loss: 0.0209 - digit2_loss: 0.0250 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9936\n",
      "Epoch 164/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0350 - digit1_loss: 0.0180 - digit2_loss: 0.0170 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9952\n",
      "Epoch 165/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0351 - digit1_loss: 0.0178 - digit2_loss: 0.0173 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9952\n",
      "Epoch 166/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0424 - digit1_loss: 0.0222 - digit2_loss: 0.0202 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9948\n",
      "Epoch 167/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0453 - digit1_loss: 0.0223 - digit2_loss: 0.0230 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9941\n",
      "Epoch 168/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0432 - digit1_loss: 0.0201 - digit2_loss: 0.0231 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9947\n",
      "Epoch 169/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0349 - digit1_loss: 0.0184 - digit2_loss: 0.0164 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9952\n",
      "Epoch 170/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0361 - digit1_loss: 0.0166 - digit2_loss: 0.0195 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9949\n",
      "Epoch 171/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0421 - digit1_loss: 0.0206 - digit2_loss: 0.0216 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9944\n",
      "Epoch 172/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0379 - digit1_loss: 0.0180 - digit2_loss: 0.0198 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9946\n",
      "Epoch 173/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0440 - digit1_loss: 0.0219 - digit2_loss: 0.0220 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9946\n",
      "Epoch 174/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0414 - digit1_loss: 0.0224 - digit2_loss: 0.0191 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9945\n",
      "Epoch 175/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0374 - digit1_loss: 0.0179 - digit2_loss: 0.0195 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9951\n",
      "Epoch 176/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0445 - digit1_loss: 0.0227 - digit2_loss: 0.0218 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9941\n",
      "Epoch 177/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0426 - digit1_loss: 0.0212 - digit2_loss: 0.0214 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9943\n",
      "Epoch 178/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0307 - digit1_loss: 0.0139 - digit2_loss: 0.0168 - digit1_accuracy: 0.9962 - digit2_accuracy: 0.9959\n",
      "Epoch 179/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0468 - digit1_loss: 0.0230 - digit2_loss: 0.0238 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9934\n",
      "Epoch 180/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0418 - digit1_loss: 0.0195 - digit2_loss: 0.0223 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9944\n",
      "Epoch 181/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0370 - digit1_loss: 0.0201 - digit2_loss: 0.0169 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9955\n",
      "Epoch 182/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0371 - digit1_loss: 0.0166 - digit2_loss: 0.0205 - digit1_accuracy: 0.9957 - digit2_accuracy: 0.9947\n",
      "Epoch 183/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0373 - digit1_loss: 0.0178 - digit2_loss: 0.0195 - digit1_accuracy: 0.9956 - digit2_accuracy: 0.9948\n",
      "Epoch 184/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0432 - digit1_loss: 0.0223 - digit2_loss: 0.0208 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9944\n",
      "Epoch 185/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0402 - digit1_loss: 0.0189 - digit2_loss: 0.0213 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9947\n",
      "Epoch 186/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0386 - digit1_loss: 0.0188 - digit2_loss: 0.0198 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9950\n",
      "Epoch 187/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0382 - digit1_loss: 0.0192 - digit2_loss: 0.0190 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9948\n",
      "Epoch 188/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0428 - digit1_loss: 0.0206 - digit2_loss: 0.0222 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9945\n",
      "Epoch 189/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0388 - digit1_loss: 0.0208 - digit2_loss: 0.0180 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9953\n",
      "Epoch 190/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0367 - digit1_loss: 0.0194 - digit2_loss: 0.0173 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9953\n",
      "Epoch 191/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0409 - digit1_loss: 0.0188 - digit2_loss: 0.0221 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9947\n",
      "Epoch 192/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0395 - digit1_loss: 0.0198 - digit2_loss: 0.0196 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9946\n",
      "Epoch 193/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0368 - digit1_loss: 0.0175 - digit2_loss: 0.0192 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9954\n",
      "Epoch 194/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0431 - digit1_loss: 0.0219 - digit2_loss: 0.0212 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9944\n",
      "Epoch 195/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0455 - digit1_loss: 0.0222 - digit2_loss: 0.0233 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9943\n",
      "Epoch 196/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0325 - digit1_loss: 0.0161 - digit2_loss: 0.0164 - digit1_accuracy: 0.9957 - digit2_accuracy: 0.9956\n",
      "Epoch 197/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0402 - digit1_loss: 0.0199 - digit2_loss: 0.0203 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9953\n",
      "Epoch 198/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0386 - digit1_loss: 0.0189 - digit2_loss: 0.0197 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9956\n",
      "Epoch 199/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0382 - digit1_loss: 0.0191 - digit2_loss: 0.0191 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9952\n",
      "Epoch 200/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0425 - digit1_loss: 0.0217 - digit2_loss: 0.0208 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9948\n",
      "loss : 2.4876352548599243\n",
      "digit1_loss : 1.198359191417694\n",
      "digit2_loss : 1.2892767786979675\n",
      "digit1_accuracy : 0.924875020980835\n",
      "digit2_accuracy : 0.9198749959468842\n",
      "Fold 3\n",
      "Epoch 1/200\n",
      "750/750 [==============================] - 4s 4ms/step - loss: 3.2573 - digit1_loss: 1.5342 - digit2_loss: 1.7231 - digit1_accuracy: 0.4547 - digit2_accuracy: 0.3756\n",
      "Epoch 2/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 2.0258 - digit1_loss: 0.9286 - digit2_loss: 1.0972 - digit1_accuracy: 0.6806 - digit2_accuracy: 0.6151\n",
      "Epoch 3/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.5302 - digit1_loss: 0.7078 - digit2_loss: 0.8224 - digit1_accuracy: 0.7620 - digit2_accuracy: 0.7191\n",
      "Epoch 4/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.2296 - digit1_loss: 0.5756 - digit2_loss: 0.6540 - digit1_accuracy: 0.8065 - digit2_accuracy: 0.7807\n",
      "Epoch 5/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.0230 - digit1_loss: 0.4814 - digit2_loss: 0.5417 - digit1_accuracy: 0.8408 - digit2_accuracy: 0.8181\n",
      "Epoch 6/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.8824 - digit1_loss: 0.4161 - digit2_loss: 0.4663 - digit1_accuracy: 0.8617 - digit2_accuracy: 0.8432\n",
      "Epoch 7/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7620 - digit1_loss: 0.3622 - digit2_loss: 0.3998 - digit1_accuracy: 0.8786 - digit2_accuracy: 0.8661\n",
      "Epoch 8/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6645 - digit1_loss: 0.3167 - digit2_loss: 0.3478 - digit1_accuracy: 0.8946 - digit2_accuracy: 0.8841\n",
      "Epoch 9/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.5907 - digit1_loss: 0.2815 - digit2_loss: 0.3092 - digit1_accuracy: 0.9052 - digit2_accuracy: 0.8947\n",
      "Epoch 10/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.5297 - digit1_loss: 0.2560 - digit2_loss: 0.2737 - digit1_accuracy: 0.9131 - digit2_accuracy: 0.9069\n",
      "Epoch 11/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.4807 - digit1_loss: 0.2271 - digit2_loss: 0.2536 - digit1_accuracy: 0.9218 - digit2_accuracy: 0.9126\n",
      "Epoch 12/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.4317 - digit1_loss: 0.2110 - digit2_loss: 0.2207 - digit1_accuracy: 0.9287 - digit2_accuracy: 0.9250\n",
      "Epoch 13/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3955 - digit1_loss: 0.1906 - digit2_loss: 0.2048 - digit1_accuracy: 0.9351 - digit2_accuracy: 0.9297\n",
      "Epoch 14/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3601 - digit1_loss: 0.1745 - digit2_loss: 0.1856 - digit1_accuracy: 0.9396 - digit2_accuracy: 0.9366\n",
      "Epoch 15/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3332 - digit1_loss: 0.1597 - digit2_loss: 0.1734 - digit1_accuracy: 0.9460 - digit2_accuracy: 0.9411\n",
      "Epoch 16/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3092 - digit1_loss: 0.1495 - digit2_loss: 0.1597 - digit1_accuracy: 0.9489 - digit2_accuracy: 0.9452\n",
      "Epoch 17/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2859 - digit1_loss: 0.1390 - digit2_loss: 0.1469 - digit1_accuracy: 0.9524 - digit2_accuracy: 0.9492\n",
      "Epoch 18/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2669 - digit1_loss: 0.1286 - digit2_loss: 0.1383 - digit1_accuracy: 0.9557 - digit2_accuracy: 0.9524\n",
      "Epoch 19/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2478 - digit1_loss: 0.1194 - digit2_loss: 0.1283 - digit1_accuracy: 0.9598 - digit2_accuracy: 0.9558\n",
      "Epoch 20/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2300 - digit1_loss: 0.1098 - digit2_loss: 0.1202 - digit1_accuracy: 0.9628 - digit2_accuracy: 0.9591\n",
      "Epoch 21/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2236 - digit1_loss: 0.1085 - digit2_loss: 0.1151 - digit1_accuracy: 0.9628 - digit2_accuracy: 0.9600\n",
      "Epoch 22/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2094 - digit1_loss: 0.1009 - digit2_loss: 0.1085 - digit1_accuracy: 0.9660 - digit2_accuracy: 0.9627\n",
      "Epoch 23/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1930 - digit1_loss: 0.0946 - digit2_loss: 0.0984 - digit1_accuracy: 0.9674 - digit2_accuracy: 0.9659\n",
      "Epoch 24/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1873 - digit1_loss: 0.0917 - digit2_loss: 0.0956 - digit1_accuracy: 0.9693 - digit2_accuracy: 0.9663\n",
      "Epoch 25/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1787 - digit1_loss: 0.0858 - digit2_loss: 0.0929 - digit1_accuracy: 0.9702 - digit2_accuracy: 0.9684\n",
      "Epoch 26/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1697 - digit1_loss: 0.0803 - digit2_loss: 0.0894 - digit1_accuracy: 0.9723 - digit2_accuracy: 0.9688\n",
      "Epoch 27/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1613 - digit1_loss: 0.0803 - digit2_loss: 0.0810 - digit1_accuracy: 0.9723 - digit2_accuracy: 0.9716\n",
      "Epoch 28/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.1597 - digit1_loss: 0.0782 - digit2_loss: 0.0815 - digit1_accuracy: 0.9729 - digit2_accuracy: 0.9719\n",
      "Epoch 29/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.1488 - digit1_loss: 0.0709 - digit2_loss: 0.0779 - digit1_accuracy: 0.9756 - digit2_accuracy: 0.9726\n",
      "Epoch 30/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1401 - digit1_loss: 0.0674 - digit2_loss: 0.0727 - digit1_accuracy: 0.9764 - digit2_accuracy: 0.9749\n",
      "Epoch 31/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1393 - digit1_loss: 0.0651 - digit2_loss: 0.0742 - digit1_accuracy: 0.9776 - digit2_accuracy: 0.9743\n",
      "Epoch 32/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1309 - digit1_loss: 0.0641 - digit2_loss: 0.0668 - digit1_accuracy: 0.9792 - digit2_accuracy: 0.9768\n",
      "Epoch 33/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1349 - digit1_loss: 0.0654 - digit2_loss: 0.0694 - digit1_accuracy: 0.9781 - digit2_accuracy: 0.9767\n",
      "Epoch 34/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1271 - digit1_loss: 0.0613 - digit2_loss: 0.0658 - digit1_accuracy: 0.9794 - digit2_accuracy: 0.9769\n",
      "Epoch 35/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1133 - digit1_loss: 0.0544 - digit2_loss: 0.0589 - digit1_accuracy: 0.9820 - digit2_accuracy: 0.9803\n",
      "Epoch 36/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1207 - digit1_loss: 0.0582 - digit2_loss: 0.0625 - digit1_accuracy: 0.9810 - digit2_accuracy: 0.9788\n",
      "Epoch 37/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1154 - digit1_loss: 0.0561 - digit2_loss: 0.0594 - digit1_accuracy: 0.9806 - digit2_accuracy: 0.9795\n",
      "Epoch 38/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1091 - digit1_loss: 0.0530 - digit2_loss: 0.0561 - digit1_accuracy: 0.9826 - digit2_accuracy: 0.9810\n",
      "Epoch 39/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1088 - digit1_loss: 0.0542 - digit2_loss: 0.0546 - digit1_accuracy: 0.9830 - digit2_accuracy: 0.9817\n",
      "Epoch 40/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1074 - digit1_loss: 0.0519 - digit2_loss: 0.0555 - digit1_accuracy: 0.9830 - digit2_accuracy: 0.9821\n",
      "Epoch 41/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1074 - digit1_loss: 0.0524 - digit2_loss: 0.0550 - digit1_accuracy: 0.9837 - digit2_accuracy: 0.9818\n",
      "Epoch 42/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0990 - digit1_loss: 0.0498 - digit2_loss: 0.0493 - digit1_accuracy: 0.9840 - digit2_accuracy: 0.9830\n",
      "Epoch 43/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0991 - digit1_loss: 0.0478 - digit2_loss: 0.0513 - digit1_accuracy: 0.9844 - digit2_accuracy: 0.9831\n",
      "Epoch 44/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1042 - digit1_loss: 0.0496 - digit2_loss: 0.0545 - digit1_accuracy: 0.9834 - digit2_accuracy: 0.9816\n",
      "Epoch 45/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0880 - digit1_loss: 0.0420 - digit2_loss: 0.0460 - digit1_accuracy: 0.9861 - digit2_accuracy: 0.9846\n",
      "Epoch 46/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0965 - digit1_loss: 0.0469 - digit2_loss: 0.0496 - digit1_accuracy: 0.9847 - digit2_accuracy: 0.9839\n",
      "Epoch 47/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0888 - digit1_loss: 0.0428 - digit2_loss: 0.0461 - digit1_accuracy: 0.9861 - digit2_accuracy: 0.9840\n",
      "Epoch 48/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0901 - digit1_loss: 0.0442 - digit2_loss: 0.0459 - digit1_accuracy: 0.9856 - digit2_accuracy: 0.9843\n",
      "Epoch 49/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0912 - digit1_loss: 0.0444 - digit2_loss: 0.0468 - digit1_accuracy: 0.9857 - digit2_accuracy: 0.9847\n",
      "Epoch 50/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0890 - digit1_loss: 0.0449 - digit2_loss: 0.0441 - digit1_accuracy: 0.9859 - digit2_accuracy: 0.9856\n",
      "Epoch 51/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0883 - digit1_loss: 0.0428 - digit2_loss: 0.0455 - digit1_accuracy: 0.9861 - digit2_accuracy: 0.9857\n",
      "Epoch 52/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0838 - digit1_loss: 0.0403 - digit2_loss: 0.0435 - digit1_accuracy: 0.9871 - digit2_accuracy: 0.9859\n",
      "Epoch 53/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0852 - digit1_loss: 0.0410 - digit2_loss: 0.0442 - digit1_accuracy: 0.9864 - digit2_accuracy: 0.9857\n",
      "Epoch 54/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0834 - digit1_loss: 0.0421 - digit2_loss: 0.0413 - digit1_accuracy: 0.9866 - digit2_accuracy: 0.9864\n",
      "Epoch 55/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0771 - digit1_loss: 0.0355 - digit2_loss: 0.0416 - digit1_accuracy: 0.9885 - digit2_accuracy: 0.9866\n",
      "Epoch 56/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0794 - digit1_loss: 0.0389 - digit2_loss: 0.0405 - digit1_accuracy: 0.9872 - digit2_accuracy: 0.9868\n",
      "Epoch 57/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0787 - digit1_loss: 0.0400 - digit2_loss: 0.0387 - digit1_accuracy: 0.9875 - digit2_accuracy: 0.9872\n",
      "Epoch 58/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0856 - digit1_loss: 0.0403 - digit2_loss: 0.0454 - digit1_accuracy: 0.9866 - digit2_accuracy: 0.9863\n",
      "Epoch 59/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0712 - digit1_loss: 0.0359 - digit2_loss: 0.0353 - digit1_accuracy: 0.9887 - digit2_accuracy: 0.9889\n",
      "Epoch 60/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0722 - digit1_loss: 0.0363 - digit2_loss: 0.0359 - digit1_accuracy: 0.9887 - digit2_accuracy: 0.9884\n",
      "Epoch 61/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0796 - digit1_loss: 0.0388 - digit2_loss: 0.0408 - digit1_accuracy: 0.9881 - digit2_accuracy: 0.9868\n",
      "Epoch 62/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0733 - digit1_loss: 0.0361 - digit2_loss: 0.0372 - digit1_accuracy: 0.9888 - digit2_accuracy: 0.9881\n",
      "Epoch 63/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0763 - digit1_loss: 0.0377 - digit2_loss: 0.0386 - digit1_accuracy: 0.9888 - digit2_accuracy: 0.9874\n",
      "Epoch 64/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0669 - digit1_loss: 0.0325 - digit2_loss: 0.0344 - digit1_accuracy: 0.9898 - digit2_accuracy: 0.9886\n",
      "Epoch 65/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0760 - digit1_loss: 0.0358 - digit2_loss: 0.0401 - digit1_accuracy: 0.9889 - digit2_accuracy: 0.9878\n",
      "Epoch 66/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0690 - digit1_loss: 0.0340 - digit2_loss: 0.0351 - digit1_accuracy: 0.9894 - digit2_accuracy: 0.9891\n",
      "Epoch 67/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0726 - digit1_loss: 0.0342 - digit2_loss: 0.0383 - digit1_accuracy: 0.9894 - digit2_accuracy: 0.9885\n",
      "Epoch 68/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0628 - digit1_loss: 0.0296 - digit2_loss: 0.0332 - digit1_accuracy: 0.9904 - digit2_accuracy: 0.9889\n",
      "Epoch 69/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0697 - digit1_loss: 0.0320 - digit2_loss: 0.0377 - digit1_accuracy: 0.9902 - digit2_accuracy: 0.9887\n",
      "Epoch 70/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0638 - digit1_loss: 0.0320 - digit2_loss: 0.0318 - digit1_accuracy: 0.9902 - digit2_accuracy: 0.9895\n",
      "Epoch 71/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0675 - digit1_loss: 0.0343 - digit2_loss: 0.0331 - digit1_accuracy: 0.9896 - digit2_accuracy: 0.9897\n",
      "Epoch 72/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0582 - digit1_loss: 0.0286 - digit2_loss: 0.0296 - digit1_accuracy: 0.9911 - digit2_accuracy: 0.9902\n",
      "Epoch 73/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0653 - digit1_loss: 0.0323 - digit2_loss: 0.0330 - digit1_accuracy: 0.9899 - digit2_accuracy: 0.9894\n",
      "Epoch 74/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0682 - digit1_loss: 0.0326 - digit2_loss: 0.0356 - digit1_accuracy: 0.9902 - digit2_accuracy: 0.9890\n",
      "Epoch 75/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0670 - digit1_loss: 0.0326 - digit2_loss: 0.0344 - digit1_accuracy: 0.9896 - digit2_accuracy: 0.9897\n",
      "Epoch 76/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0689 - digit1_loss: 0.0335 - digit2_loss: 0.0354 - digit1_accuracy: 0.9904 - digit2_accuracy: 0.9895\n",
      "Epoch 77/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0636 - digit1_loss: 0.0310 - digit2_loss: 0.0327 - digit1_accuracy: 0.9909 - digit2_accuracy: 0.9900\n",
      "Epoch 78/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0591 - digit1_loss: 0.0280 - digit2_loss: 0.0312 - digit1_accuracy: 0.9913 - digit2_accuracy: 0.9901\n",
      "Epoch 79/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0651 - digit1_loss: 0.0313 - digit2_loss: 0.0338 - digit1_accuracy: 0.9906 - digit2_accuracy: 0.9898\n",
      "Epoch 80/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0589 - digit1_loss: 0.0281 - digit2_loss: 0.0308 - digit1_accuracy: 0.9915 - digit2_accuracy: 0.9906\n",
      "Epoch 81/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0613 - digit1_loss: 0.0280 - digit2_loss: 0.0333 - digit1_accuracy: 0.9913 - digit2_accuracy: 0.9899\n",
      "Epoch 82/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0604 - digit1_loss: 0.0297 - digit2_loss: 0.0307 - digit1_accuracy: 0.9904 - digit2_accuracy: 0.9903\n",
      "Epoch 83/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0617 - digit1_loss: 0.0309 - digit2_loss: 0.0309 - digit1_accuracy: 0.9906 - digit2_accuracy: 0.9907\n",
      "Epoch 84/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0613 - digit1_loss: 0.0290 - digit2_loss: 0.0323 - digit1_accuracy: 0.9912 - digit2_accuracy: 0.9906\n",
      "Epoch 85/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0560 - digit1_loss: 0.0272 - digit2_loss: 0.0288 - digit1_accuracy: 0.9915 - digit2_accuracy: 0.9907\n",
      "Epoch 86/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0561 - digit1_loss: 0.0270 - digit2_loss: 0.0291 - digit1_accuracy: 0.9919 - digit2_accuracy: 0.9910\n",
      "Epoch 87/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0645 - digit1_loss: 0.0318 - digit2_loss: 0.0327 - digit1_accuracy: 0.9902 - digit2_accuracy: 0.9906\n",
      "Epoch 88/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0619 - digit1_loss: 0.0295 - digit2_loss: 0.0325 - digit1_accuracy: 0.9912 - digit2_accuracy: 0.9907\n",
      "Epoch 89/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0541 - digit1_loss: 0.0277 - digit2_loss: 0.0264 - digit1_accuracy: 0.9916 - digit2_accuracy: 0.9919\n",
      "Epoch 90/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0593 - digit1_loss: 0.0294 - digit2_loss: 0.0299 - digit1_accuracy: 0.9911 - digit2_accuracy: 0.9916\n",
      "Epoch 91/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0553 - digit1_loss: 0.0267 - digit2_loss: 0.0285 - digit1_accuracy: 0.9918 - digit2_accuracy: 0.9910\n",
      "Epoch 92/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0558 - digit1_loss: 0.0254 - digit2_loss: 0.0304 - digit1_accuracy: 0.9925 - digit2_accuracy: 0.9912\n",
      "Epoch 93/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0552 - digit1_loss: 0.0249 - digit2_loss: 0.0303 - digit1_accuracy: 0.9925 - digit2_accuracy: 0.9909\n",
      "Epoch 94/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0520 - digit1_loss: 0.0241 - digit2_loss: 0.0278 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9917\n",
      "Epoch 95/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0556 - digit1_loss: 0.0251 - digit2_loss: 0.0305 - digit1_accuracy: 0.9922 - digit2_accuracy: 0.9913\n",
      "Epoch 96/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0567 - digit1_loss: 0.0293 - digit2_loss: 0.0274 - digit1_accuracy: 0.9913 - digit2_accuracy: 0.9913\n",
      "Epoch 97/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0514 - digit1_loss: 0.0247 - digit2_loss: 0.0267 - digit1_accuracy: 0.9927 - digit2_accuracy: 0.9921\n",
      "Epoch 98/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0465 - digit1_loss: 0.0234 - digit2_loss: 0.0231 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9932\n",
      "Epoch 99/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0592 - digit1_loss: 0.0282 - digit2_loss: 0.0310 - digit1_accuracy: 0.9919 - digit2_accuracy: 0.9911\n",
      "Epoch 100/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0521 - digit1_loss: 0.0241 - digit2_loss: 0.0281 - digit1_accuracy: 0.9922 - digit2_accuracy: 0.9921\n",
      "Epoch 101/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0549 - digit1_loss: 0.0270 - digit2_loss: 0.0279 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9919\n",
      "Epoch 102/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0532 - digit1_loss: 0.0252 - digit2_loss: 0.0281 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9917\n",
      "Epoch 103/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0582 - digit1_loss: 0.0293 - digit2_loss: 0.0290 - digit1_accuracy: 0.9916 - digit2_accuracy: 0.9916\n",
      "Epoch 104/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0449 - digit1_loss: 0.0232 - digit2_loss: 0.0217 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9933\n",
      "Epoch 105/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0547 - digit1_loss: 0.0257 - digit2_loss: 0.0289 - digit1_accuracy: 0.9927 - digit2_accuracy: 0.9916\n",
      "Epoch 106/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0577 - digit1_loss: 0.0295 - digit2_loss: 0.0282 - digit1_accuracy: 0.9919 - digit2_accuracy: 0.9915\n",
      "Epoch 107/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0513 - digit1_loss: 0.0242 - digit2_loss: 0.0271 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9922\n",
      "Epoch 108/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0522 - digit1_loss: 0.0252 - digit2_loss: 0.0270 - digit1_accuracy: 0.9923 - digit2_accuracy: 0.9922\n",
      "Epoch 109/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0450 - digit1_loss: 0.0240 - digit2_loss: 0.0210 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9935\n",
      "Epoch 110/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0437 - digit1_loss: 0.0215 - digit2_loss: 0.0222 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9933\n",
      "Epoch 111/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0460 - digit1_loss: 0.0214 - digit2_loss: 0.0247 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9929\n",
      "Epoch 112/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0546 - digit1_loss: 0.0264 - digit2_loss: 0.0282 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9918\n",
      "Epoch 113/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0489 - digit1_loss: 0.0242 - digit2_loss: 0.0247 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9930\n",
      "Epoch 114/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0480 - digit1_loss: 0.0227 - digit2_loss: 0.0253 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9926\n",
      "Epoch 115/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0546 - digit1_loss: 0.0269 - digit2_loss: 0.0277 - digit1_accuracy: 0.9927 - digit2_accuracy: 0.9919\n",
      "Epoch 116/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0463 - digit1_loss: 0.0226 - digit2_loss: 0.0238 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9934\n",
      "Epoch 117/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0513 - digit1_loss: 0.0254 - digit2_loss: 0.0259 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9933\n",
      "Epoch 118/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0520 - digit1_loss: 0.0258 - digit2_loss: 0.0262 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9929\n",
      "Epoch 119/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0488 - digit1_loss: 0.0227 - digit2_loss: 0.0261 - digit1_accuracy: 0.9934 - digit2_accuracy: 0.9925\n",
      "Epoch 120/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0462 - digit1_loss: 0.0225 - digit2_loss: 0.0237 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9934\n",
      "Epoch 121/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0436 - digit1_loss: 0.0193 - digit2_loss: 0.0243 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9932\n",
      "Epoch 122/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0540 - digit1_loss: 0.0274 - digit2_loss: 0.0265 - digit1_accuracy: 0.9925 - digit2_accuracy: 0.9924\n",
      "Epoch 123/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0479 - digit1_loss: 0.0249 - digit2_loss: 0.0230 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9932\n",
      "Epoch 124/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0430 - digit1_loss: 0.0192 - digit2_loss: 0.0238 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9933\n",
      "Epoch 125/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0485 - digit1_loss: 0.0241 - digit2_loss: 0.0244 - digit1_accuracy: 0.9936 - digit2_accuracy: 0.9936\n",
      "Epoch 126/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0464 - digit1_loss: 0.0232 - digit2_loss: 0.0232 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9930\n",
      "Epoch 127/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0462 - digit1_loss: 0.0216 - digit2_loss: 0.0246 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9932\n",
      "Epoch 128/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0499 - digit1_loss: 0.0255 - digit2_loss: 0.0244 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9930\n",
      "Epoch 129/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0498 - digit1_loss: 0.0255 - digit2_loss: 0.0242 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9936\n",
      "Epoch 130/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0449 - digit1_loss: 0.0215 - digit2_loss: 0.0234 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9932\n",
      "Epoch 131/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0456 - digit1_loss: 0.0210 - digit2_loss: 0.0246 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9929\n",
      "Epoch 132/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0440 - digit1_loss: 0.0220 - digit2_loss: 0.0221 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9942\n",
      "Epoch 133/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0431 - digit1_loss: 0.0226 - digit2_loss: 0.0205 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9936\n",
      "Epoch 134/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0400 - digit1_loss: 0.0190 - digit2_loss: 0.0210 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9941\n",
      "Epoch 135/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0448 - digit1_loss: 0.0227 - digit2_loss: 0.0222 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9933\n",
      "Epoch 136/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0495 - digit1_loss: 0.0249 - digit2_loss: 0.0246 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9926\n",
      "Epoch 137/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0428 - digit1_loss: 0.0227 - digit2_loss: 0.0201 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9939\n",
      "Epoch 138/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0471 - digit1_loss: 0.0243 - digit2_loss: 0.0228 - digit1_accuracy: 0.9936 - digit2_accuracy: 0.9936\n",
      "Epoch 139/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0422 - digit1_loss: 0.0203 - digit2_loss: 0.0219 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9936\n",
      "Epoch 140/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0470 - digit1_loss: 0.0216 - digit2_loss: 0.0254 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9930\n",
      "Epoch 141/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0409 - digit1_loss: 0.0217 - digit2_loss: 0.0192 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9948\n",
      "Epoch 142/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0453 - digit1_loss: 0.0211 - digit2_loss: 0.0242 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9932\n",
      "Epoch 143/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0345 - digit1_loss: 0.0170 - digit2_loss: 0.0175 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9946\n",
      "Epoch 144/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0478 - digit1_loss: 0.0216 - digit2_loss: 0.0262 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9929\n",
      "Epoch 145/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0419 - digit1_loss: 0.0195 - digit2_loss: 0.0225 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9938\n",
      "Epoch 146/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0470 - digit1_loss: 0.0234 - digit2_loss: 0.0237 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9934\n",
      "Epoch 147/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0449 - digit1_loss: 0.0222 - digit2_loss: 0.0226 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9936\n",
      "Epoch 148/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0403 - digit1_loss: 0.0189 - digit2_loss: 0.0214 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9940\n",
      "Epoch 149/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0447 - digit1_loss: 0.0212 - digit2_loss: 0.0235 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9939\n",
      "Epoch 150/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0444 - digit1_loss: 0.0220 - digit2_loss: 0.0224 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9944\n",
      "Epoch 151/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0387 - digit1_loss: 0.0202 - digit2_loss: 0.0185 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9945\n",
      "Epoch 152/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0488 - digit1_loss: 0.0241 - digit2_loss: 0.0247 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9936\n",
      "Epoch 153/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0457 - digit1_loss: 0.0222 - digit2_loss: 0.0235 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9938\n",
      "Epoch 154/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0405 - digit1_loss: 0.0210 - digit2_loss: 0.0195 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9943\n",
      "Epoch 155/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0485 - digit1_loss: 0.0246 - digit2_loss: 0.0239 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9940\n",
      "Epoch 156/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0381 - digit1_loss: 0.0193 - digit2_loss: 0.0188 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9948\n",
      "Epoch 157/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0399 - digit1_loss: 0.0182 - digit2_loss: 0.0217 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9941\n",
      "Epoch 158/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0411 - digit1_loss: 0.0204 - digit2_loss: 0.0207 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9942\n",
      "Epoch 159/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0431 - digit1_loss: 0.0216 - digit2_loss: 0.0215 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9941\n",
      "Epoch 160/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0370 - digit1_loss: 0.0174 - digit2_loss: 0.0196 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9947\n",
      "Epoch 161/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0402 - digit1_loss: 0.0202 - digit2_loss: 0.0200 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9946\n",
      "Epoch 162/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0379 - digit1_loss: 0.0189 - digit2_loss: 0.0190 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9947\n",
      "Epoch 163/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0435 - digit1_loss: 0.0199 - digit2_loss: 0.0235 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9937\n",
      "Epoch 164/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0484 - digit1_loss: 0.0248 - digit2_loss: 0.0235 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9935\n",
      "Epoch 165/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0387 - digit1_loss: 0.0184 - digit2_loss: 0.0203 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9944\n",
      "Epoch 166/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0457 - digit1_loss: 0.0237 - digit2_loss: 0.0219 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9939\n",
      "Epoch 167/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0411 - digit1_loss: 0.0195 - digit2_loss: 0.0216 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9945\n",
      "Epoch 168/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0343 - digit1_loss: 0.0150 - digit2_loss: 0.0192 - digit1_accuracy: 0.9961 - digit2_accuracy: 0.9951\n",
      "Epoch 169/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0427 - digit1_loss: 0.0197 - digit2_loss: 0.0230 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9941\n",
      "Epoch 170/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0420 - digit1_loss: 0.0206 - digit2_loss: 0.0215 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9944\n",
      "Epoch 171/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0452 - digit1_loss: 0.0235 - digit2_loss: 0.0217 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9940\n",
      "Epoch 172/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0444 - digit1_loss: 0.0233 - digit2_loss: 0.0211 - digit1_accuracy: 0.9943 - digit2_accuracy: 0.9944\n",
      "Epoch 173/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0435 - digit1_loss: 0.0196 - digit2_loss: 0.0239 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9941\n",
      "Epoch 174/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0368 - digit1_loss: 0.0188 - digit2_loss: 0.0179 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9949\n",
      "Epoch 175/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0398 - digit1_loss: 0.0201 - digit2_loss: 0.0197 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9950\n",
      "Epoch 176/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0383 - digit1_loss: 0.0191 - digit2_loss: 0.0192 - digit1_accuracy: 0.9953 - digit2_accuracy: 0.9948\n",
      "Epoch 177/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0390 - digit1_loss: 0.0193 - digit2_loss: 0.0197 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9944\n",
      "Epoch 178/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0436 - digit1_loss: 0.0185 - digit2_loss: 0.0251 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9941\n",
      "Epoch 179/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0389 - digit1_loss: 0.0185 - digit2_loss: 0.0205 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9948\n",
      "Epoch 180/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0350 - digit1_loss: 0.0179 - digit2_loss: 0.0171 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9951\n",
      "Epoch 181/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0408 - digit1_loss: 0.0180 - digit2_loss: 0.0229 - digit1_accuracy: 0.9953 - digit2_accuracy: 0.9944\n",
      "Epoch 182/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0390 - digit1_loss: 0.0196 - digit2_loss: 0.0195 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9950\n",
      "Epoch 183/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0369 - digit1_loss: 0.0162 - digit2_loss: 0.0207 - digit1_accuracy: 0.9956 - digit2_accuracy: 0.9946\n",
      "Epoch 184/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0397 - digit1_loss: 0.0169 - digit2_loss: 0.0228 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9946\n",
      "Epoch 185/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0358 - digit1_loss: 0.0167 - digit2_loss: 0.0192 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9949\n",
      "Epoch 186/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0375 - digit1_loss: 0.0183 - digit2_loss: 0.0192 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9949\n",
      "Epoch 187/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0444 - digit1_loss: 0.0212 - digit2_loss: 0.0231 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9941\n",
      "Epoch 188/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0362 - digit1_loss: 0.0196 - digit2_loss: 0.0166 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9955\n",
      "Epoch 189/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0403 - digit1_loss: 0.0187 - digit2_loss: 0.0216 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9944\n",
      "Epoch 190/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0342 - digit1_loss: 0.0157 - digit2_loss: 0.0185 - digit1_accuracy: 0.9958 - digit2_accuracy: 0.9952\n",
      "Epoch 191/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0405 - digit1_loss: 0.0199 - digit2_loss: 0.0206 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9945\n",
      "Epoch 192/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0368 - digit1_loss: 0.0185 - digit2_loss: 0.0182 - digit1_accuracy: 0.9957 - digit2_accuracy: 0.9952\n",
      "Epoch 193/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0425 - digit1_loss: 0.0229 - digit2_loss: 0.0196 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9951\n",
      "Epoch 194/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0434 - digit1_loss: 0.0232 - digit2_loss: 0.0202 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9952\n",
      "Epoch 195/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0355 - digit1_loss: 0.0176 - digit2_loss: 0.0179 - digit1_accuracy: 0.9957 - digit2_accuracy: 0.9955\n",
      "Epoch 196/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0434 - digit1_loss: 0.0224 - digit2_loss: 0.0210 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9944\n",
      "Epoch 197/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0364 - digit1_loss: 0.0174 - digit2_loss: 0.0189 - digit1_accuracy: 0.9953 - digit2_accuracy: 0.9952\n",
      "Epoch 198/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0329 - digit1_loss: 0.0155 - digit2_loss: 0.0174 - digit1_accuracy: 0.9960 - digit2_accuracy: 0.9956\n",
      "Epoch 199/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0354 - digit1_loss: 0.0183 - digit2_loss: 0.0171 - digit1_accuracy: 0.9958 - digit2_accuracy: 0.9954\n",
      "Epoch 200/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0384 - digit1_loss: 0.0169 - digit2_loss: 0.0215 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9950\n",
      "loss : 2.475400765736898\n",
      "digit1_loss : 1.1704961061477661\n",
      "digit2_loss : 1.3049048980077107\n",
      "digit1_accuracy : 0.9248055617014567\n",
      "digit2_accuracy : 0.9181944330533346\n",
      "Fold 4\n",
      "Epoch 1/200\n",
      "750/750 [==============================] - 4s 4ms/step - loss: 3.0795 - digit1_loss: 1.4330 - digit2_loss: 1.6465 - digit1_accuracy: 0.4950 - digit2_accuracy: 0.3995\n",
      "Epoch 2/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.7417 - digit1_loss: 0.7954 - digit2_loss: 0.9462 - digit1_accuracy: 0.7289 - digit2_accuracy: 0.6758\n",
      "Epoch 3/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.2709 - digit1_loss: 0.5902 - digit2_loss: 0.6807 - digit1_accuracy: 0.8042 - digit2_accuracy: 0.7712\n",
      "Epoch 4/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 1.0029 - digit1_loss: 0.4715 - digit2_loss: 0.5314 - digit1_accuracy: 0.8434 - digit2_accuracy: 0.8245\n",
      "Epoch 5/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.8324 - digit1_loss: 0.3911 - digit2_loss: 0.4413 - digit1_accuracy: 0.8730 - digit2_accuracy: 0.8543\n",
      "Epoch 6/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7103 - digit1_loss: 0.3358 - digit2_loss: 0.3745 - digit1_accuracy: 0.8895 - digit2_accuracy: 0.8770\n",
      "Epoch 7/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6073 - digit1_loss: 0.2874 - digit2_loss: 0.3199 - digit1_accuracy: 0.9056 - digit2_accuracy: 0.8940\n",
      "Epoch 8/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.5376 - digit1_loss: 0.2541 - digit2_loss: 0.2836 - digit1_accuracy: 0.9165 - digit2_accuracy: 0.9060\n",
      "Epoch 9/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.4735 - digit1_loss: 0.2278 - digit2_loss: 0.2457 - digit1_accuracy: 0.9247 - digit2_accuracy: 0.9186\n",
      "Epoch 10/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.4173 - digit1_loss: 0.1984 - digit2_loss: 0.2189 - digit1_accuracy: 0.9335 - digit2_accuracy: 0.9270\n",
      "Epoch 11/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3763 - digit1_loss: 0.1779 - digit2_loss: 0.1983 - digit1_accuracy: 0.9397 - digit2_accuracy: 0.9336\n",
      "Epoch 12/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3334 - digit1_loss: 0.1595 - digit2_loss: 0.1739 - digit1_accuracy: 0.9467 - digit2_accuracy: 0.9422\n",
      "Epoch 13/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3075 - digit1_loss: 0.1472 - digit2_loss: 0.1603 - digit1_accuracy: 0.9502 - digit2_accuracy: 0.9462\n",
      "Epoch 14/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.2792 - digit1_loss: 0.1319 - digit2_loss: 0.1473 - digit1_accuracy: 0.9554 - digit2_accuracy: 0.9491\n",
      "Epoch 15/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.2614 - digit1_loss: 0.1269 - digit2_loss: 0.1344 - digit1_accuracy: 0.9551 - digit2_accuracy: 0.9540\n",
      "Epoch 16/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.2370 - digit1_loss: 0.1138 - digit2_loss: 0.1232 - digit1_accuracy: 0.9605 - digit2_accuracy: 0.9582\n",
      "Epoch 17/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2221 - digit1_loss: 0.1091 - digit2_loss: 0.1131 - digit1_accuracy: 0.9634 - digit2_accuracy: 0.9610\n",
      "Epoch 18/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2088 - digit1_loss: 0.0984 - digit2_loss: 0.1103 - digit1_accuracy: 0.9667 - digit2_accuracy: 0.9629\n",
      "Epoch 19/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1899 - digit1_loss: 0.0902 - digit2_loss: 0.0997 - digit1_accuracy: 0.9681 - digit2_accuracy: 0.9668\n",
      "Epoch 20/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1822 - digit1_loss: 0.0885 - digit2_loss: 0.0936 - digit1_accuracy: 0.9693 - digit2_accuracy: 0.9675\n",
      "Epoch 21/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1742 - digit1_loss: 0.0840 - digit2_loss: 0.0901 - digit1_accuracy: 0.9718 - digit2_accuracy: 0.9688\n",
      "Epoch 22/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1637 - digit1_loss: 0.0780 - digit2_loss: 0.0857 - digit1_accuracy: 0.9736 - digit2_accuracy: 0.9705\n",
      "Epoch 23/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1593 - digit1_loss: 0.0770 - digit2_loss: 0.0822 - digit1_accuracy: 0.9738 - digit2_accuracy: 0.9716\n",
      "Epoch 24/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1508 - digit1_loss: 0.0729 - digit2_loss: 0.0779 - digit1_accuracy: 0.9746 - digit2_accuracy: 0.9742\n",
      "Epoch 25/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1441 - digit1_loss: 0.0707 - digit2_loss: 0.0734 - digit1_accuracy: 0.9764 - digit2_accuracy: 0.9753\n",
      "Epoch 26/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1340 - digit1_loss: 0.0652 - digit2_loss: 0.0688 - digit1_accuracy: 0.9782 - digit2_accuracy: 0.9768\n",
      "Epoch 27/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1376 - digit1_loss: 0.0675 - digit2_loss: 0.0701 - digit1_accuracy: 0.9779 - digit2_accuracy: 0.9771\n",
      "Epoch 28/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1256 - digit1_loss: 0.0600 - digit2_loss: 0.0657 - digit1_accuracy: 0.9794 - digit2_accuracy: 0.9781\n",
      "Epoch 29/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1246 - digit1_loss: 0.0617 - digit2_loss: 0.0629 - digit1_accuracy: 0.9797 - digit2_accuracy: 0.9780\n",
      "Epoch 30/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1146 - digit1_loss: 0.0555 - digit2_loss: 0.0591 - digit1_accuracy: 0.9821 - digit2_accuracy: 0.9805\n",
      "Epoch 31/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1190 - digit1_loss: 0.0593 - digit2_loss: 0.0597 - digit1_accuracy: 0.9805 - digit2_accuracy: 0.9801\n",
      "Epoch 32/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1166 - digit1_loss: 0.0570 - digit2_loss: 0.0596 - digit1_accuracy: 0.9812 - digit2_accuracy: 0.9802\n",
      "Epoch 33/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1107 - digit1_loss: 0.0539 - digit2_loss: 0.0568 - digit1_accuracy: 0.9821 - digit2_accuracy: 0.9808\n",
      "Epoch 34/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1109 - digit1_loss: 0.0567 - digit2_loss: 0.0542 - digit1_accuracy: 0.9823 - digit2_accuracy: 0.9819\n",
      "Epoch 35/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1051 - digit1_loss: 0.0513 - digit2_loss: 0.0537 - digit1_accuracy: 0.9831 - digit2_accuracy: 0.9819\n",
      "Epoch 36/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0982 - digit1_loss: 0.0484 - digit2_loss: 0.0498 - digit1_accuracy: 0.9837 - digit2_accuracy: 0.9840\n",
      "Epoch 37/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0983 - digit1_loss: 0.0469 - digit2_loss: 0.0514 - digit1_accuracy: 0.9848 - digit2_accuracy: 0.9836\n",
      "Epoch 38/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0947 - digit1_loss: 0.0445 - digit2_loss: 0.0502 - digit1_accuracy: 0.9849 - digit2_accuracy: 0.9838\n",
      "Epoch 39/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0978 - digit1_loss: 0.0484 - digit2_loss: 0.0494 - digit1_accuracy: 0.9845 - digit2_accuracy: 0.9837\n",
      "Epoch 40/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0917 - digit1_loss: 0.0439 - digit2_loss: 0.0478 - digit1_accuracy: 0.9860 - digit2_accuracy: 0.9851\n",
      "Epoch 41/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0892 - digit1_loss: 0.0445 - digit2_loss: 0.0447 - digit1_accuracy: 0.9851 - digit2_accuracy: 0.9851\n",
      "Epoch 42/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0899 - digit1_loss: 0.0433 - digit2_loss: 0.0465 - digit1_accuracy: 0.9857 - digit2_accuracy: 0.9847\n",
      "Epoch 43/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0886 - digit1_loss: 0.0428 - digit2_loss: 0.0458 - digit1_accuracy: 0.9856 - digit2_accuracy: 0.9853\n",
      "Epoch 44/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0780 - digit1_loss: 0.0366 - digit2_loss: 0.0414 - digit1_accuracy: 0.9884 - digit2_accuracy: 0.9862\n",
      "Epoch 45/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0853 - digit1_loss: 0.0421 - digit2_loss: 0.0432 - digit1_accuracy: 0.9859 - digit2_accuracy: 0.9857\n",
      "Epoch 46/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0872 - digit1_loss: 0.0440 - digit2_loss: 0.0432 - digit1_accuracy: 0.9859 - digit2_accuracy: 0.9864\n",
      "Epoch 47/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0861 - digit1_loss: 0.0440 - digit2_loss: 0.0420 - digit1_accuracy: 0.9862 - digit2_accuracy: 0.9866\n",
      "Epoch 48/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0832 - digit1_loss: 0.0412 - digit2_loss: 0.0420 - digit1_accuracy: 0.9868 - digit2_accuracy: 0.9867\n",
      "Epoch 49/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0796 - digit1_loss: 0.0371 - digit2_loss: 0.0424 - digit1_accuracy: 0.9880 - digit2_accuracy: 0.9870\n",
      "Epoch 50/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0737 - digit1_loss: 0.0353 - digit2_loss: 0.0384 - digit1_accuracy: 0.9882 - digit2_accuracy: 0.9878\n",
      "Epoch 51/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0782 - digit1_loss: 0.0410 - digit2_loss: 0.0372 - digit1_accuracy: 0.9872 - digit2_accuracy: 0.9885\n",
      "Epoch 52/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0756 - digit1_loss: 0.0374 - digit2_loss: 0.0382 - digit1_accuracy: 0.9882 - digit2_accuracy: 0.9877\n",
      "Epoch 53/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0708 - digit1_loss: 0.0346 - digit2_loss: 0.0362 - digit1_accuracy: 0.9890 - digit2_accuracy: 0.9883\n",
      "Epoch 54/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0759 - digit1_loss: 0.0399 - digit2_loss: 0.0360 - digit1_accuracy: 0.9880 - digit2_accuracy: 0.9879\n",
      "Epoch 55/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0646 - digit1_loss: 0.0304 - digit2_loss: 0.0343 - digit1_accuracy: 0.9902 - digit2_accuracy: 0.9891\n",
      "Epoch 56/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0795 - digit1_loss: 0.0395 - digit2_loss: 0.0400 - digit1_accuracy: 0.9877 - digit2_accuracy: 0.9874\n",
      "Epoch 57/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0732 - digit1_loss: 0.0376 - digit2_loss: 0.0356 - digit1_accuracy: 0.9880 - digit2_accuracy: 0.9889\n",
      "Epoch 58/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0754 - digit1_loss: 0.0373 - digit2_loss: 0.0380 - digit1_accuracy: 0.9884 - digit2_accuracy: 0.9885\n",
      "Epoch 59/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0688 - digit1_loss: 0.0329 - digit2_loss: 0.0360 - digit1_accuracy: 0.9897 - digit2_accuracy: 0.9889\n",
      "Epoch 60/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0672 - digit1_loss: 0.0323 - digit2_loss: 0.0349 - digit1_accuracy: 0.9898 - digit2_accuracy: 0.9895\n",
      "Epoch 61/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0733 - digit1_loss: 0.0373 - digit2_loss: 0.0360 - digit1_accuracy: 0.9891 - digit2_accuracy: 0.9890\n",
      "Epoch 62/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0656 - digit1_loss: 0.0340 - digit2_loss: 0.0316 - digit1_accuracy: 0.9894 - digit2_accuracy: 0.9894\n",
      "Epoch 63/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0647 - digit1_loss: 0.0327 - digit2_loss: 0.0321 - digit1_accuracy: 0.9895 - digit2_accuracy: 0.9900\n",
      "Epoch 64/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0658 - digit1_loss: 0.0320 - digit2_loss: 0.0337 - digit1_accuracy: 0.9896 - digit2_accuracy: 0.9891\n",
      "Epoch 65/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0653 - digit1_loss: 0.0315 - digit2_loss: 0.0337 - digit1_accuracy: 0.9897 - digit2_accuracy: 0.9896\n",
      "Epoch 66/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0593 - digit1_loss: 0.0300 - digit2_loss: 0.0293 - digit1_accuracy: 0.9903 - digit2_accuracy: 0.9907\n",
      "Epoch 67/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0645 - digit1_loss: 0.0301 - digit2_loss: 0.0344 - digit1_accuracy: 0.9908 - digit2_accuracy: 0.9895\n",
      "Epoch 68/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0618 - digit1_loss: 0.0308 - digit2_loss: 0.0311 - digit1_accuracy: 0.9908 - digit2_accuracy: 0.9904\n",
      "Epoch 69/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0637 - digit1_loss: 0.0316 - digit2_loss: 0.0320 - digit1_accuracy: 0.9905 - digit2_accuracy: 0.9900\n",
      "Epoch 70/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0622 - digit1_loss: 0.0311 - digit2_loss: 0.0311 - digit1_accuracy: 0.9909 - digit2_accuracy: 0.9901\n",
      "Epoch 71/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0647 - digit1_loss: 0.0321 - digit2_loss: 0.0326 - digit1_accuracy: 0.9900 - digit2_accuracy: 0.9901\n",
      "Epoch 72/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0652 - digit1_loss: 0.0315 - digit2_loss: 0.0337 - digit1_accuracy: 0.9906 - digit2_accuracy: 0.9897\n",
      "Epoch 73/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0634 - digit1_loss: 0.0315 - digit2_loss: 0.0319 - digit1_accuracy: 0.9904 - digit2_accuracy: 0.9907\n",
      "Epoch 74/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0563 - digit1_loss: 0.0275 - digit2_loss: 0.0288 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9914\n",
      "Epoch 75/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0588 - digit1_loss: 0.0283 - digit2_loss: 0.0306 - digit1_accuracy: 0.9914 - digit2_accuracy: 0.9905\n",
      "Epoch 76/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0550 - digit1_loss: 0.0268 - digit2_loss: 0.0281 - digit1_accuracy: 0.9910 - digit2_accuracy: 0.9916\n",
      "Epoch 77/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0597 - digit1_loss: 0.0296 - digit2_loss: 0.0301 - digit1_accuracy: 0.9909 - digit2_accuracy: 0.9910\n",
      "Epoch 78/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0588 - digit1_loss: 0.0303 - digit2_loss: 0.0285 - digit1_accuracy: 0.9911 - digit2_accuracy: 0.9914\n",
      "Epoch 79/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0590 - digit1_loss: 0.0302 - digit2_loss: 0.0288 - digit1_accuracy: 0.9910 - digit2_accuracy: 0.9910\n",
      "Epoch 80/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0562 - digit1_loss: 0.0295 - digit2_loss: 0.0267 - digit1_accuracy: 0.9916 - digit2_accuracy: 0.9920\n",
      "Epoch 81/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0583 - digit1_loss: 0.0306 - digit2_loss: 0.0277 - digit1_accuracy: 0.9912 - digit2_accuracy: 0.9917\n",
      "Epoch 82/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0580 - digit1_loss: 0.0303 - digit2_loss: 0.0277 - digit1_accuracy: 0.9916 - digit2_accuracy: 0.9921\n",
      "Epoch 83/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0560 - digit1_loss: 0.0267 - digit2_loss: 0.0293 - digit1_accuracy: 0.9919 - digit2_accuracy: 0.9911\n",
      "Epoch 84/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0523 - digit1_loss: 0.0260 - digit2_loss: 0.0263 - digit1_accuracy: 0.9918 - digit2_accuracy: 0.9923\n",
      "Epoch 85/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0550 - digit1_loss: 0.0259 - digit2_loss: 0.0291 - digit1_accuracy: 0.9922 - digit2_accuracy: 0.9919\n",
      "Epoch 86/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0546 - digit1_loss: 0.0285 - digit2_loss: 0.0261 - digit1_accuracy: 0.9911 - digit2_accuracy: 0.9921\n",
      "Epoch 87/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0561 - digit1_loss: 0.0256 - digit2_loss: 0.0305 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9911\n",
      "Epoch 88/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0535 - digit1_loss: 0.0269 - digit2_loss: 0.0266 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9917\n",
      "Epoch 89/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0532 - digit1_loss: 0.0264 - digit2_loss: 0.0269 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9919\n",
      "Epoch 90/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0528 - digit1_loss: 0.0262 - digit2_loss: 0.0266 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9919\n",
      "Epoch 91/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0520 - digit1_loss: 0.0277 - digit2_loss: 0.0243 - digit1_accuracy: 0.9922 - digit2_accuracy: 0.9933\n",
      "Epoch 92/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0549 - digit1_loss: 0.0289 - digit2_loss: 0.0260 - digit1_accuracy: 0.9916 - digit2_accuracy: 0.9920\n",
      "Epoch 93/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0501 - digit1_loss: 0.0259 - digit2_loss: 0.0243 - digit1_accuracy: 0.9923 - digit2_accuracy: 0.9926\n",
      "Epoch 94/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0511 - digit1_loss: 0.0266 - digit2_loss: 0.0245 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9931\n",
      "Epoch 95/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0526 - digit1_loss: 0.0267 - digit2_loss: 0.0259 - digit1_accuracy: 0.9920 - digit2_accuracy: 0.9919\n",
      "Epoch 96/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0536 - digit1_loss: 0.0249 - digit2_loss: 0.0287 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9920\n",
      "Epoch 97/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0494 - digit1_loss: 0.0249 - digit2_loss: 0.0245 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9926\n",
      "Epoch 98/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0495 - digit1_loss: 0.0242 - digit2_loss: 0.0253 - digit1_accuracy: 0.9925 - digit2_accuracy: 0.9926\n",
      "Epoch 99/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0573 - digit1_loss: 0.0275 - digit2_loss: 0.0298 - digit1_accuracy: 0.9924 - digit2_accuracy: 0.9911\n",
      "Epoch 100/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0472 - digit1_loss: 0.0233 - digit2_loss: 0.0239 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9930\n",
      "Epoch 101/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0468 - digit1_loss: 0.0229 - digit2_loss: 0.0239 - digit1_accuracy: 0.9934 - digit2_accuracy: 0.9929\n",
      "Epoch 102/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0501 - digit1_loss: 0.0241 - digit2_loss: 0.0260 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9925\n",
      "Epoch 103/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0466 - digit1_loss: 0.0235 - digit2_loss: 0.0231 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9937\n",
      "Epoch 104/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0468 - digit1_loss: 0.0231 - digit2_loss: 0.0237 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9933\n",
      "Epoch 105/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0564 - digit1_loss: 0.0284 - digit2_loss: 0.0280 - digit1_accuracy: 0.9922 - digit2_accuracy: 0.9924\n",
      "Epoch 106/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0478 - digit1_loss: 0.0245 - digit2_loss: 0.0233 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9930\n",
      "Epoch 107/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0458 - digit1_loss: 0.0220 - digit2_loss: 0.0238 - digit1_accuracy: 0.9929 - digit2_accuracy: 0.9929\n",
      "Epoch 108/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0459 - digit1_loss: 0.0226 - digit2_loss: 0.0233 - digit1_accuracy: 0.9934 - digit2_accuracy: 0.9929\n",
      "Epoch 109/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0447 - digit1_loss: 0.0215 - digit2_loss: 0.0232 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9932\n",
      "Epoch 110/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0416 - digit1_loss: 0.0219 - digit2_loss: 0.0196 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9942\n",
      "Epoch 111/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0530 - digit1_loss: 0.0262 - digit2_loss: 0.0267 - digit1_accuracy: 0.9927 - digit2_accuracy: 0.9927\n",
      "Epoch 112/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0520 - digit1_loss: 0.0249 - digit2_loss: 0.0271 - digit1_accuracy: 0.9927 - digit2_accuracy: 0.9927\n",
      "Epoch 113/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0459 - digit1_loss: 0.0228 - digit2_loss: 0.0231 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9930\n",
      "Epoch 114/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0508 - digit1_loss: 0.0238 - digit2_loss: 0.0270 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9922\n",
      "Epoch 115/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0420 - digit1_loss: 0.0221 - digit2_loss: 0.0199 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9943\n",
      "Epoch 116/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0485 - digit1_loss: 0.0235 - digit2_loss: 0.0250 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9932\n",
      "Epoch 117/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0529 - digit1_loss: 0.0247 - digit2_loss: 0.0282 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9919\n",
      "Epoch 118/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0422 - digit1_loss: 0.0205 - digit2_loss: 0.0217 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9936\n",
      "Epoch 119/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0514 - digit1_loss: 0.0260 - digit2_loss: 0.0254 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9933\n",
      "Epoch 120/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0503 - digit1_loss: 0.0250 - digit2_loss: 0.0252 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9930\n",
      "Epoch 121/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0494 - digit1_loss: 0.0265 - digit2_loss: 0.0228 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9934\n",
      "Epoch 122/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0487 - digit1_loss: 0.0237 - digit2_loss: 0.0250 - digit1_accuracy: 0.9936 - digit2_accuracy: 0.9937\n",
      "Epoch 123/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0400 - digit1_loss: 0.0203 - digit2_loss: 0.0197 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9942\n",
      "Epoch 124/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0447 - digit1_loss: 0.0219 - digit2_loss: 0.0227 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9938\n",
      "Epoch 125/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0440 - digit1_loss: 0.0226 - digit2_loss: 0.0214 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9939\n",
      "Epoch 126/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0375 - digit1_loss: 0.0187 - digit2_loss: 0.0188 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9947\n",
      "Epoch 127/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0483 - digit1_loss: 0.0243 - digit2_loss: 0.0240 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9928\n",
      "Epoch 128/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0470 - digit1_loss: 0.0234 - digit2_loss: 0.0236 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9935\n",
      "Epoch 129/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0469 - digit1_loss: 0.0239 - digit2_loss: 0.0230 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9937\n",
      "Epoch 130/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0496 - digit1_loss: 0.0252 - digit2_loss: 0.0244 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9926\n",
      "Epoch 131/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0441 - digit1_loss: 0.0225 - digit2_loss: 0.0216 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9938\n",
      "Epoch 132/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0416 - digit1_loss: 0.0218 - digit2_loss: 0.0198 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9945\n",
      "Epoch 133/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0435 - digit1_loss: 0.0215 - digit2_loss: 0.0220 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9940\n",
      "Epoch 134/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0416 - digit1_loss: 0.0209 - digit2_loss: 0.0207 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9947\n",
      "Epoch 135/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0432 - digit1_loss: 0.0206 - digit2_loss: 0.0226 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9938\n",
      "Epoch 136/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0432 - digit1_loss: 0.0185 - digit2_loss: 0.0246 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9935\n",
      "Epoch 137/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0469 - digit1_loss: 0.0248 - digit2_loss: 0.0222 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9940\n",
      "Epoch 138/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0420 - digit1_loss: 0.0202 - digit2_loss: 0.0218 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9941\n",
      "Epoch 139/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0405 - digit1_loss: 0.0190 - digit2_loss: 0.0215 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9937\n",
      "Epoch 140/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0406 - digit1_loss: 0.0188 - digit2_loss: 0.0217 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9941\n",
      "Epoch 141/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0382 - digit1_loss: 0.0174 - digit2_loss: 0.0208 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9945\n",
      "Epoch 142/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0448 - digit1_loss: 0.0224 - digit2_loss: 0.0224 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9940\n",
      "Epoch 143/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0451 - digit1_loss: 0.0234 - digit2_loss: 0.0218 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9938\n",
      "Epoch 144/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0419 - digit1_loss: 0.0197 - digit2_loss: 0.0222 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9941\n",
      "Epoch 145/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0425 - digit1_loss: 0.0227 - digit2_loss: 0.0198 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9945\n",
      "Epoch 146/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0481 - digit1_loss: 0.0235 - digit2_loss: 0.0245 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9936\n",
      "Epoch 147/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0388 - digit1_loss: 0.0198 - digit2_loss: 0.0190 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9945\n",
      "Epoch 148/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0378 - digit1_loss: 0.0189 - digit2_loss: 0.0188 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9949\n",
      "Epoch 149/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0417 - digit1_loss: 0.0215 - digit2_loss: 0.0202 - digit1_accuracy: 0.9943 - digit2_accuracy: 0.9942\n",
      "Epoch 150/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0471 - digit1_loss: 0.0226 - digit2_loss: 0.0244 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9933\n",
      "Epoch 151/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0424 - digit1_loss: 0.0217 - digit2_loss: 0.0206 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9943\n",
      "Epoch 152/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0430 - digit1_loss: 0.0219 - digit2_loss: 0.0212 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9944\n",
      "Epoch 153/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0443 - digit1_loss: 0.0211 - digit2_loss: 0.0231 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9937\n",
      "Epoch 154/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0433 - digit1_loss: 0.0216 - digit2_loss: 0.0217 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9941\n",
      "Epoch 155/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0482 - digit1_loss: 0.0224 - digit2_loss: 0.0258 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9939\n",
      "Epoch 156/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0393 - digit1_loss: 0.0208 - digit2_loss: 0.0185 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9952\n",
      "Epoch 157/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0413 - digit1_loss: 0.0207 - digit2_loss: 0.0207 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9942\n",
      "Epoch 158/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0369 - digit1_loss: 0.0179 - digit2_loss: 0.0190 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9946\n",
      "Epoch 159/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0444 - digit1_loss: 0.0208 - digit2_loss: 0.0236 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9935\n",
      "Epoch 160/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0389 - digit1_loss: 0.0210 - digit2_loss: 0.0179 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9949\n",
      "Epoch 161/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0417 - digit1_loss: 0.0206 - digit2_loss: 0.0211 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9942\n",
      "Epoch 162/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0467 - digit1_loss: 0.0230 - digit2_loss: 0.0237 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9939\n",
      "Epoch 163/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0413 - digit1_loss: 0.0216 - digit2_loss: 0.0198 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9950\n",
      "Epoch 164/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0417 - digit1_loss: 0.0205 - digit2_loss: 0.0212 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9945\n",
      "Epoch 165/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0353 - digit1_loss: 0.0163 - digit2_loss: 0.0189 - digit1_accuracy: 0.9953 - digit2_accuracy: 0.9950\n",
      "Epoch 166/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0443 - digit1_loss: 0.0229 - digit2_loss: 0.0214 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9944\n",
      "Epoch 167/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0422 - digit1_loss: 0.0189 - digit2_loss: 0.0233 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9943\n",
      "Epoch 168/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0431 - digit1_loss: 0.0228 - digit2_loss: 0.0203 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9947\n",
      "Epoch 169/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0399 - digit1_loss: 0.0192 - digit2_loss: 0.0207 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9944\n",
      "Epoch 170/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0366 - digit1_loss: 0.0179 - digit2_loss: 0.0187 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9954\n",
      "Epoch 171/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0371 - digit1_loss: 0.0174 - digit2_loss: 0.0197 - digit1_accuracy: 0.9953 - digit2_accuracy: 0.9949\n",
      "Epoch 172/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0422 - digit1_loss: 0.0214 - digit2_loss: 0.0208 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9943\n",
      "Epoch 173/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0424 - digit1_loss: 0.0191 - digit2_loss: 0.0233 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9939\n",
      "Epoch 174/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0433 - digit1_loss: 0.0215 - digit2_loss: 0.0218 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9941\n",
      "Epoch 175/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0403 - digit1_loss: 0.0198 - digit2_loss: 0.0204 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9945\n",
      "Epoch 176/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0361 - digit1_loss: 0.0175 - digit2_loss: 0.0186 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9948\n",
      "Epoch 177/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0365 - digit1_loss: 0.0187 - digit2_loss: 0.0178 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9951\n",
      "Epoch 178/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0389 - digit1_loss: 0.0196 - digit2_loss: 0.0193 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9951\n",
      "Epoch 179/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0356 - digit1_loss: 0.0156 - digit2_loss: 0.0200 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9952\n",
      "Epoch 180/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0410 - digit1_loss: 0.0197 - digit2_loss: 0.0213 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9946\n",
      "Epoch 181/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0395 - digit1_loss: 0.0171 - digit2_loss: 0.0224 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9945\n",
      "Epoch 182/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0409 - digit1_loss: 0.0221 - digit2_loss: 0.0188 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9948\n",
      "Epoch 183/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0379 - digit1_loss: 0.0184 - digit2_loss: 0.0196 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9949\n",
      "Epoch 184/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0514 - digit1_loss: 0.0264 - digit2_loss: 0.0250 - digit1_accuracy: 0.9936 - digit2_accuracy: 0.9939\n",
      "Epoch 185/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0426 - digit1_loss: 0.0210 - digit2_loss: 0.0216 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9949\n",
      "Epoch 186/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0394 - digit1_loss: 0.0217 - digit2_loss: 0.0178 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9951\n",
      "Epoch 187/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0339 - digit1_loss: 0.0148 - digit2_loss: 0.0191 - digit1_accuracy: 0.9959 - digit2_accuracy: 0.9955\n",
      "Epoch 188/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0414 - digit1_loss: 0.0199 - digit2_loss: 0.0215 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9945\n",
      "Epoch 189/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0443 - digit1_loss: 0.0238 - digit2_loss: 0.0205 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9950\n",
      "Epoch 190/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0371 - digit1_loss: 0.0170 - digit2_loss: 0.0202 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9948\n",
      "Epoch 191/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0365 - digit1_loss: 0.0196 - digit2_loss: 0.0169 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9956\n",
      "Epoch 192/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0381 - digit1_loss: 0.0194 - digit2_loss: 0.0187 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9954\n",
      "Epoch 193/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0363 - digit1_loss: 0.0188 - digit2_loss: 0.0175 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9952\n",
      "Epoch 194/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0427 - digit1_loss: 0.0201 - digit2_loss: 0.0225 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9946\n",
      "Epoch 195/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0378 - digit1_loss: 0.0225 - digit2_loss: 0.0153 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9956\n",
      "Epoch 196/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0356 - digit1_loss: 0.0170 - digit2_loss: 0.0185 - digit1_accuracy: 0.9956 - digit2_accuracy: 0.9957\n",
      "Epoch 197/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0393 - digit1_loss: 0.0202 - digit2_loss: 0.0191 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9951\n",
      "Epoch 198/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0384 - digit1_loss: 0.0206 - digit2_loss: 0.0178 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9955\n",
      "Epoch 199/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0321 - digit1_loss: 0.0168 - digit2_loss: 0.0153 - digit1_accuracy: 0.9959 - digit2_accuracy: 0.9956\n",
      "Epoch 200/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0438 - digit1_loss: 0.0218 - digit2_loss: 0.0220 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9944\n",
      "loss : 2.4654372930526733\n",
      "digit1_loss : 1.1738986372947693\n",
      "digit2_loss : 1.2915387451648712\n",
      "digit1_accuracy : 0.9236041754484177\n",
      "digit2_accuracy : 0.917395830154419\n",
      "Fold 5\n",
      "Epoch 1/200\n",
      "750/750 [==============================] - 4s 4ms/step - loss: 3.2461 - digit1_loss: 1.5085 - digit2_loss: 1.7376 - digit1_accuracy: 0.4627 - digit2_accuracy: 0.3627\n",
      "Epoch 2/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.8629 - digit1_loss: 0.8442 - digit2_loss: 1.0187 - digit1_accuracy: 0.7123 - digit2_accuracy: 0.6453\n",
      "Epoch 3/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.3541 - digit1_loss: 0.6329 - digit2_loss: 0.7212 - digit1_accuracy: 0.7868 - digit2_accuracy: 0.7572\n",
      "Epoch 4/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.0684 - digit1_loss: 0.4987 - digit2_loss: 0.5696 - digit1_accuracy: 0.8327 - digit2_accuracy: 0.8089\n",
      "Epoch 5/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.8886 - digit1_loss: 0.4199 - digit2_loss: 0.4686 - digit1_accuracy: 0.8609 - digit2_accuracy: 0.8443\n",
      "Epoch 6/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7485 - digit1_loss: 0.3526 - digit2_loss: 0.3959 - digit1_accuracy: 0.8820 - digit2_accuracy: 0.8706\n",
      "Epoch 7/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6464 - digit1_loss: 0.3075 - digit2_loss: 0.3389 - digit1_accuracy: 0.8975 - digit2_accuracy: 0.8875\n",
      "Epoch 8/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.5679 - digit1_loss: 0.2687 - digit2_loss: 0.2992 - digit1_accuracy: 0.9101 - digit2_accuracy: 0.9009\n",
      "Epoch 9/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.4923 - digit1_loss: 0.2351 - digit2_loss: 0.2572 - digit1_accuracy: 0.9208 - digit2_accuracy: 0.9156\n",
      "Epoch 10/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.4427 - digit1_loss: 0.2065 - digit2_loss: 0.2362 - digit1_accuracy: 0.9309 - digit2_accuracy: 0.9195\n",
      "Epoch 11/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3909 - digit1_loss: 0.1855 - digit2_loss: 0.2054 - digit1_accuracy: 0.9371 - digit2_accuracy: 0.9305\n",
      "Epoch 12/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3525 - digit1_loss: 0.1675 - digit2_loss: 0.1850 - digit1_accuracy: 0.9437 - digit2_accuracy: 0.9365\n",
      "Epoch 13/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.3136 - digit1_loss: 0.1483 - digit2_loss: 0.1653 - digit1_accuracy: 0.9494 - digit2_accuracy: 0.9427\n",
      "Epoch 14/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2858 - digit1_loss: 0.1382 - digit2_loss: 0.1476 - digit1_accuracy: 0.9520 - digit2_accuracy: 0.9495\n",
      "Epoch 15/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2682 - digit1_loss: 0.1268 - digit2_loss: 0.1414 - digit1_accuracy: 0.9565 - digit2_accuracy: 0.9519\n",
      "Epoch 16/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2417 - digit1_loss: 0.1163 - digit2_loss: 0.1254 - digit1_accuracy: 0.9601 - digit2_accuracy: 0.9570\n",
      "Epoch 17/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2313 - digit1_loss: 0.1116 - digit2_loss: 0.1198 - digit1_accuracy: 0.9615 - digit2_accuracy: 0.9593\n",
      "Epoch 18/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2112 - digit1_loss: 0.1025 - digit2_loss: 0.1087 - digit1_accuracy: 0.9649 - digit2_accuracy: 0.9629\n",
      "Epoch 19/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1903 - digit1_loss: 0.0927 - digit2_loss: 0.0976 - digit1_accuracy: 0.9686 - digit2_accuracy: 0.9667\n",
      "Epoch 20/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1852 - digit1_loss: 0.0905 - digit2_loss: 0.0947 - digit1_accuracy: 0.9687 - digit2_accuracy: 0.9679\n",
      "Epoch 21/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1716 - digit1_loss: 0.0824 - digit2_loss: 0.0893 - digit1_accuracy: 0.9721 - digit2_accuracy: 0.9695\n",
      "Epoch 22/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1642 - digit1_loss: 0.0799 - digit2_loss: 0.0843 - digit1_accuracy: 0.9730 - digit2_accuracy: 0.9714\n",
      "Epoch 23/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1528 - digit1_loss: 0.0728 - digit2_loss: 0.0800 - digit1_accuracy: 0.9753 - digit2_accuracy: 0.9729\n",
      "Epoch 24/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1481 - digit1_loss: 0.0736 - digit2_loss: 0.0745 - digit1_accuracy: 0.9745 - digit2_accuracy: 0.9747\n",
      "Epoch 25/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1426 - digit1_loss: 0.0715 - digit2_loss: 0.0711 - digit1_accuracy: 0.9761 - digit2_accuracy: 0.9756\n",
      "Epoch 26/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1358 - digit1_loss: 0.0661 - digit2_loss: 0.0697 - digit1_accuracy: 0.9779 - digit2_accuracy: 0.9764\n",
      "Epoch 27/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1292 - digit1_loss: 0.0627 - digit2_loss: 0.0664 - digit1_accuracy: 0.9790 - digit2_accuracy: 0.9770\n",
      "Epoch 28/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1231 - digit1_loss: 0.0587 - digit2_loss: 0.0643 - digit1_accuracy: 0.9803 - digit2_accuracy: 0.9781\n",
      "Epoch 29/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1236 - digit1_loss: 0.0599 - digit2_loss: 0.0637 - digit1_accuracy: 0.9796 - digit2_accuracy: 0.9788\n",
      "Epoch 30/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1188 - digit1_loss: 0.0565 - digit2_loss: 0.0623 - digit1_accuracy: 0.9812 - digit2_accuracy: 0.9793\n",
      "Epoch 31/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1125 - digit1_loss: 0.0544 - digit2_loss: 0.0582 - digit1_accuracy: 0.9818 - digit2_accuracy: 0.9811\n",
      "Epoch 32/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1063 - digit1_loss: 0.0502 - digit2_loss: 0.0561 - digit1_accuracy: 0.9834 - digit2_accuracy: 0.9811\n",
      "Epoch 33/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1112 - digit1_loss: 0.0528 - digit2_loss: 0.0584 - digit1_accuracy: 0.9826 - digit2_accuracy: 0.9806\n",
      "Epoch 34/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1016 - digit1_loss: 0.0494 - digit2_loss: 0.0521 - digit1_accuracy: 0.9830 - digit2_accuracy: 0.9828\n",
      "Epoch 35/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0977 - digit1_loss: 0.0484 - digit2_loss: 0.0493 - digit1_accuracy: 0.9840 - digit2_accuracy: 0.9836\n",
      "Epoch 36/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1114 - digit1_loss: 0.0552 - digit2_loss: 0.0561 - digit1_accuracy: 0.9828 - digit2_accuracy: 0.9817\n",
      "Epoch 37/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0921 - digit1_loss: 0.0464 - digit2_loss: 0.0457 - digit1_accuracy: 0.9838 - digit2_accuracy: 0.9842\n",
      "Epoch 38/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0934 - digit1_loss: 0.0437 - digit2_loss: 0.0498 - digit1_accuracy: 0.9858 - digit2_accuracy: 0.9837\n",
      "Epoch 39/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0874 - digit1_loss: 0.0423 - digit2_loss: 0.0450 - digit1_accuracy: 0.9850 - digit2_accuracy: 0.9853\n",
      "Epoch 40/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0904 - digit1_loss: 0.0438 - digit2_loss: 0.0466 - digit1_accuracy: 0.9858 - digit2_accuracy: 0.9845\n",
      "Epoch 41/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0876 - digit1_loss: 0.0434 - digit2_loss: 0.0442 - digit1_accuracy: 0.9858 - digit2_accuracy: 0.9851\n",
      "Epoch 42/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0857 - digit1_loss: 0.0411 - digit2_loss: 0.0445 - digit1_accuracy: 0.9868 - digit2_accuracy: 0.9859\n",
      "Epoch 43/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0875 - digit1_loss: 0.0413 - digit2_loss: 0.0461 - digit1_accuracy: 0.9861 - digit2_accuracy: 0.9858\n",
      "Epoch 44/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0753 - digit1_loss: 0.0351 - digit2_loss: 0.0402 - digit1_accuracy: 0.9889 - digit2_accuracy: 0.9861\n",
      "Epoch 45/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0851 - digit1_loss: 0.0407 - digit2_loss: 0.0444 - digit1_accuracy: 0.9866 - digit2_accuracy: 0.9856\n",
      "Epoch 46/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0809 - digit1_loss: 0.0394 - digit2_loss: 0.0415 - digit1_accuracy: 0.9874 - digit2_accuracy: 0.9871\n",
      "Epoch 47/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0871 - digit1_loss: 0.0441 - digit2_loss: 0.0430 - digit1_accuracy: 0.9864 - digit2_accuracy: 0.9866\n",
      "Epoch 48/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0744 - digit1_loss: 0.0386 - digit2_loss: 0.0358 - digit1_accuracy: 0.9884 - digit2_accuracy: 0.9883\n",
      "Epoch 49/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0791 - digit1_loss: 0.0385 - digit2_loss: 0.0406 - digit1_accuracy: 0.9879 - digit2_accuracy: 0.9869\n",
      "Epoch 50/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0705 - digit1_loss: 0.0341 - digit2_loss: 0.0364 - digit1_accuracy: 0.9890 - digit2_accuracy: 0.9881\n",
      "Epoch 51/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0830 - digit1_loss: 0.0431 - digit2_loss: 0.0399 - digit1_accuracy: 0.9864 - digit2_accuracy: 0.9873\n",
      "Epoch 52/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0679 - digit1_loss: 0.0351 - digit2_loss: 0.0327 - digit1_accuracy: 0.9888 - digit2_accuracy: 0.9895\n",
      "Epoch 53/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0718 - digit1_loss: 0.0352 - digit2_loss: 0.0366 - digit1_accuracy: 0.9886 - digit2_accuracy: 0.9880\n",
      "Epoch 54/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0702 - digit1_loss: 0.0357 - digit2_loss: 0.0345 - digit1_accuracy: 0.9886 - digit2_accuracy: 0.9890\n",
      "Epoch 55/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0718 - digit1_loss: 0.0352 - digit2_loss: 0.0366 - digit1_accuracy: 0.9896 - digit2_accuracy: 0.9890\n",
      "Epoch 56/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0654 - digit1_loss: 0.0310 - digit2_loss: 0.0344 - digit1_accuracy: 0.9904 - digit2_accuracy: 0.9895\n",
      "Epoch 57/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0781 - digit1_loss: 0.0357 - digit2_loss: 0.0424 - digit1_accuracy: 0.9883 - digit2_accuracy: 0.9870\n",
      "Epoch 58/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0707 - digit1_loss: 0.0354 - digit2_loss: 0.0353 - digit1_accuracy: 0.9891 - digit2_accuracy: 0.9894\n",
      "Epoch 59/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0639 - digit1_loss: 0.0301 - digit2_loss: 0.0338 - digit1_accuracy: 0.9900 - digit2_accuracy: 0.9895\n",
      "Epoch 60/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0688 - digit1_loss: 0.0335 - digit2_loss: 0.0353 - digit1_accuracy: 0.9896 - digit2_accuracy: 0.9897\n",
      "Epoch 61/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0687 - digit1_loss: 0.0331 - digit2_loss: 0.0356 - digit1_accuracy: 0.9901 - digit2_accuracy: 0.9892\n",
      "Epoch 62/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0617 - digit1_loss: 0.0320 - digit2_loss: 0.0297 - digit1_accuracy: 0.9901 - digit2_accuracy: 0.9903\n",
      "Epoch 63/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0636 - digit1_loss: 0.0320 - digit2_loss: 0.0316 - digit1_accuracy: 0.9900 - digit2_accuracy: 0.9904\n",
      "Epoch 64/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0685 - digit1_loss: 0.0330 - digit2_loss: 0.0356 - digit1_accuracy: 0.9896 - digit2_accuracy: 0.9893\n",
      "Epoch 65/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0555 - digit1_loss: 0.0270 - digit2_loss: 0.0284 - digit1_accuracy: 0.9914 - digit2_accuracy: 0.9915\n",
      "Epoch 66/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0591 - digit1_loss: 0.0302 - digit2_loss: 0.0289 - digit1_accuracy: 0.9908 - digit2_accuracy: 0.9912\n",
      "Epoch 67/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0617 - digit1_loss: 0.0305 - digit2_loss: 0.0312 - digit1_accuracy: 0.9908 - digit2_accuracy: 0.9902\n",
      "Epoch 68/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0620 - digit1_loss: 0.0307 - digit2_loss: 0.0314 - digit1_accuracy: 0.9907 - digit2_accuracy: 0.9904\n",
      "Epoch 69/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0596 - digit1_loss: 0.0303 - digit2_loss: 0.0293 - digit1_accuracy: 0.9914 - digit2_accuracy: 0.9914\n",
      "Epoch 70/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0624 - digit1_loss: 0.0313 - digit2_loss: 0.0311 - digit1_accuracy: 0.9909 - digit2_accuracy: 0.9908\n",
      "Epoch 71/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0643 - digit1_loss: 0.0308 - digit2_loss: 0.0335 - digit1_accuracy: 0.9907 - digit2_accuracy: 0.9901\n",
      "Epoch 72/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0585 - digit1_loss: 0.0284 - digit2_loss: 0.0301 - digit1_accuracy: 0.9912 - digit2_accuracy: 0.9914\n",
      "Epoch 73/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0579 - digit1_loss: 0.0280 - digit2_loss: 0.0298 - digit1_accuracy: 0.9918 - digit2_accuracy: 0.9903\n",
      "Epoch 74/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0520 - digit1_loss: 0.0266 - digit2_loss: 0.0254 - digit1_accuracy: 0.9917 - digit2_accuracy: 0.9918\n",
      "Epoch 75/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0612 - digit1_loss: 0.0296 - digit2_loss: 0.0317 - digit1_accuracy: 0.9909 - digit2_accuracy: 0.9902\n",
      "Epoch 76/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0590 - digit1_loss: 0.0290 - digit2_loss: 0.0300 - digit1_accuracy: 0.9912 - digit2_accuracy: 0.9916\n",
      "Epoch 77/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0541 - digit1_loss: 0.0278 - digit2_loss: 0.0263 - digit1_accuracy: 0.9915 - digit2_accuracy: 0.9921\n",
      "Epoch 78/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0536 - digit1_loss: 0.0271 - digit2_loss: 0.0264 - digit1_accuracy: 0.9919 - digit2_accuracy: 0.9921\n",
      "Epoch 79/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0566 - digit1_loss: 0.0276 - digit2_loss: 0.0290 - digit1_accuracy: 0.9915 - digit2_accuracy: 0.9909\n",
      "Epoch 80/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0524 - digit1_loss: 0.0263 - digit2_loss: 0.0261 - digit1_accuracy: 0.9920 - digit2_accuracy: 0.9917\n",
      "Epoch 81/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0567 - digit1_loss: 0.0277 - digit2_loss: 0.0290 - digit1_accuracy: 0.9920 - digit2_accuracy: 0.9918\n",
      "Epoch 82/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0542 - digit1_loss: 0.0273 - digit2_loss: 0.0269 - digit1_accuracy: 0.9920 - digit2_accuracy: 0.9922\n",
      "Epoch 83/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0529 - digit1_loss: 0.0253 - digit2_loss: 0.0276 - digit1_accuracy: 0.9928 - digit2_accuracy: 0.9919\n",
      "Epoch 84/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0509 - digit1_loss: 0.0256 - digit2_loss: 0.0253 - digit1_accuracy: 0.9922 - digit2_accuracy: 0.9924\n",
      "Epoch 85/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0567 - digit1_loss: 0.0297 - digit2_loss: 0.0269 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9922\n",
      "Epoch 86/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0494 - digit1_loss: 0.0240 - digit2_loss: 0.0254 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9923\n",
      "Epoch 87/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0526 - digit1_loss: 0.0259 - digit2_loss: 0.0266 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9918\n",
      "Epoch 88/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0495 - digit1_loss: 0.0242 - digit2_loss: 0.0252 - digit1_accuracy: 0.9925 - digit2_accuracy: 0.9924\n",
      "Epoch 89/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0465 - digit1_loss: 0.0229 - digit2_loss: 0.0236 - digit1_accuracy: 0.9930 - digit2_accuracy: 0.9927\n",
      "Epoch 90/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0514 - digit1_loss: 0.0244 - digit2_loss: 0.0270 - digit1_accuracy: 0.9927 - digit2_accuracy: 0.9919\n",
      "Epoch 91/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0514 - digit1_loss: 0.0253 - digit2_loss: 0.0261 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9926\n",
      "Epoch 92/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0510 - digit1_loss: 0.0247 - digit2_loss: 0.0263 - digit1_accuracy: 0.9931 - digit2_accuracy: 0.9924\n",
      "Epoch 93/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0534 - digit1_loss: 0.0256 - digit2_loss: 0.0278 - digit1_accuracy: 0.9927 - digit2_accuracy: 0.9923\n",
      "Epoch 94/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0539 - digit1_loss: 0.0277 - digit2_loss: 0.0261 - digit1_accuracy: 0.9924 - digit2_accuracy: 0.9920\n",
      "Epoch 95/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0490 - digit1_loss: 0.0249 - digit2_loss: 0.0241 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9927\n",
      "Epoch 96/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0404 - digit1_loss: 0.0200 - digit2_loss: 0.0204 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9942\n",
      "Epoch 97/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0497 - digit1_loss: 0.0242 - digit2_loss: 0.0255 - digit1_accuracy: 0.9930 - digit2_accuracy: 0.9925\n",
      "Epoch 98/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0474 - digit1_loss: 0.0229 - digit2_loss: 0.0246 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9929\n",
      "Epoch 99/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0481 - digit1_loss: 0.0244 - digit2_loss: 0.0236 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9930\n",
      "Epoch 100/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0544 - digit1_loss: 0.0277 - digit2_loss: 0.0267 - digit1_accuracy: 0.9925 - digit2_accuracy: 0.9925\n",
      "Epoch 101/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0460 - digit1_loss: 0.0238 - digit2_loss: 0.0222 - digit1_accuracy: 0.9936 - digit2_accuracy: 0.9939\n",
      "Epoch 102/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0459 - digit1_loss: 0.0212 - digit2_loss: 0.0247 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9932\n",
      "Epoch 103/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0501 - digit1_loss: 0.0227 - digit2_loss: 0.0274 - digit1_accuracy: 0.9933 - digit2_accuracy: 0.9920\n",
      "Epoch 104/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0522 - digit1_loss: 0.0276 - digit2_loss: 0.0246 - digit1_accuracy: 0.9927 - digit2_accuracy: 0.9929\n",
      "Epoch 105/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0434 - digit1_loss: 0.0227 - digit2_loss: 0.0208 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9940\n",
      "Epoch 106/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0451 - digit1_loss: 0.0229 - digit2_loss: 0.0222 - digit1_accuracy: 0.9936 - digit2_accuracy: 0.9938\n",
      "Epoch 107/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0506 - digit1_loss: 0.0242 - digit2_loss: 0.0264 - digit1_accuracy: 0.9930 - digit2_accuracy: 0.9930\n",
      "Epoch 108/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0440 - digit1_loss: 0.0220 - digit2_loss: 0.0221 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9931\n",
      "Epoch 109/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0456 - digit1_loss: 0.0225 - digit2_loss: 0.0231 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9929\n",
      "Epoch 110/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0466 - digit1_loss: 0.0237 - digit2_loss: 0.0229 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9933\n",
      "Epoch 111/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0421 - digit1_loss: 0.0212 - digit2_loss: 0.0209 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9938\n",
      "Epoch 112/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0469 - digit1_loss: 0.0243 - digit2_loss: 0.0226 - digit1_accuracy: 0.9932 - digit2_accuracy: 0.9936\n",
      "Epoch 113/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0423 - digit1_loss: 0.0205 - digit2_loss: 0.0218 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9941\n",
      "Epoch 114/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0451 - digit1_loss: 0.0216 - digit2_loss: 0.0236 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9935\n",
      "Epoch 115/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0412 - digit1_loss: 0.0203 - digit2_loss: 0.0209 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9941\n",
      "Epoch 116/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0462 - digit1_loss: 0.0242 - digit2_loss: 0.0220 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9938\n",
      "Epoch 117/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0458 - digit1_loss: 0.0223 - digit2_loss: 0.0236 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9940\n",
      "Epoch 118/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0404 - digit1_loss: 0.0196 - digit2_loss: 0.0208 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9940\n",
      "Epoch 119/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0396 - digit1_loss: 0.0192 - digit2_loss: 0.0204 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9941\n",
      "Epoch 120/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0478 - digit1_loss: 0.0254 - digit2_loss: 0.0224 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9936\n",
      "Epoch 121/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0389 - digit1_loss: 0.0176 - digit2_loss: 0.0213 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9942\n",
      "Epoch 122/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0434 - digit1_loss: 0.0223 - digit2_loss: 0.0211 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9941\n",
      "Epoch 123/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0397 - digit1_loss: 0.0203 - digit2_loss: 0.0193 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9946\n",
      "Epoch 124/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0421 - digit1_loss: 0.0214 - digit2_loss: 0.0207 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9940\n",
      "Epoch 125/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0407 - digit1_loss: 0.0173 - digit2_loss: 0.0234 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9934\n",
      "Epoch 126/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0460 - digit1_loss: 0.0226 - digit2_loss: 0.0233 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9933\n",
      "Epoch 127/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0433 - digit1_loss: 0.0227 - digit2_loss: 0.0206 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9941\n",
      "Epoch 128/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0448 - digit1_loss: 0.0234 - digit2_loss: 0.0214 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9942\n",
      "Epoch 129/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0348 - digit1_loss: 0.0178 - digit2_loss: 0.0170 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9951\n",
      "Epoch 130/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0442 - digit1_loss: 0.0232 - digit2_loss: 0.0211 - digit1_accuracy: 0.9943 - digit2_accuracy: 0.9942\n",
      "Epoch 131/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0464 - digit1_loss: 0.0213 - digit2_loss: 0.0251 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9933\n",
      "Epoch 132/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0461 - digit1_loss: 0.0234 - digit2_loss: 0.0227 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9935\n",
      "Epoch 133/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0441 - digit1_loss: 0.0211 - digit2_loss: 0.0230 - digit1_accuracy: 0.9942 - digit2_accuracy: 0.9939\n",
      "Epoch 134/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0484 - digit1_loss: 0.0234 - digit2_loss: 0.0250 - digit1_accuracy: 0.9937 - digit2_accuracy: 0.9933\n",
      "Epoch 135/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0407 - digit1_loss: 0.0202 - digit2_loss: 0.0205 - digit1_accuracy: 0.9946 - digit2_accuracy: 0.9942\n",
      "Epoch 136/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0401 - digit1_loss: 0.0196 - digit2_loss: 0.0204 - digit1_accuracy: 0.9943 - digit2_accuracy: 0.9945\n",
      "Epoch 137/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0469 - digit1_loss: 0.0214 - digit2_loss: 0.0255 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9936\n",
      "Epoch 138/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0360 - digit1_loss: 0.0161 - digit2_loss: 0.0199 - digit1_accuracy: 0.9953 - digit2_accuracy: 0.9947\n",
      "Epoch 139/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0435 - digit1_loss: 0.0196 - digit2_loss: 0.0239 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9940\n",
      "Epoch 140/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0398 - digit1_loss: 0.0208 - digit2_loss: 0.0190 - digit1_accuracy: 0.9943 - digit2_accuracy: 0.9945\n",
      "Epoch 141/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0428 - digit1_loss: 0.0216 - digit2_loss: 0.0212 - digit1_accuracy: 0.9943 - digit2_accuracy: 0.9942\n",
      "Epoch 142/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0347 - digit1_loss: 0.0164 - digit2_loss: 0.0183 - digit1_accuracy: 0.9957 - digit2_accuracy: 0.9953\n",
      "Epoch 143/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0468 - digit1_loss: 0.0240 - digit2_loss: 0.0227 - digit1_accuracy: 0.9941 - digit2_accuracy: 0.9941\n",
      "Epoch 144/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0387 - digit1_loss: 0.0199 - digit2_loss: 0.0188 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9949\n",
      "Epoch 145/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0435 - digit1_loss: 0.0212 - digit2_loss: 0.0222 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9941\n",
      "Epoch 146/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0484 - digit1_loss: 0.0238 - digit2_loss: 0.0247 - digit1_accuracy: 0.9940 - digit2_accuracy: 0.9941\n",
      "Epoch 147/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0380 - digit1_loss: 0.0192 - digit2_loss: 0.0188 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9950\n",
      "Epoch 148/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0400 - digit1_loss: 0.0196 - digit2_loss: 0.0205 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9943\n",
      "Epoch 149/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0394 - digit1_loss: 0.0191 - digit2_loss: 0.0204 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9946\n",
      "Epoch 150/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0407 - digit1_loss: 0.0200 - digit2_loss: 0.0207 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9948\n",
      "Epoch 151/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0414 - digit1_loss: 0.0187 - digit2_loss: 0.0226 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9941\n",
      "Epoch 152/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0404 - digit1_loss: 0.0217 - digit2_loss: 0.0187 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9949\n",
      "Epoch 153/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0394 - digit1_loss: 0.0216 - digit2_loss: 0.0178 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9950\n",
      "Epoch 154/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0383 - digit1_loss: 0.0191 - digit2_loss: 0.0192 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9948\n",
      "Epoch 155/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0425 - digit1_loss: 0.0204 - digit2_loss: 0.0221 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9941\n",
      "Epoch 156/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0392 - digit1_loss: 0.0176 - digit2_loss: 0.0216 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9945\n",
      "Epoch 157/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0382 - digit1_loss: 0.0180 - digit2_loss: 0.0202 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9946\n",
      "Epoch 158/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0381 - digit1_loss: 0.0221 - digit2_loss: 0.0160 - digit1_accuracy: 0.9943 - digit2_accuracy: 0.9955\n",
      "Epoch 159/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0400 - digit1_loss: 0.0210 - digit2_loss: 0.0190 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9951\n",
      "Epoch 160/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0371 - digit1_loss: 0.0181 - digit2_loss: 0.0190 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9951\n",
      "Epoch 161/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0363 - digit1_loss: 0.0165 - digit2_loss: 0.0198 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9946\n",
      "Epoch 162/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0357 - digit1_loss: 0.0185 - digit2_loss: 0.0172 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9953\n",
      "Epoch 163/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0483 - digit1_loss: 0.0243 - digit2_loss: 0.0240 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9935\n",
      "Epoch 164/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0399 - digit1_loss: 0.0199 - digit2_loss: 0.0200 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9948\n",
      "Epoch 165/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0327 - digit1_loss: 0.0170 - digit2_loss: 0.0157 - digit1_accuracy: 0.9953 - digit2_accuracy: 0.9956\n",
      "Epoch 166/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0403 - digit1_loss: 0.0175 - digit2_loss: 0.0228 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9945\n",
      "Epoch 167/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0407 - digit1_loss: 0.0216 - digit2_loss: 0.0191 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9949\n",
      "Epoch 168/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0405 - digit1_loss: 0.0203 - digit2_loss: 0.0202 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9950\n",
      "Epoch 169/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0340 - digit1_loss: 0.0150 - digit2_loss: 0.0190 - digit1_accuracy: 0.9957 - digit2_accuracy: 0.9950\n",
      "Epoch 170/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0433 - digit1_loss: 0.0219 - digit2_loss: 0.0215 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9944\n",
      "Epoch 171/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0355 - digit1_loss: 0.0188 - digit2_loss: 0.0166 - digit1_accuracy: 0.9950 - digit2_accuracy: 0.9953\n",
      "Epoch 172/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0371 - digit1_loss: 0.0180 - digit2_loss: 0.0191 - digit1_accuracy: 0.9956 - digit2_accuracy: 0.9950\n",
      "Epoch 173/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0350 - digit1_loss: 0.0162 - digit2_loss: 0.0188 - digit1_accuracy: 0.9959 - digit2_accuracy: 0.9950\n",
      "Epoch 174/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0344 - digit1_loss: 0.0157 - digit2_loss: 0.0186 - digit1_accuracy: 0.9961 - digit2_accuracy: 0.9956\n",
      "Epoch 175/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0442 - digit1_loss: 0.0241 - digit2_loss: 0.0201 - digit1_accuracy: 0.9944 - digit2_accuracy: 0.9950\n",
      "Epoch 176/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0409 - digit1_loss: 0.0208 - digit2_loss: 0.0201 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9948\n",
      "Epoch 177/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0370 - digit1_loss: 0.0180 - digit2_loss: 0.0191 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9949\n",
      "Epoch 178/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0471 - digit1_loss: 0.0260 - digit2_loss: 0.0211 - digit1_accuracy: 0.9945 - digit2_accuracy: 0.9944\n",
      "Epoch 179/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0383 - digit1_loss: 0.0204 - digit2_loss: 0.0179 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9953\n",
      "Epoch 180/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0326 - digit1_loss: 0.0166 - digit2_loss: 0.0161 - digit1_accuracy: 0.9960 - digit2_accuracy: 0.9960\n",
      "Epoch 181/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0377 - digit1_loss: 0.0176 - digit2_loss: 0.0202 - digit1_accuracy: 0.9956 - digit2_accuracy: 0.9950\n",
      "Epoch 182/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0405 - digit1_loss: 0.0207 - digit2_loss: 0.0198 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9949\n",
      "Epoch 183/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0372 - digit1_loss: 0.0190 - digit2_loss: 0.0182 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9951\n",
      "Epoch 184/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0390 - digit1_loss: 0.0194 - digit2_loss: 0.0196 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9950\n",
      "Epoch 185/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0416 - digit1_loss: 0.0201 - digit2_loss: 0.0215 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9949\n",
      "Epoch 186/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0317 - digit1_loss: 0.0168 - digit2_loss: 0.0149 - digit1_accuracy: 0.9959 - digit2_accuracy: 0.9960\n",
      "Epoch 187/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0399 - digit1_loss: 0.0205 - digit2_loss: 0.0194 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9946\n",
      "Epoch 188/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0388 - digit1_loss: 0.0202 - digit2_loss: 0.0187 - digit1_accuracy: 0.9956 - digit2_accuracy: 0.9949\n",
      "Epoch 189/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0340 - digit1_loss: 0.0177 - digit2_loss: 0.0163 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9955\n",
      "Epoch 190/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0442 - digit1_loss: 0.0230 - digit2_loss: 0.0212 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9952\n",
      "Epoch 191/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0380 - digit1_loss: 0.0193 - digit2_loss: 0.0186 - digit1_accuracy: 0.9952 - digit2_accuracy: 0.9953\n",
      "Epoch 192/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0342 - digit1_loss: 0.0166 - digit2_loss: 0.0176 - digit1_accuracy: 0.9958 - digit2_accuracy: 0.9955\n",
      "Epoch 193/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0337 - digit1_loss: 0.0165 - digit2_loss: 0.0172 - digit1_accuracy: 0.9959 - digit2_accuracy: 0.9956\n",
      "Epoch 194/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0397 - digit1_loss: 0.0195 - digit2_loss: 0.0201 - digit1_accuracy: 0.9953 - digit2_accuracy: 0.9952\n",
      "Epoch 195/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0401 - digit1_loss: 0.0199 - digit2_loss: 0.0202 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9949\n",
      "Epoch 196/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0377 - digit1_loss: 0.0193 - digit2_loss: 0.0184 - digit1_accuracy: 0.9955 - digit2_accuracy: 0.9959\n",
      "Epoch 197/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0406 - digit1_loss: 0.0215 - digit2_loss: 0.0191 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9956\n",
      "Epoch 198/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0321 - digit1_loss: 0.0157 - digit2_loss: 0.0164 - digit1_accuracy: 0.9960 - digit2_accuracy: 0.9961\n",
      "Epoch 199/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0425 - digit1_loss: 0.0217 - digit2_loss: 0.0208 - digit1_accuracy: 0.9947 - digit2_accuracy: 0.9952\n",
      "Epoch 200/200\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.0445 - digit1_loss: 0.0215 - digit2_loss: 0.0230 - digit1_accuracy: 0.9948 - digit2_accuracy: 0.9946\n",
      "loss : 2.4594059944152833\n",
      "digit1_loss : 1.1772409915924071\n",
      "digit2_loss : 1.282165026664734\n",
      "digit1_accuracy : 0.9238487482070923\n",
      "digit2_accuracy : 0.9184987068176269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# Create the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize some lists to store the results\n",
    "all_metrics = []\n",
    "all_fold_scores = []\n",
    "\n",
    "# Loop over the folds\n",
    "for i, (train_index, test_index) in enumerate(kf.split(data_X)):\n",
    "    print(\"Fold\", i+1)\n",
    "    \n",
    "    # Get the current fold's train and test data\n",
    "    fold_train_X, fold_test_X = data_X[train_index], data_X[test_index]\n",
    "    fold_train_Y, fold_test_Y = data_Y[train_index], data_Y[test_index]\n",
    "    \n",
    "    # Reshape the data\n",
    "    fold_train_X = fold_train_X.reshape(fold_train_X.shape[0], 32, 32, 1)\n",
    "    fold_test_X = fold_test_X.reshape(fold_test_X.shape[0], 32, 32, 1)\n",
    "    \n",
    "    # Preprocess the labels\n",
    "    fold_train_Y1, fold_train_Y2 = fold_train_Y[:,0], fold_train_Y[:,1]\n",
    "    fold_test_Y1, fold_test_Y2 = fold_test_Y[:,0], fold_test_Y[:,1]\n",
    "\n",
    "    fold_train_Y1 = to_categorical(fold_train_Y1, num_classes=10)\n",
    "    fold_train_Y2 = to_categorical(fold_train_Y2, num_classes=10)\n",
    "\n",
    "    fold_test_Y1 = to_categorical(fold_test_Y1, num_classes=10)\n",
    "    fold_test_Y2 = to_categorical(fold_test_Y2, num_classes=10)\n",
    "    \n",
    "    best_kernel_size = 5\n",
    "    best_num_filters = 113\n",
    "    best_dropout_rate = 0.47592726919130585\n",
    "\n",
    "    # Create the model with the best hyperparameters\n",
    "    inputs = Input(shape=(32, 32, 1))\n",
    "    x = Conv2D(best_num_filters, kernel_size=(best_kernel_size, best_kernel_size), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(best_num_filters*2, kernel_size=(best_kernel_size, best_kernel_size), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(best_dropout_rate)(x)\n",
    "    output1 = Dense(10, activation='softmax', name='digit1')(x)\n",
    "    output2 = Dense(10, activation='softmax', name='digit2')(x)\n",
    "    model = Model(inputs, [output1, output2])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(fold_train_X, [fold_train_Y1, fold_train_Y2], batch_size=64, epochs=200)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    metrics_names = model.metrics_names\n",
    "    fold_test_values = model.evaluate(fold_test_X, [fold_test_Y1, fold_test_Y2], verbose=0)\n",
    "\n",
    "    # Store the results\n",
    "    fold_scores = {}\n",
    "    for i in range(len(metrics_names)):\n",
    "        fold_scores[metrics_names[i]] = fold_test_values[i]\n",
    "        all_fold_scores.append(fold_scores)\n",
    "\n",
    "    # Print the average results across all folds\n",
    "    for metric in metrics_names:\n",
    "      mean_score = np.mean([fold_scores[metric] for fold_scores in all_fold_scores])\n",
    "      print(metric, \":\", mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7ypdiuTAVBP"
   },
   "source": [
    "# Final model gets ~98% accuracy on both digits"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
